{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape, learning_rate = 0.001):\n",
    "    # apply weight decay\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.0001)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# # Create the CNN model\n",
    "# model = build_model(input_shape)\n",
    "# model.summary()\n",
    "\n",
    "# # Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# Data generator for training with augmentation\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 11):\n",
    "    # Create the CNN model\n",
    "    model = build_model(input_shape, learning_rate=0.001)\n",
    "    model.summary()\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    # Training data with augmentation\n",
    "    train_generator = train_data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    # Training the model with augmented data\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=100\n",
    "    )\n",
    "\n",
    "    # Print the contents of history.history\n",
    "    print(history.history)\n",
    "    # Save training loss values\n",
    "    train_loss = history.history['loss']\n",
    "    train_accuracies = history.history['accuracy']\n",
    "\n",
    "    # Save training and test loss values to a file\n",
    "    losses_filename = 'losses_pretrained_model10FOLD100EPOCHS.txt'\n",
    "    with open(losses_filename, 'w') as losses_file:\n",
    "        losses_file.write(\"Epoch\\tTraining Loss\\tTraining Accuracy\\n\")\n",
    "        for epoch in range(len(train_loss)):\n",
    "            losses_file.write(f\"{epoch + 1}\\t{train_loss[epoch]}\\t{train_accuracies[epoch]}\\n\")\n",
    "\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'10fold_model_fold_DataAugment_100epochs_{fold_number}.h5')\n",
    "\n",
    "    # Load the saved model for testing\n",
    "    loaded_model = load_model(f'10fold_model_fold_DataAugment_100epochs_{fold_number}.h5')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "     # Save classification results to a file\n",
    "    results_filename = f'10fold_classification_resultsDataAugment100epochs_fold_{fold_number}.txt'\n",
    "    with open(results_filename, 'w') as results_file:\n",
    "        results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "        for i in range(len(test_generator.filenames)):\n",
    "            image_name = os.path.basename(test_generator.filenames[i])\n",
    "            true_label = true_labels[i]\n",
    "            predicted_label = predicted_labels[i]\n",
    "            results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results_10FOLD100EPOCHS.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 10),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results_10FOLD100EPOCHS.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# # Create a DataFrame for easy summary and visualization\n",
    "# df_results = pd.DataFrame({\n",
    "#     'Fold': np.repeat(range(1, 11), 3),\n",
    "#     'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "#     'Score': precision_list + recall_list + f1_list\n",
    "# })\n",
    "\n",
    "# # Visualize the results with a single boxplot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "# plt.title('Performance Across 5-Folds')\n",
    "# plt.show()\n",
    "\n",
    "# # Summary table\n",
    "# summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "# summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "# print(\"\\nSummary of Results:\")\n",
    "# print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision_list': [0.5567010309278351, 0.9772727272727273, 0.8362573099415205, 0.9815950920245399, 0.9754601226993865, 0.99375, 0.9696969696969697, 1.0, 1.0, 1.0], 'recall_list': [0.675, 0.80625, 0.89375, 1.0, 0.99375, 0.99375, 1.0, 1.0, 1.0, 1.0], 'f1_list': [0.6101694915254238, 0.8835616438356164, 0.8640483383685801, 0.9907120743034056, 0.9845201238390093, 0.99375, 0.9846153846153847, 1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/wangg/REU-Hearing-Loss-Project-1/machine learning/checkpoint results/10folds - 80-20 train test split (includes all subjects)/experiments/100epochsDataAugLRScheduler/results/evaluation_results.pkl\"\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    evaluation_results = pickle.load(file)\n",
    "\n",
    "\n",
    "print(evaluation_results)\n",
    "# Now, 'evaluation_results' contains the data loaded from the pickle file\n",
    "# You can access and manipulate the data as needed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU-Hearing-Loss-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
