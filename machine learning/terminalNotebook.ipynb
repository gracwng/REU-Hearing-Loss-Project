{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's try 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "# Paths to training and testing data\n",
    "training_data_path = '/home/wangg/REU-Hearing-Loss-Project-1/machine learning/preTrainedModel/data/10folds - 70-15-15 train test split (includes all subjects)/fold1/Training'\n",
    "testing_data_path = '/home/wangg/REU-Hearing-Loss-Project-1/machine learning/preTrainedModel/data/10folds - 70-15-15 train test split (includes all subjects)/fold1/Testing'\n",
    "\n",
    "print(\"WORKING NOW\")\n",
    "# Image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators for training and testing with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "# Create data generators for training and testing\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # bc we have two classes\n",
    ")\n",
    "\n",
    "# # Print the class names\n",
    "# class_names = list(train_generator.class_indices.keys())\n",
    "# print(\"Class Names:\", class_names)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testing_data_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model with weights from ImageNet\n",
    "base_model = ResNet50(\n",
    "    include_top=False, # don't want to include the top layer because we will define our own input/output layer\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    # pooling=None,\n",
    "    pooling= 'max',\n",
    "    classes=2,\n",
    ")\n",
    "# Freeze only the convolutional layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, keras.layers.Conv2D):\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "# Add custom classification layers on top of ResNet-50\n",
    "# these new layers and specifically the 512 neurons are the ones that will be learning the new weights \n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)  # Assuming 2 classes: Healthy and Hearing Impaired\n",
    "\n",
    "\n",
    "# Create the final model\n",
    "model = keras.Model(base_model.input, x)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# # Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Count the number of batches per epoch\n",
    "num_batches_per_epoch = len(train_generator)\n",
    "\n",
    "# Calculate the total number of images seen during training\n",
    "total_images_seen = batch_size * num_batches_per_epoch * 10  # Assuming 10 epochs\n",
    "\n",
    "print(f\"Total number of batches per epoch: {num_batches_per_epoch}\")\n",
    "print(f\"Total number of images seen during training: {total_images_seen}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=100)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Save accuracies during training\n",
    "train_accuracies = history.history['accuracy']\n",
    "\n",
    "# Evaluate the model on the testing data and get predictions\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Calculate precision, recall, and f1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Save classification results to a file\n",
    "results_filename = 'classification_results_pretrained_model_freeze_convo_layers_100epoch.txt'\n",
    "with open(results_filename, 'w') as results_file:\n",
    "    results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "    for i in range(len(test_generator.filenames)):\n",
    "        image_name = os.path.basename(test_generator.filenames[i])\n",
    "        true_label = true_labels[i]\n",
    "        predicted_label = predicted_labels[i]\n",
    "        results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save metrics to a text file with a different filename\n",
    "metrics_filename = 'classification_metrics_pretrained_model_freeze_convo_layers_100epoch.txt'\n",
    "with open(metrics_filename, 'w') as file:\n",
    "    file.write(f'Test Accuracy: {test_acc}\\n')\n",
    "    file.write(f'Precision: {precision}\\n')\n",
    "    file.write(f'Recall: {recall}\\n')\n",
    "    file.write(f'F1 Score: {f1_score}\\n')\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
