{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:46:22.383185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 09:46:22.388749: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "45/45 [==============================] - 1198s 25s/step - loss: 0.8850 - categorical_accuracy: 0.5722\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 1267s 28s/step - loss: 0.6345 - categorical_accuracy: 0.6583\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 1279s 28s/step - loss: 0.5673 - categorical_accuracy: 0.7049\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 1293s 29s/step - loss: 0.7087 - categorical_accuracy: 0.6354\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 1308s 29s/step - loss: 0.5239 - categorical_accuracy: 0.7486\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 1275s 28s/step - loss: 0.5214 - categorical_accuracy: 0.7465\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 1263s 28s/step - loss: 0.5393 - categorical_accuracy: 0.7410\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 1278s 28s/step - loss: 0.4162 - categorical_accuracy: 0.8160\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 1211s 27s/step - loss: 0.6352 - categorical_accuracy: 0.7528\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 1252s 28s/step - loss: 0.5372 - categorical_accuracy: 0.7590\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 1280s 28s/step - loss: 0.3911 - categorical_accuracy: 0.8424\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 1291s 29s/step - loss: 0.4254 - categorical_accuracy: 0.8264\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 1178s 26s/step - loss: 0.3325 - categorical_accuracy: 0.8694\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 1159s 26s/step - loss: 0.2721 - categorical_accuracy: 0.8882\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 1118s 25s/step - loss: 0.3036 - categorical_accuracy: 0.8750\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 1127s 25s/step - loss: 0.2663 - categorical_accuracy: 0.8944\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 1292s 29s/step - loss: 0.2092 - categorical_accuracy: 0.9167\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 1175s 26s/step - loss: 0.1822 - categorical_accuracy: 0.9326\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 976s 22s/step - loss: 0.1171 - categorical_accuracy: 0.9597\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 978s 22s/step - loss: 0.1304 - categorical_accuracy: 0.9507\n",
      "Epoch 21/60\n",
      "10/45 [=====>........................] - ETA: 11:33 - loss: 0.0998 - categorical_accuracy: 0.9594"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, \\\n",
    "    Dense, Concatenate, Add, ReLU, BatchNormalization, AvgPool2D, \\\n",
    "    MaxPool2D, GlobalAvgPool2D, Reshape, Permute, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def stage(x, channels, repetitions, groups):\n",
    "    x = shufflenet_block(x, channels=channels, strides=2, groups=groups)\n",
    "    for i in range(repetitions):\n",
    "        x = shufflenet_block(x, channels=channels, strides=1, groups=groups)\n",
    "    return x\n",
    "\n",
    "def shufflenet_block(tensor, channels, strides, groups):\n",
    "    x = gconv(tensor, channels=channels // 4, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    " \n",
    "    x = channel_shuffle(x, groups)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    " \n",
    "    if strides == 2:\n",
    "        channels = channels - tensor.get_shape().as_list()[-1]\n",
    "    x = gconv(x, channels=channels, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    " \n",
    "    if strides == 1:\n",
    "        x = Add()([tensor, x])\n",
    "    else:\n",
    "        avg = AvgPool2D(pool_size=3, strides=2, padding='same')(tensor)\n",
    "        x = Concatenate()([avg, x])\n",
    " \n",
    "    output = ReLU()(x)\n",
    "    return output\n",
    "\n",
    "def gconv(tensor, channels, groups):\n",
    "    input_ch = tensor.get_shape().as_list()[-1]\n",
    "    group_ch = input_ch // groups\n",
    "    output_ch = channels // groups\n",
    "    groups_list = []\n",
    " \n",
    "    for i in range(groups):\n",
    "        group_tensor = Lambda(lambda x: x[:, :, :, i * group_ch: (i+1) * group_ch])(tensor)\n",
    "        group_tensor = Conv2D(output_ch, 1)(group_tensor)\n",
    "        groups_list.append(group_tensor)\n",
    " \n",
    "    output = Concatenate()(groups_list)\n",
    "    return output\n",
    "\n",
    "def channel_shuffle(x, groups):  \n",
    "    _, width, height, channels = x.get_shape().as_list()\n",
    "    group_ch = channels // groups\n",
    " \n",
    "    x = Reshape([width, height, group_ch, groups])(x)\n",
    "    x = Permute([1, 2, 4, 3])(x)\n",
    "    x = Reshape([width, height, channels])(x)\n",
    "    return x\n",
    "\n",
    "def build_shufflenet(input_shape, num_classes=2):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=24, kernel_size=3, strides=2, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3, 7, 3]\n",
    "    initial_channels = 384\n",
    "    groups = 8\n",
    "\n",
    "    for i, reps in enumerate(repetitions):\n",
    "        channels = initial_channels * (2**i)\n",
    "        x = stage(x, channels, reps, groups)\n",
    "\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    shufflenet_model = Model(inputs=input_tensor, outputs=output)\n",
    "    return shufflenet_model\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'\n",
    "# List all fold directories\n",
    "all_folds = os.listdir(fold_data_dir)\n",
    "\n",
    "# K-fold cross-validation\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "for fold_number in range(1, 6):\n",
    "    # Create a list of folds excluding the current fold for testing\n",
    "    test_fold = f'fold{fold_number}'\n",
    "    train_folds = [f for f in all_folds if f != test_fold]\n",
    "\n",
    "    # Data generators for training and testing\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        os.path.join(fold_data_dir, train_folds[0], 'Training'),  # Assuming each fold has the same structure\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        os.path.join(fold_data_dir, test_fold, 'Testing'),\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Build and compile ShuffleNet model\n",
    "    shufflenet_model = build_shufflenet(input_shape)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    loss_function = categorical_crossentropy\n",
    "    metrics = [categorical_accuracy]\n",
    "\n",
    "    shufflenet_model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "\n",
    "    # Train the model\n",
    "    history = shufflenet_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy, test_precision, test_recall = shufflenet_model.evaluate(test_generator)\n",
    "    test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "    print(f'\\nEvaluation for Fold {fold_number + 1}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"Test Precision:\", test_precision)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test F1 Score:\", test_f1_score)\n",
    "\n",
    "    # Store the metrics for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "    fold_precisions.append(test_precision)\n",
    "    fold_recalls.append(test_recall)\n",
    "    fold_f1_scores.append(test_f1_score)\n",
    "\n",
    "    # Save the model if needed\n",
    "    shufflenet_model.save(f'shufflenet_fold_{fold_number + 1}.h5')\n",
    "\n",
    "# Save results to a file or print as needed\n",
    "results_filename = 'shufflenet_results.txt'\n",
    "with open(results_filename, 'w') as file:\n",
    "    file.write(\"Fold, Accuracy, Precision, Recall, F1 Score\\n\")\n",
    "    for fold_number, (accuracy, precision, recall, f1_score) in enumerate(zip(fold_accuracies, fold_precisions, fold_recalls, fold_f1_scores), start=1):\n",
    "        file.write(f'{fold_number}, {accuracy}, {precision}, {recall}, {f1_score}\\n')\n",
    "\n",
    "# Print average metrics across folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "average_precision = np.mean(fold_precisions)\n",
    "average_recall = np.mean(fold_recalls)\n",
    "average_f1_score = np.mean(fold_f1_scores)\n",
    "\n",
    "print(f'\\nAverage Accuracy across Folds 1-{num_folds}: {average_accuracy}')\n",
    "print(f'Average Precision across Folds 1-{num_folds}: {average_precision}')\n",
    "print(f'Average Recall across Folds 1-{num_folds}: {average_recall}')\n",
    "print(f'Average F1 Score across Folds 1-{num_folds}: {average_f1_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU-Hearing-Loss-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
