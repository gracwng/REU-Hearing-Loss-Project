{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:32:05.677849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 102\u001b[0m\n\u001b[1;32m     98\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (img_width, img_height, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_number, (train_indices, test_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(fold_data_dir))), np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(fold_data_dir))))):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Data generators for training and testing\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_generator\u001b[49m\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m    103\u001b[0m         fold_data_dir,\n\u001b[1;32m    104\u001b[0m         target_size\u001b[38;5;241m=\u001b[39m(img_width, img_height),\n\u001b[1;32m    105\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    106\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    107\u001b[0m         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    108\u001b[0m         indices\u001b[38;5;241m=\u001b[39mtrain_indices\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    111\u001b[0m     test_generator \u001b[38;5;241m=\u001b[39m data_generator\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m    112\u001b[0m         fold_data_dir,\n\u001b[1;32m    113\u001b[0m         target_size\u001b[38;5;241m=\u001b[39m(img_width, img_height),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         indices\u001b[38;5;241m=\u001b[39mtest_indices\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Build and compile ShuffleNet model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, \\\n",
    "    Dense, Concatenate, Add, ReLU, BatchNormalization, AvgPool2D, \\\n",
    "    MaxPool2D, GlobalAvgPool2D, Reshape, Permute, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def stage(x, channels, repetitions, groups):\n",
    "    x = shufflenet_block(x, channels=channels, strides=2, groups=groups)\n",
    "    for i in range(repetitions):\n",
    "        x = shufflenet_block(x, channels=channels, strides=1, groups=groups)\n",
    "    return x\n",
    "\n",
    "def shufflenet_block(tensor, channels, strides, groups):\n",
    "    x = gconv(tensor, channels=channels // 4, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    " \n",
    "    x = channel_shuffle(x, groups)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    " \n",
    "    if strides == 2:\n",
    "        channels = channels - tensor.get_shape().as_list()[-1]\n",
    "    x = gconv(x, channels=channels, groups=groups)\n",
    "    x = BatchNormalization()(x)\n",
    " \n",
    "    if strides == 1:\n",
    "        x = Add()([tensor, x])\n",
    "    else:\n",
    "        avg = AvgPool2D(pool_size=3, strides=2, padding='same')(tensor)\n",
    "        x = Concatenate()([avg, x])\n",
    " \n",
    "    output = ReLU()(x)\n",
    "    return output\n",
    "\n",
    "def gconv(tensor, channels, groups):\n",
    "    input_ch = tensor.get_shape().as_list()[-1]\n",
    "    group_ch = input_ch // groups\n",
    "    output_ch = channels // groups\n",
    "    groups_list = []\n",
    " \n",
    "    for i in range(groups):\n",
    "        group_tensor = Lambda(lambda x: x[:, :, :, i * group_ch: (i+1) * group_ch])(tensor)\n",
    "        group_tensor = Conv2D(output_ch, 1)(group_tensor)\n",
    "        groups_list.append(group_tensor)\n",
    " \n",
    "    output = Concatenate()(groups_list)\n",
    "    return output\n",
    "\n",
    "def channel_shuffle(x, groups):  \n",
    "    _, width, height, channels = x.get_shape().as_list()\n",
    "    group_ch = channels // groups\n",
    " \n",
    "    x = Reshape([width, height, group_ch, groups])(x)\n",
    "    x = Permute([1, 2, 4, 3])(x)\n",
    "    x = Reshape([width, height, channels])(x)\n",
    "    return x\n",
    "\n",
    "def build_shufflenet(input_shape, num_classes=2):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=24, kernel_size=3, strides=2, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    repetitions = [3, 7, 3]\n",
    "    initial_channels = 384\n",
    "    groups = 8\n",
    "\n",
    "    for i, reps in enumerate(repetitions):\n",
    "        channels = initial_channels * (2**i)\n",
    "        x = stage(x, channels, reps, groups)\n",
    "\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    shufflenet_model = Model(inputs=input_tensor, outputs=output)\n",
    "    return shufflenet_model\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'\n",
    "\n",
    "# K-fold cross-validation\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "for fold_number, (train_indices, test_indices) in enumerate(skf.split(np.zeros(len(os.listdir(fold_data_dir))), np.zeros(len(os.listdir(fold_data_dir))))):\n",
    "    # Data generators for training and testing\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        fold_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        indices=train_indices\n",
    "    )\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        fold_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        indices=test_indices\n",
    "    )\n",
    "\n",
    "    # Build and compile ShuffleNet model\n",
    "    shufflenet_model = build_shufflenet(input_shape)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    loss_function = categorical_crossentropy\n",
    "    metrics = [categorical_accuracy]\n",
    "\n",
    "    shufflenet_model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "\n",
    "    # Train the model\n",
    "    history = shufflenet_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy, test_precision, test_recall = shufflenet_model.evaluate(test_generator)\n",
    "    test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "    print(f'\\nEvaluation for Fold {fold_number + 1}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"Test Precision:\", test_precision)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test F1 Score:\", test_f1_score)\n",
    "\n",
    "    # Store the metrics for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "    fold_precisions.append(test_precision)\n",
    "    fold_recalls.append(test_recall)\n",
    "    fold_f1_scores.append(test_f1_score)\n",
    "\n",
    "    # Save the model if needed\n",
    "    shufflenet_model.save(f'shufflenet_fold_{fold_number + 1}.h5')\n",
    "\n",
    "# Save results to a file or print as needed\n",
    "results_filename = 'shufflenet_results.txt'\n",
    "with open(results_filename, 'w') as file:\n",
    "    file.write(\"Fold, Accuracy, Precision, Recall, F1 Score\\n\")\n",
    "    for fold_number, (accuracy, precision, recall, f1_score) in enumerate(zip(fold_accuracies, fold_precisions, fold_recalls, fold_f1_scores), start=1):\n",
    "        file.write(f'{fold_number}, {accuracy}, {precision}, {recall}, {f1_score}\\n')\n",
    "\n",
    "# Print average metrics across folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "average_precision = np.mean(fold_precisions)\n",
    "average_recall = np.mean(fold_recalls)\n",
    "average_f1_score = np.mean(fold_f1_scores)\n",
    "\n",
    "print(f'\\nAverage Accuracy across Folds 1-{num_folds}: {average_accuracy}')\n",
    "print(f'Average Precision across Folds 1-{num_folds}: {average_precision}')\n",
    "print(f'Average Recall across Folds 1-{num_folds}: {average_recall}')\n",
    "print(f'Average F1 Score across Folds 1-{num_folds}: {average_f1_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU-Hearing-Loss-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
