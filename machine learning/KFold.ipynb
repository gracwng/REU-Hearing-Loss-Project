{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 10 Folds, 80% training, 20% testing split. (4 HI, 4 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 05:08:13.379489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 05:08:15.379476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 05:08:15.386183: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 29s 610ms/step - loss: 1.3232 - accuracy: 0.5472\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.6130 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.5448 - accuracy: 0.7139\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.5083 - accuracy: 0.7382\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.4601 - accuracy: 0.7688\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.3982 - accuracy: 0.8090\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.3966 - accuracy: 0.7965\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.3511 - accuracy: 0.8285\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.3238 - accuracy: 0.8597\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.2771 - accuracy: 0.8743\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.2366 - accuracy: 0.8931\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.2636 - accuracy: 0.8813\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.2123 - accuracy: 0.9139\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.2019 - accuracy: 0.9153\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.1519 - accuracy: 0.9375\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.2108 - accuracy: 0.9118\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.1535 - accuracy: 0.9375\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.1204 - accuracy: 0.9535\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.1098 - accuracy: 0.9604\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.1282 - accuracy: 0.9486\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.2098 - accuracy: 0.9187\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.1243 - accuracy: 0.9556\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.1126 - accuracy: 0.9576\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.1199 - accuracy: 0.9563\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0820 - accuracy: 0.9653\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0903 - accuracy: 0.9667\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0902 - accuracy: 0.9625\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0748 - accuracy: 0.9715\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.1098 - accuracy: 0.9528\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0559 - accuracy: 0.9799\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0868 - accuracy: 0.9618\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0794 - accuracy: 0.9757\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0381 - accuracy: 0.9875\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0595 - accuracy: 0.9792\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0796 - accuracy: 0.9757\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0752 - accuracy: 0.9715\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0541 - accuracy: 0.9799\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0263 - accuracy: 0.9944\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0299 - accuracy: 0.9896\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0254 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0172 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0236 - accuracy: 0.9917\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.1393 - accuracy: 0.9597\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0408 - accuracy: 0.9868\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0394 - accuracy: 0.9882\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0453 - accuracy: 0.9833\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0251 - accuracy: 0.9931\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0169 - accuracy: 0.9931\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0295 - accuracy: 0.9924\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0703 - accuracy: 0.9736\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0213 - accuracy: 0.9931\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0306 - accuracy: 0.9910\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0377 - accuracy: 0.9917\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0580 - accuracy: 0.9806\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 3.1274 - accuracy: 0.6062\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 3.1273767948150635\n",
      "Test Accuracy: 0.606249988079071\n",
      "10/10 [==============================] - 2s 192ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.2718 - accuracy: 0.9229\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0944 - accuracy: 0.9646\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0802 - accuracy: 0.9722\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0724 - accuracy: 0.9729\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0544 - accuracy: 0.9819\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0417 - accuracy: 0.9854\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0253 - accuracy: 0.9910\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0163 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0453 - accuracy: 0.9840\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0398 - accuracy: 0.9875\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0598 - accuracy: 0.9792\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0482 - accuracy: 0.9812\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.0735 - accuracy: 0.9729\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0442 - accuracy: 0.9854\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0261 - accuracy: 0.9896\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0306 - accuracy: 0.9882\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0121 - accuracy: 0.9972\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0165 - accuracy: 0.9937\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0577 - accuracy: 0.9778\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0327 - accuracy: 0.9910\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0555 - accuracy: 0.9812\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0778 - accuracy: 0.9708\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0379 - accuracy: 0.9889\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0159 - accuracy: 0.9944\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0114 - accuracy: 0.9958\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.2201 - accuracy: 0.9410\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0985 - accuracy: 0.9639\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0245 - accuracy: 0.9931\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0258 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0068 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0051 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0300 - accuracy: 0.9931\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0090 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0257 - accuracy: 0.9937\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0227 - accuracy: 0.9937\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0313 - accuracy: 0.9896\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.0798 - accuracy: 0.9785\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0662 - accuracy: 0.9764\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0156 - accuracy: 0.9944\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.9624 - accuracy: 0.8562\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.9624485969543457\n",
      "Test Accuracy: 0.856249988079071\n",
      "10/10 [==============================] - 2s 205ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.1442 - accuracy: 0.9597\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0941 - accuracy: 0.9632\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0343 - accuracy: 0.9854\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0316 - accuracy: 0.9889\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0216 - accuracy: 0.9944\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0217 - accuracy: 0.9937\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0107 - accuracy: 0.9958\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0086 - accuracy: 0.9958\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0095 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.1623 - accuracy: 0.9674\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0422 - accuracy: 0.9861\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 6.4943e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0339 - accuracy: 0.9882\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.1940 - accuracy: 0.9535\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0504 - accuracy: 0.9799\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0237 - accuracy: 0.9910\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0114 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0202 - accuracy: 0.9965\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 24s 540ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0156 - accuracy: 0.9965\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0071 - accuracy: 0.9958\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.3520 - accuracy: 0.9031\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.35199588537216187\n",
      "Test Accuracy: 0.903124988079071\n",
      "10/10 [==============================] - 2s 189ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0425 - accuracy: 0.9882\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0131 - accuracy: 0.9944\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0223 - accuracy: 0.9896\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0085 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.1615 - accuracy: 0.9590\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0552 - accuracy: 0.9806\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0096 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0141 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0330 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0320 - accuracy: 0.9882\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0048 - accuracy: 0.9972\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0048 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0140 - accuracy: 0.9965\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0664 - accuracy: 0.9771\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0171 - accuracy: 0.9924\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0103 - accuracy: 0.9958\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 7.5669e-04 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 9.9703e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0309 - accuracy: 0.9931\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0367 - accuracy: 0.9882\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0436 - accuracy: 0.9861\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.3962 - accuracy: 0.9062\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.3961780071258545\n",
      "Test Accuracy: 0.90625\n",
      "10/10 [==============================] - 2s 217ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0120 - accuracy: 0.9944\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 9.4777e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 5.8247e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0056 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0062 - accuracy: 0.9972\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0060 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0149 - accuracy: 0.9965\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0131 - accuracy: 0.9965\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0111 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 7.8063e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 9.6342e-04 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 5.4044e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0075 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 1.4928e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0239 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0751 - accuracy: 0.9882\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0088 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0135 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 6.5079e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0073 - accuracy: 0.9958\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0028 - accuracy: 0.9979\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 7.7715e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 1.3331e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 3.1308e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 2.0198e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 1.8366e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.0010273780208081007\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 205ms/step\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0231 - accuracy: 0.9931\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0088 - accuracy: 0.9958\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0035 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 2.7494e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 4.1995e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 6.2680e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 3.1434e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 2.2479e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 4.2832e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 1.1173e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 2.8771e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 7.6939e-04 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 2.6788e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 1.0084e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 1.9828e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.6232e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 6.8759e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 5.8210e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 3.9211e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 4.5795e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 5.0184e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 2.3218e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 4.3941e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0045 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 4.9085e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 1.2422e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 2.1889e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 5.4873e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.0213e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0080 - accuracy: 0.9965\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0081 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0197 - accuracy: 0.9944\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0923 - accuracy: 0.9826\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0599 - accuracy: 0.9861\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0304 - accuracy: 0.9910\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0159 - accuracy: 0.9958\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0114 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.0067 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 0.006706621497869492\n",
      "Test Accuracy: 0.996874988079071\n",
      "10/10 [==============================] - 2s 196ms/step\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0073 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0020 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 4.4569e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0106 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0144 - accuracy: 0.9944\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0407 - accuracy: 0.9903\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0220 - accuracy: 0.9951\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 1.6605e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 1.4799e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 6.0322e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 1.2865e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 1.3863e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 5.3926e-04 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 2.3381e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 2.1904e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 2.0916e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 9.5250e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 2.0064e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 6.5376e-04 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0326 - accuracy: 0.9917\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0084 - accuracy: 0.9958\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 24s 524ms/step - loss: 5.3064e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.6979e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 1.6688e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 1.2531e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 1.1139e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.4943e-05 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 4.5171e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 7.1910e-05 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 2.3225e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 3.0088e-06 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 4.2227e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 28s 608ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0050 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 2.0741e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 8.4699e-05 - accuracy: 1.0000\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.1012 - accuracy: 0.9812\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 0.10119403898715973\n",
      "Test Accuracy: 0.981249988079071\n",
      "10/10 [==============================] - 2s 197ms/step\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.1388 - accuracy: 0.9736\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0325 - accuracy: 0.9937\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0137 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0120 - accuracy: 0.9972\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0260 - accuracy: 0.9944\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0596 - accuracy: 0.9917\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0201 - accuracy: 0.9958\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0044 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 9.8768e-04 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 1.7901e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 3.5677e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 2.3128e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 3.9119e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 3.0239e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 1.3321e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 1.2127e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 1.6311e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.2333e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 1.7216e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 5.1129e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 3.2349e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.7747e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 2.3690e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 9.6357e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 1.9944e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 8.3442e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 1.7125e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 2.9409e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 2.2505e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 5.4631e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 8.6580e-04 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 7.4036e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0380 - accuracy: 0.9944\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0389 - accuracy: 0.9903\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 8.2708e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 1.1664e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 7.7421e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 1.7008e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 5.8091e-04 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 2.5983e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 2.2866e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 24s 522ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 2.1087e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 0.00021087145432829857\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 142ms/step\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0518 - accuracy: 0.9896\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0057 - accuracy: 0.9958\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 2.9521e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 2.5368e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 4.2463e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 2.6318e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 3.5783e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 2.0730e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 9.4721e-04 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 7.2150e-05 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 3.3196e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 8.9548e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 6.6356e-04 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 2.7164e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 2.7678e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 5.3318e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 2.7578e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 7.2174e-06 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 3.1351e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 3.5377e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 2.8481e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 4.0806e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0103 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 9.0380e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 4.6870e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0404 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 9.9459e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 9.4020e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 2.2542e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 1.2009e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 1.0381e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.1366e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 6.6753e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 2.9600e-05 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 1.1252e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 1.6214e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 1.2019e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 6.1278e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.5392e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 3.3294e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0273 - accuracy: 0.9931\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0345 - accuracy: 0.9924\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 0.0040 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 0.003990915138274431\n",
      "Test Accuracy: 0.996874988079071\n",
      "10/10 [==============================] - 1s 136ms/step\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0201 - accuracy: 0.9951\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0071 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 6.8516e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 8.5290e-05 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 5.0972e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 6.7155e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 3.3346e-05 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 7.7327e-05 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.7410e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.1468e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 1.1135e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 7.6700e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 3.3628e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 4.6956e-06 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 1.2704e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 1.0487e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 2.4462e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 1.6358e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 4.6326e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 9.7512e-06 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 6.6123e-06 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 9.9532e-06 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 5.2735e-06 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 2.5057e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 9.3295e-06 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 4.0107e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 7.5162e-06 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 1.2695e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 1.7537e-05 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 2.2147e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.4227e-05 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 6.2128e-06 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 28s 609ms/step - loss: 1.2353e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 5.9674e-05 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 2.6209e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 1.8943e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 8.0607e-06 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 6.4433e-06 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 3.9324e-06 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 3.0997e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.5876e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 6.9703e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 1.1384e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 8.3694e-07 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 2.5646e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 1.4737e-05 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 1.2173e-05 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0389 - accuracy: 0.9903\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0686 - accuracy: 0.9875\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 7.1481e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 0.0007148078875616193\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 144ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Fold  Accuracy  Precision   Recall  F1 Score\n",
      "0     1  0.606250   0.584158  0.73750  0.651934\n",
      "1     2  0.856250   0.959677  0.74375  0.838028\n",
      "2     3  0.903125   0.938776  0.86250  0.899023\n",
      "3     4  0.906250   0.911392  0.90000  0.905660\n",
      "4     5  1.000000   1.000000  1.00000  1.000000\n",
      "5     6  0.996875   1.000000  0.99375  0.996865\n",
      "6     7  0.981250   1.000000  0.96250  0.980892\n",
      "7     8  1.000000   1.000000  1.00000  1.000000\n",
      "8     9  0.996875   1.000000  0.99375  0.996865\n",
      "9    10  1.000000   1.000000  1.00000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 11),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "           Worst Fold  Avg. Fold  Best Fold\n",
      "Metric                                     \n",
      "Accuracy     0.606250   0.924687        1.0\n",
      "F1 Score     0.651934   0.926927        1.0\n",
      "Precision    0.584158   0.939400        1.0\n",
      "Recall       0.737500   0.919375        1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "accuracy_list = [0.606250, 0.856250, 0.903125, 0.906250, 1.000000, 0.996875, 0.981250, 1.000000, 0.996875, 1.000000]  # Replace with your actual accuracy values\n",
    "precision_list = [0.584158, 0.959677, 0.938776, 0.911392, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "recall_list = [0.7375, 0.74375, 0.8625, 0.9, 1.0, 0.99375, 0.9625, 1.0, 0.99375, 1.0]\n",
    "f1_list = [0.651934, 0.838028, 0.899023, 0.90566, 1.0, 0.996865, 0.980892, 1.0, 0.996865, 1.0]\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [accuracy_list, precision_list, recall_list, f1_list]  # Include accuracy in the data\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Accuracy', 'Precision', 'Recall', 'F1 Score'])  # Adjust the labels\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Accuracy, Precision, Recall, and F1 Score across 10-Folds')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 11), 4),  # Adjust the repeat value\n",
    "    'Metric': ['Accuracy'] * 10 + ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,  # Adjust the categories\n",
    "    'Score': accuracy_list + precision_list + recall_list + f1_list  # Include accuracy in the scores\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 10-Folds (including Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 5 Folds, 80% training, 20% testing split. (4 HI, 4 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 06:42:30.869819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 06:42:32.256520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 06:42:32.264014: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 444ms/step - loss: 0.8751 - accuracy: 0.5458\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.6165 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.5873 - accuracy: 0.6875\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.5554 - accuracy: 0.7139\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.5281 - accuracy: 0.7333\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.4543 - accuracy: 0.7785\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.4291 - accuracy: 0.7840\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.5549 - accuracy: 0.7035\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.4563 - accuracy: 0.7701\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3812 - accuracy: 0.8139\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.3230 - accuracy: 0.8396\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3139 - accuracy: 0.8604\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3086 - accuracy: 0.8618\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.2662 - accuracy: 0.8792\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.2653 - accuracy: 0.8854\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.2436 - accuracy: 0.8944\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2320 - accuracy: 0.8924\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.1933 - accuracy: 0.9181\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2012 - accuracy: 0.9104\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1843 - accuracy: 0.9333\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.1646 - accuracy: 0.9340\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.1567 - accuracy: 0.9340\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1466 - accuracy: 0.9410\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.1476 - accuracy: 0.9354\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1469 - accuracy: 0.9389\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.1324 - accuracy: 0.9431\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.1222 - accuracy: 0.9514\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.1019 - accuracy: 0.9611\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.1123 - accuracy: 0.9556\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0887 - accuracy: 0.9660\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0963 - accuracy: 0.9625\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1615 - accuracy: 0.9396\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.1103 - accuracy: 0.9563\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.1116 - accuracy: 0.9597\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0974 - accuracy: 0.9653\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0879 - accuracy: 0.9715\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.1117 - accuracy: 0.9576\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0727 - accuracy: 0.9743\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0651 - accuracy: 0.9736\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0892 - accuracy: 0.9604\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0692 - accuracy: 0.9743\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0882 - accuracy: 0.9694\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0669 - accuracy: 0.9757\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0606 - accuracy: 0.9792\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0613 - accuracy: 0.9833\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0791 - accuracy: 0.9708\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0517 - accuracy: 0.9826\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0371 - accuracy: 0.9917\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0311 - accuracy: 0.9882\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0429 - accuracy: 0.9861\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0291 - accuracy: 0.9903\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0497 - accuracy: 0.9819\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0386 - accuracy: 0.9889\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0402 - accuracy: 0.9847\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0213 - accuracy: 0.9951\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0325 - accuracy: 0.9882\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.1109 - accuracy: 0.9549\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0681 - accuracy: 0.9715\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0325 - accuracy: 0.9868\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 2.6364 - accuracy: 0.6562\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 2.636406898498535\n",
      "Test Accuracy: 0.65625\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.3207 - accuracy: 0.8903\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1837 - accuracy: 0.9333\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.1134 - accuracy: 0.9583\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0824 - accuracy: 0.9743\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0877 - accuracy: 0.9694\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.1012 - accuracy: 0.9688\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0566 - accuracy: 0.9833\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0330 - accuracy: 0.9917\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0460 - accuracy: 0.9840\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0489 - accuracy: 0.9819\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0273 - accuracy: 0.9889\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0359 - accuracy: 0.9910\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0371 - accuracy: 0.9931\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0162 - accuracy: 0.9917\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0618 - accuracy: 0.9819\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0719 - accuracy: 0.9861\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0351 - accuracy: 0.9854\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0221 - accuracy: 0.9896\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0374 - accuracy: 0.9896\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0417 - accuracy: 0.9861\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0240 - accuracy: 0.9937\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0449 - accuracy: 0.9854\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0153 - accuracy: 0.9931\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0305 - accuracy: 0.9903\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0213 - accuracy: 0.9917\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0099 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0314 - accuracy: 0.9868\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0402 - accuracy: 0.9840\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0151 - accuracy: 0.9937\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0103 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0154 - accuracy: 0.9937\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0174 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0151 - accuracy: 0.9958\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0396 - accuracy: 0.9833\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0284 - accuracy: 0.9889\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0307 - accuracy: 0.9889\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0096 - accuracy: 0.9958\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0138 - accuracy: 0.9944\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0164 - accuracy: 0.9924\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0161 - accuracy: 0.9937\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0141 - accuracy: 0.9924\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0095 - accuracy: 0.9951\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0148 - accuracy: 0.9972\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.4543 - accuracy: 0.8844\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.4542678892612457\n",
      "Test Accuracy: 0.8843749761581421\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.1744 - accuracy: 0.9479\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0520 - accuracy: 0.9806\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0276 - accuracy: 0.9917\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0169 - accuracy: 0.9937\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0197 - accuracy: 0.9924\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0163 - accuracy: 0.9924\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0258 - accuracy: 0.9937\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0114 - accuracy: 0.9951\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0139 - accuracy: 0.9944\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0060 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0243 - accuracy: 0.9903\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0230 - accuracy: 0.9924\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0051 - accuracy: 0.9972\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0473 - accuracy: 0.9882\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0567 - accuracy: 0.9875\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0104 - accuracy: 0.9951\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0180 - accuracy: 0.9958\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0102 - accuracy: 0.9979\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 8.6504e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 5.9666e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0208 - accuracy: 0.9910\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0128 - accuracy: 0.9951\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0162 - accuracy: 0.9965\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0117 - accuracy: 0.9986\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0186 - accuracy: 0.9937\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0166 - accuracy: 0.9965\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0315 - accuracy: 0.9861\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0246 - accuracy: 0.9937\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0424 - accuracy: 0.9847\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3166 - accuracy: 0.8875\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.31663310527801514\n",
      "Test Accuracy: 0.887499988079071\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0571 - accuracy: 0.9812\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0203 - accuracy: 0.9924\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0197 - accuracy: 0.9931\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0376 - accuracy: 0.9868\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0305 - accuracy: 0.9931\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0143 - accuracy: 0.9958\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0096 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0161 - accuracy: 0.9931\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0095 - accuracy: 0.9965\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0166 - accuracy: 0.9958\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0102 - accuracy: 0.9979\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0154 - accuracy: 0.9937\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0149 - accuracy: 0.9979\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0047 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0162 - accuracy: 0.9937\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0093 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0417 - accuracy: 0.9882\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0170 - accuracy: 0.9965\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0335 - accuracy: 0.9924\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0142 - accuracy: 0.9972\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0073 - accuracy: 0.9965\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0098 - accuracy: 0.9965\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0090 - accuracy: 0.9951\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 6.9084e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 6.7861e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0390 - accuracy: 0.9812\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.03903304785490036\n",
      "Test Accuracy: 0.981249988079071\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0463 - accuracy: 0.9868\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0180 - accuracy: 0.9924\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0188 - accuracy: 0.9958\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0143 - accuracy: 0.9944\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0024 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 8.8664e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 9.0243e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 7.2921e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 6.3062e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0556 - accuracy: 0.9896\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0632 - accuracy: 0.9806\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0087 - accuracy: 0.9958\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0151 - accuracy: 0.9937\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0169 - accuracy: 0.9931\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0029 - accuracy: 0.9979\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0153 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0599 - accuracy: 0.9812\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0516 - accuracy: 0.9861\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0195 - accuracy: 0.9944\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0316 - accuracy: 0.9910\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0059 - accuracy: 0.9972\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 5.7248e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 5.3881e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 5.7841e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 6.9475e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 1.1409e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0025 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 7.1108e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 5.9546e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.0005954562220722437\n",
      "Test Accuracy: 1.0\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.65625\n",
      "Fold 2: 0.8843749761581421\n",
      "Fold 3: 0.887499988079071\n",
      "Fold 4: 0.981249988079071\n",
      "Fold 5: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.8818749904632568\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.12228935757243639\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.65625\n",
      "Fold 2: 0.8843749761581421\n",
      "Fold 3: 0.887499988079071\n",
      "Fold 4: 0.981249988079071\n",
      "Fold 5: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.8818749904632568\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.12228935757243639\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'  # Change this to the root folder containing your k-fold data\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 6):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-5: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-5: {std_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-11-23\n",
    "This code below is for K fold: 5 folds, 80%-20% train/test split, but it includes evluation metrics, boxplot and summary table \n",
    "\n",
    "UPDATE: THIS IS THE ONE FOR 5 FOLD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 40s 813ms/step - loss: 1.1192 - accuracy: 0.5896\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 35s 780ms/step - loss: 0.6065 - accuracy: 0.6826\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 36s 785ms/step - loss: 0.5816 - accuracy: 0.6924\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 35s 773ms/step - loss: 0.5522 - accuracy: 0.7153\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 37s 808ms/step - loss: 0.5144 - accuracy: 0.7340\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 36s 789ms/step - loss: 0.4967 - accuracy: 0.7431\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 35s 776ms/step - loss: 0.4638 - accuracy: 0.7674\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 35s 781ms/step - loss: 0.4120 - accuracy: 0.8069\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.3787 - accuracy: 0.8167\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 35s 769ms/step - loss: 0.3412 - accuracy: 0.8472\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 33s 732ms/step - loss: 0.3209 - accuracy: 0.8500\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.2817 - accuracy: 0.8701\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 30s 672ms/step - loss: 0.2628 - accuracy: 0.8910\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 31s 681ms/step - loss: 0.2269 - accuracy: 0.8972\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 32s 697ms/step - loss: 0.2603 - accuracy: 0.8896\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.2268 - accuracy: 0.8972\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 31s 688ms/step - loss: 0.2078 - accuracy: 0.9062\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.2095 - accuracy: 0.9083\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.1843 - accuracy: 0.9243\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.1547 - accuracy: 0.9361\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 31s 689ms/step - loss: 0.2061 - accuracy: 0.9146\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 34s 757ms/step - loss: 0.2233 - accuracy: 0.9125\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 32s 696ms/step - loss: 0.1464 - accuracy: 0.9396\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 31s 681ms/step - loss: 0.2045 - accuracy: 0.9181\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 30s 655ms/step - loss: 0.1519 - accuracy: 0.9396\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.1217 - accuracy: 0.9493\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 29s 634ms/step - loss: 0.1186 - accuracy: 0.9493\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 30s 656ms/step - loss: 0.1014 - accuracy: 0.9604\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 29s 650ms/step - loss: 0.1068 - accuracy: 0.9569\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 30s 669ms/step - loss: 0.1332 - accuracy: 0.9542\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 31s 694ms/step - loss: 0.1506 - accuracy: 0.9375\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.1087 - accuracy: 0.9583\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 31s 683ms/step - loss: 0.0802 - accuracy: 0.9715\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.1126 - accuracy: 0.9569\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 32s 711ms/step - loss: 0.1030 - accuracy: 0.9576\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 33s 721ms/step - loss: 0.0814 - accuracy: 0.9674\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 34s 744ms/step - loss: 0.0617 - accuracy: 0.9785\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 34s 757ms/step - loss: 0.0583 - accuracy: 0.9799\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 35s 768ms/step - loss: 0.0405 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 35s 767ms/step - loss: 0.0866 - accuracy: 0.9632\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 35s 767ms/step - loss: 0.1024 - accuracy: 0.9639\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 37s 819ms/step - loss: 0.0502 - accuracy: 0.9833\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 36s 792ms/step - loss: 0.0365 - accuracy: 0.9882\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 36s 791ms/step - loss: 0.0365 - accuracy: 0.9875\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 36s 798ms/step - loss: 0.1002 - accuracy: 0.9694\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 35s 766ms/step - loss: 0.0574 - accuracy: 0.9778\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 36s 791ms/step - loss: 0.0925 - accuracy: 0.9632\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 35s 782ms/step - loss: 0.0784 - accuracy: 0.9688\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 35s 764ms/step - loss: 0.0480 - accuracy: 0.9806\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.1540 - accuracy: 0.9521\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 35s 772ms/step - loss: 0.0654 - accuracy: 0.9757\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 33s 739ms/step - loss: 0.0475 - accuracy: 0.9861\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 35s 766ms/step - loss: 0.0296 - accuracy: 0.9917\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 31s 687ms/step - loss: 0.0318 - accuracy: 0.9896\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 29s 639ms/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 31s 687ms/step - loss: 0.0443 - accuracy: 0.9854\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 29s 643ms/step - loss: 0.0406 - accuracy: 0.9875\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 33s 739ms/step - loss: 0.0656 - accuracy: 0.9812\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 31s 695ms/step - loss: 0.0400 - accuracy: 0.9868\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 32s 698ms/step - loss: 0.0418 - accuracy: 0.9875\n",
      "10/10 [==============================] - 3s 240ms/step - loss: 2.0810 - accuracy: 0.6844\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 2.0809648036956787\n",
      "Test Accuracy: 0.684374988079071\n",
      "10/10 [==============================] - 3s 267ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 34s 753ms/step - loss: 0.3833 - accuracy: 0.8708\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 33s 731ms/step - loss: 0.1597 - accuracy: 0.9451\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 32s 714ms/step - loss: 0.1109 - accuracy: 0.9625\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 32s 701ms/step - loss: 0.0727 - accuracy: 0.9722\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 32s 710ms/step - loss: 0.0674 - accuracy: 0.9771\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 32s 697ms/step - loss: 0.0715 - accuracy: 0.9750\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 33s 738ms/step - loss: 0.0773 - accuracy: 0.9785\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 32s 696ms/step - loss: 0.0566 - accuracy: 0.9847\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 34s 754ms/step - loss: 0.0409 - accuracy: 0.9882\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 32s 716ms/step - loss: 0.0429 - accuracy: 0.9861\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 34s 761ms/step - loss: 0.0678 - accuracy: 0.9799\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 32s 710ms/step - loss: 0.0417 - accuracy: 0.9833\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 31s 684ms/step - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 29s 649ms/step - loss: 0.0393 - accuracy: 0.9868\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 34s 760ms/step - loss: 0.0427 - accuracy: 0.9826\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 32s 707ms/step - loss: 0.0514 - accuracy: 0.9812\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 35s 769ms/step - loss: 0.0788 - accuracy: 0.9729\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 35s 768ms/step - loss: 0.0418 - accuracy: 0.9847\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 35s 774ms/step - loss: 0.0197 - accuracy: 0.9924\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 36s 789ms/step - loss: 0.0212 - accuracy: 0.9944\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 36s 799ms/step - loss: 0.0203 - accuracy: 0.9917\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 36s 803ms/step - loss: 0.0229 - accuracy: 0.9937\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 36s 792ms/step - loss: 0.0339 - accuracy: 0.9861\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 36s 791ms/step - loss: 0.0512 - accuracy: 0.9799\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 36s 803ms/step - loss: 0.1667 - accuracy: 0.9340\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 37s 813ms/step - loss: 0.0529 - accuracy: 0.9861\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 37s 821ms/step - loss: 0.0231 - accuracy: 0.9917\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 37s 811ms/step - loss: 0.0237 - accuracy: 0.9931\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 36s 805ms/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 36s 784ms/step - loss: 0.0126 - accuracy: 0.9972\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 37s 819ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 36s 805ms/step - loss: 0.0247 - accuracy: 0.9896\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 36s 791ms/step - loss: 0.0297 - accuracy: 0.9903\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 34s 754ms/step - loss: 0.0124 - accuracy: 0.9951\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 30s 663ms/step - loss: 0.0405 - accuracy: 0.9875\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 30s 653ms/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 32s 716ms/step - loss: 0.0417 - accuracy: 0.9861\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.0239 - accuracy: 0.9903\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 30s 666ms/step - loss: 0.0320 - accuracy: 0.9896\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 31s 691ms/step - loss: 0.0148 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.0147 - accuracy: 0.9944\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 33s 727ms/step - loss: 0.0129 - accuracy: 0.9951\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 34s 743ms/step - loss: 0.0064 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 29s 644ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 32s 712ms/step - loss: 0.0519 - accuracy: 0.9847\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 31s 676ms/step - loss: 0.0274 - accuracy: 0.9937\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 34s 757ms/step - loss: 0.0217 - accuracy: 0.9958\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.0076 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 32s 697ms/step - loss: 0.0129 - accuracy: 0.9931\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 33s 727ms/step - loss: 0.0176 - accuracy: 0.9937\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 34s 754ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.0074 - accuracy: 0.9958\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 33s 727ms/step - loss: 0.0096 - accuracy: 0.9965\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 30s 660ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 32s 706ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 33s 721ms/step - loss: 0.0069 - accuracy: 0.9986\n",
      "10/10 [==============================] - 3s 246ms/step - loss: 0.5458 - accuracy: 0.8906\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.5458295345306396\n",
      "Test Accuracy: 0.890625\n",
      "10/10 [==============================] - 2s 217ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.1476 - accuracy: 0.9604\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.0826 - accuracy: 0.9674\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 32s 706ms/step - loss: 0.0755 - accuracy: 0.9743\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 30s 666ms/step - loss: 0.0539 - accuracy: 0.9806\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 30s 662ms/step - loss: 0.0297 - accuracy: 0.9910\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 33s 731ms/step - loss: 0.0553 - accuracy: 0.9806\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.0213 - accuracy: 0.9910\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 33s 729ms/step - loss: 0.0123 - accuracy: 0.9972\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.0123 - accuracy: 0.9958\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 30s 666ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 30s 659ms/step - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.0086 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 29s 629ms/step - loss: 0.0997 - accuracy: 0.9632\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0333 - accuracy: 0.9847\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 32s 703ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 30s 665ms/step - loss: 0.0073 - accuracy: 0.9972\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 30s 658ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 32s 704ms/step - loss: 0.0291 - accuracy: 0.9917\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0531 - accuracy: 0.9819\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0290 - accuracy: 0.9910\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 30s 669ms/step - loss: 0.0062 - accuracy: 0.9965\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.0071 - accuracy: 0.9972\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 30s 667ms/step - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 32s 701ms/step - loss: 0.0101 - accuracy: 0.9965\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 32s 700ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 33s 730ms/step - loss: 0.0198 - accuracy: 0.9931\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 30s 666ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 30s 672ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 30s 665ms/step - loss: 7.3338e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 32s 702ms/step - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 32s 715ms/step - loss: 0.0086 - accuracy: 0.9965\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 32s 704ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 32s 709ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 33s 740ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 31s 691ms/step - loss: 0.0072 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 31s 679ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 30s 659ms/step - loss: 0.0027 - accuracy: 0.9986\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 31s 694ms/step - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.1052 - accuracy: 0.9701\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 33s 739ms/step - loss: 0.0622 - accuracy: 0.9826\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 29s 629ms/step - loss: 0.0116 - accuracy: 0.9951\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.0171 - accuracy: 0.9951\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 30s 651ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.0111 - accuracy: 0.9951\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 32s 711ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 31s 691ms/step - loss: 0.0215 - accuracy: 0.9951\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 30s 657ms/step - loss: 0.0119 - accuracy: 0.9944\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 30s 658ms/step - loss: 0.0404 - accuracy: 0.9896\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.0251 - accuracy: 0.9903\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 32s 697ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 29s 638ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "10/10 [==============================] - 3s 249ms/step - loss: 0.2072 - accuracy: 0.9187\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.2071981132030487\n",
      "Test Accuracy: 0.918749988079071\n",
      "10/10 [==============================] - 2s 213ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 32s 698ms/step - loss: 0.0725 - accuracy: 0.9806\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 33s 735ms/step - loss: 0.0353 - accuracy: 0.9896\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 32s 713ms/step - loss: 0.0301 - accuracy: 0.9882\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 31s 694ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 28s 628ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 30s 659ms/step - loss: 0.0351 - accuracy: 0.9903\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 31s 687ms/step - loss: 0.0524 - accuracy: 0.9778\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 31s 688ms/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0354 - accuracy: 0.9903\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 31s 689ms/step - loss: 0.0146 - accuracy: 0.9944\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 30s 671ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 30s 665ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 32s 701ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 29s 647ms/step - loss: 0.0167 - accuracy: 0.9972\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0262 - accuracy: 0.9937\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 30s 674ms/step - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 29s 646ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 31s 674ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 30s 668ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 30s 651ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 31s 693ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 29s 644ms/step - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 31s 676ms/step - loss: 6.3939e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 30s 664ms/step - loss: 0.0188 - accuracy: 0.9931\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 29s 644ms/step - loss: 0.0360 - accuracy: 0.9896\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 31s 686ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 31s 684ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 30s 662ms/step - loss: 0.0073 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 28s 622ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 28s 609ms/step - loss: 0.0073 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 31s 689ms/step - loss: 0.0133 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 30s 670ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 31s 684ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 29s 643ms/step - loss: 0.0242 - accuracy: 0.9944\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 33s 738ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.0822 - accuracy: 0.9722\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 29s 633ms/step - loss: 0.0436 - accuracy: 0.9861\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 31s 689ms/step - loss: 0.0118 - accuracy: 0.9972\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 29s 631ms/step - loss: 0.0071 - accuracy: 0.9972\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 30s 668ms/step - loss: 7.8739e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 29s 639ms/step - loss: 8.2396e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 5.1009e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 31s 690ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 31s 690ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 31s 679ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 30s 657ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 31s 694ms/step - loss: 0.0049 - accuracy: 0.9972\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 32s 712ms/step - loss: 3.6929e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.0197 - accuracy: 0.9906\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.019687986001372337\n",
      "Test Accuracy: 0.9906250238418579\n",
      "10/10 [==============================] - 2s 148ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0251 - accuracy: 0.9944\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 34s 759ms/step - loss: 0.0290 - accuracy: 0.9924\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 34s 744ms/step - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 34s 741ms/step - loss: 0.0124 - accuracy: 0.9944\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 33s 734ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 33s 738ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 36s 801ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 35s 769ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.0099 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 32s 712ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 37s 811ms/step - loss: 0.0038 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 34s 754ms/step - loss: 4.7744e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 32s 714ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 33s 734ms/step - loss: 0.0115 - accuracy: 0.9972\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.0093 - accuracy: 0.9986\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 35s 764ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 38s 830ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 35s 776ms/step - loss: 9.1859e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 36s 798ms/step - loss: 3.3509e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 34s 759ms/step - loss: 3.9555e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 36s 805ms/step - loss: 6.2111e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 35s 768ms/step - loss: 0.0039 - accuracy: 0.9979\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 32s 702ms/step - loss: 0.0119 - accuracy: 0.9951\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 31s 679ms/step - loss: 0.1096 - accuracy: 0.9736\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 32s 716ms/step - loss: 0.0462 - accuracy: 0.9819\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.0263 - accuracy: 0.9931\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 33s 740ms/step - loss: 0.0131 - accuracy: 0.9951\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 34s 741ms/step - loss: 0.0162 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 32s 709ms/step - loss: 0.0112 - accuracy: 0.9937\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 32s 704ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 31s 675ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 31s 692ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 35s 775ms/step - loss: 9.7924e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 4.7918e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 31s 695ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 31s 684ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 33s 739ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 32s 710ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 32s 707ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 31s 681ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 31s 687ms/step - loss: 0.0059 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 35s 771ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 30s 651ms/step - loss: 0.0019 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 31s 676ms/step - loss: 0.0361 - accuracy: 0.9861\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.0934 - accuracy: 0.9729\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 32s 699ms/step - loss: 0.0354 - accuracy: 0.9889\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 31s 694ms/step - loss: 0.0105 - accuracy: 0.9944\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 33s 741ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 33s 719ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 33s 731ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 34s 760ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 36s 795ms/step - loss: 0.0108 - accuracy: 0.9979\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 35s 782ms/step - loss: 0.0160 - accuracy: 0.9979\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 37s 810ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 35s 783ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 37s 811ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 36s 794ms/step - loss: 7.2270e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0051 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.005088483449071646\n",
      "Test Accuracy: 0.996874988079071\n",
      "10/10 [==============================] - 3s 333ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Fold  Accuracy  Precision   Recall  F1 Score\n",
      "0     1  0.684375   0.715328  0.61250  0.659933\n",
      "1     2  0.890625   0.857143  0.93750  0.895522\n",
      "2     3  0.918750   0.889535  0.95625  0.921687\n",
      "3     4  0.990625   1.000000  0.98125  0.990536\n",
      "4     5  0.996875   1.000000  0.99375  0.996865\n",
      "Precision List: [0.7153284671532847, 0.8571428571428571, 0.8895348837209303, 1.0, 1.0]\n",
      "Recall List: [0.6125, 0.9375, 0.95625, 0.98125, 0.99375]\n",
      "F1 List: [0.6599326599326599, 0.8955223880597014, 0.9216867469879518, 0.9905362776025236, 0.9968652037617556]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "           Worst Fold  Avg. Fold  Best Fold\n",
      "Metric                                     \n",
      "F1 Score     0.659933   0.892909   0.996865\n",
      "Precision    0.715328   0.892401   1.000000\n",
      "Recall       0.612500   0.896250   0.993750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 6):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 6), 3),\n",
    "    'Metric': ['Precision'] * 5 + ['Recall'] * 5 + ['F1 Score'] * 5,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 5-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "           Worst Fold  Avg. Fold  Best Fold\n",
      "Metric                                     \n",
      "Accuracy     0.684375   0.896250   0.996875\n",
      "F1 Score     0.659933   0.892909   0.996865\n",
      "Precision    0.715328   0.892401   1.000000\n",
      "Recall       0.612500   0.896250   0.993750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Data\n",
    "accuracy_list = [0.684375, 0.890625, 0.918750, 0.990625, 0.996875]  # Replace with your actual accuracy values\n",
    "precision_list = [0.7153284671532847, 0.8571428571428571, 0.8895348837209303, 1.0, 1.0]\n",
    "recall_list = [0.6125, 0.9375, 0.95625, 0.98125, 0.99375]\n",
    "f1_list = [0.6599326599326599, 0.8955223880597014, 0.9216867469879518, 0.9905362776025236, 0.9968652037617556]\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score across 5-Folds')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 6), 3),\n",
    "    'Metric': ['Precision'] * 5 + ['Recall'] * 5 + ['F1 Score'] * 5,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 10-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-13-23:\n",
    "Save Model Checkpoints:\n",
    "SCRIPT BELOW CAN BE USED FOR INDEPDENT FOLDS (5 10, ANY)\n",
    "10 folds INDEPENDENT OF 5 FOLDS\n",
    "Investigate and implement a mechanism to save model checkpoints during training, ensuring essential information is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 17:59:54.000776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 31s 632ms/step - loss: 0.8856 - accuracy: 0.6160\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 32s 704ms/step - loss: 0.5477 - accuracy: 0.7132\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 32s 714ms/step - loss: 0.5211 - accuracy: 0.7257\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 28s 633ms/step - loss: 0.4570 - accuracy: 0.7667\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.4399 - accuracy: 0.7861\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 24s 522ms/step - loss: 0.5279 - accuracy: 0.7271\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.4070 - accuracy: 0.8083\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.3494 - accuracy: 0.8375\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.3101 - accuracy: 0.8521\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.2906 - accuracy: 0.8646\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.2865 - accuracy: 0.8632\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.2530 - accuracy: 0.8896\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.2064 - accuracy: 0.9076\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.2374 - accuracy: 0.9028\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.2082 - accuracy: 0.9139\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.1548 - accuracy: 0.9375\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.1600 - accuracy: 0.9292\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.1360 - accuracy: 0.9396\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.1455 - accuracy: 0.9465\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.1577 - accuracy: 0.9403\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.1442 - accuracy: 0.9417\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.1563 - accuracy: 0.9243\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.1278 - accuracy: 0.9514\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0900 - accuracy: 0.9681\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0785 - accuracy: 0.9694\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.0648 - accuracy: 0.9792\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0501 - accuracy: 0.9812\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0735 - accuracy: 0.9785\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0818 - accuracy: 0.9688\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0607 - accuracy: 0.9806\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0487 - accuracy: 0.9826\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0531 - accuracy: 0.9785\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.1833 - accuracy: 0.9333\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0898 - accuracy: 0.9688\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0546 - accuracy: 0.9819\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0595 - accuracy: 0.9771\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 23s 500ms/step - loss: 0.0335 - accuracy: 0.9903\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0319 - accuracy: 0.9882\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0410 - accuracy: 0.9854\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0250 - accuracy: 0.9944\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0424 - accuracy: 0.9833\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.1277 - accuracy: 0.9542\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.1017 - accuracy: 0.9729\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0518 - accuracy: 0.9819\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0541 - accuracy: 0.9792\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0555 - accuracy: 0.9826\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0427 - accuracy: 0.9861\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0239 - accuracy: 0.9944\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0865 - accuracy: 0.9715\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0454 - accuracy: 0.9861\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0188 - accuracy: 0.9944\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0218 - accuracy: 0.9917\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0288 - accuracy: 0.9903\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0630 - accuracy: 0.9833\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0203 - accuracy: 0.9924\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0568 - accuracy: 0.9847\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0771 - accuracy: 0.9694\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0291 - accuracy: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:25:53.018120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 141ms/step - loss: 3.1990 - accuracy: 0.6469\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 3.199042558670044\n",
      "Test Accuracy: 0.6468750238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:25:54.728585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 138ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:25:57.557459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 397ms/step - loss: 0.2133 - accuracy: 0.9431\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1091 - accuracy: 0.9653\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0843 - accuracy: 0.9708\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0584 - accuracy: 0.9799\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0426 - accuracy: 0.9861\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0416 - accuracy: 0.9868\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0410 - accuracy: 0.9889\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.1390 - accuracy: 0.9569\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0383 - accuracy: 0.9840\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0242 - accuracy: 0.9917\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0194 - accuracy: 0.9944\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0260 - accuracy: 0.9917\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0238 - accuracy: 0.9910\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0279 - accuracy: 0.9917\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0582 - accuracy: 0.9833\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0759 - accuracy: 0.9771\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1067 - accuracy: 0.9597\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0092 - accuracy: 0.9979\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0184 - accuracy: 0.9951\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0179 - accuracy: 0.9931\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0395 - accuracy: 0.9868\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0168 - accuracy: 0.9951\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0138 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0060 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0888 - accuracy: 0.9778\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0368 - accuracy: 0.9840\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1107 - accuracy: 0.9694\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.2907 - accuracy: 0.9014\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.1027 - accuracy: 0.9653\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0402 - accuracy: 0.9861\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0162 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0092 - accuracy: 0.9958\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0112 - accuracy: 0.9951\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0395 - accuracy: 0.9868\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0499 - accuracy: 0.9799\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.0231 - accuracy: 0.9910\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0370 - accuracy: 0.9868\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0441 - accuracy: 0.9868\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 9.3570e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:44:57.105860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 126ms/step - loss: 0.4884 - accuracy: 0.8938\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.4884452819824219\n",
      "Test Accuracy: 0.893750011920929\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:44:58.600388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 111ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 18:45:00.054912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1077 - accuracy: 0.9729\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0428 - accuracy: 0.9840\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0309 - accuracy: 0.9889\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0254 - accuracy: 0.9882\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0234 - accuracy: 0.9903\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0206 - accuracy: 0.9937\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0103 - accuracy: 0.9958\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0122 - accuracy: 0.9951\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0133 - accuracy: 0.9965\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0330 - accuracy: 0.9882\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0715 - accuracy: 0.9799\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0170 - accuracy: 0.9937\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0073 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0100 - accuracy: 0.9951\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0166 - accuracy: 0.9958\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0099 - accuracy: 0.9965\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0122 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0045 - accuracy: 0.9972\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0074 - accuracy: 0.9965\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0247 - accuracy: 0.9896\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0340 - accuracy: 0.9889\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0253 - accuracy: 0.9937\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0391 - accuracy: 0.9882\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0732 - accuracy: 0.9750\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0461 - accuracy: 0.9875\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.1235 - accuracy: 0.9597\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0946 - accuracy: 0.9625\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0261 - accuracy: 0.9903\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0124 - accuracy: 0.9979\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0401 - accuracy: 0.9924\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 20s 429ms/step - loss: 0.0182 - accuracy: 0.9931\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 20s 428ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0070 - accuracy: 0.9972\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 9.1464e-04 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 4.6489e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 8.0703e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:04:50.715191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 119ms/step - loss: 0.1747 - accuracy: 0.9563\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.17474359273910522\n",
      "Test Accuracy: 0.956250011920929\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:04:52.077321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 122ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:04:53.711289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 420ms/step - loss: 0.1113 - accuracy: 0.9708\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0782 - accuracy: 0.9778\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0484 - accuracy: 0.9847\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0119 - accuracy: 0.9972\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.2151 - accuracy: 0.9299\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.2235 - accuracy: 0.9125\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0561 - accuracy: 0.9764\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0408 - accuracy: 0.9868\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0230 - accuracy: 0.9896\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0171 - accuracy: 0.9937\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0108 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0305 - accuracy: 0.9882\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0225 - accuracy: 0.9917\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0211 - accuracy: 0.9917\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0131 - accuracy: 0.9937\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0067 - accuracy: 0.9986\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0112 - accuracy: 0.9972\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0113 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0184 - accuracy: 0.9924\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0154 - accuracy: 0.9944\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0106 - accuracy: 0.9958\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0176 - accuracy: 0.9931\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0208 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0604 - accuracy: 0.9785\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.1762 - accuracy: 0.9556\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0258 - accuracy: 0.9910\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0192 - accuracy: 0.9958\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0220 - accuracy: 0.9917\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0439 - accuracy: 0.9868\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0625 - accuracy: 0.9785\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0575 - accuracy: 0.9799\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0145 - accuracy: 0.9937\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0446 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:24:17.818428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 137ms/step - loss: 0.1061 - accuracy: 0.9781\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.10609368234872818\n",
      "Test Accuracy: 0.9781249761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:24:19.366105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 102ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:24:20.820722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0492 - accuracy: 0.9882\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0174 - accuracy: 0.9931\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0105 - accuracy: 0.9958\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0175 - accuracy: 0.9944\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0370 - accuracy: 0.9896\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.1310 - accuracy: 0.9625\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0378 - accuracy: 0.9882\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0088 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 5.7092e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 2.7965e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 3.6273e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 5.6666e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0106 - accuracy: 0.9958\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0704 - accuracy: 0.9792\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0085 - accuracy: 0.9979\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 5.8034e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0025 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0109 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0072 - accuracy: 0.9965\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0090 - accuracy: 0.9979\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 8.5755e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0076 - accuracy: 0.9965\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1156 - accuracy: 0.9701\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.1459 - accuracy: 0.9576\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.1222 - accuracy: 0.9611\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0573 - accuracy: 0.9812\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0048 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0020 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0062 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 3.4749e-04 - accuracy: 1.0000\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0011 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:43:43.369704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 143ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.01487732958048582\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:43:44.962602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 101ms/step\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 19:43:46.438381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0251 - accuracy: 0.9937\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0143 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0115 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0058 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0084 - accuracy: 0.9979\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.1282 - accuracy: 0.9674\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0372 - accuracy: 0.9896\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0368 - accuracy: 0.9889\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0112 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 4.4916e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 4.9662e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 6.9827e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 2.7640e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 2.8289e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 4.1994e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 7.3328e-04 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 5.3693e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 7.4994e-04 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0307 - accuracy: 0.9903\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0020 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 2.1609e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 8.9791e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 6.4690e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0076 - accuracy: 0.9972\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 9.4260e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 7.5212e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0099 - accuracy: 0.9965\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 4.8109e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:02:45.001140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 130ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 0.0063432990573346615\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:02:46.487063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 126ms/step\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:02:48.152829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1119 - accuracy: 0.9701\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0358 - accuracy: 0.9896\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.1294 - accuracy: 0.9778\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0824 - accuracy: 0.9785\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0904 - accuracy: 0.9792\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0142 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0245 - accuracy: 0.9903\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 7.4112e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0046 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 7.3490e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0121 - accuracy: 0.9986\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 6.4602e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 4.5179e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 3.9734e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 5.5109e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 3.9876e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 8.1499e-04 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 3.8677e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 3.9740e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 9.4001e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 5.7373e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 3.5312e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 3.4679e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 4.6134e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 9.8978e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 3.9156e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 9.7579e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 2.8950e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0134 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0097 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0129 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 7.8403e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 3.6416e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 2.7010e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 7.8759e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 2.1242e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 2.5893e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 1.2989e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 5.9627e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 7.7782e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:21:59.933751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0610 - accuracy: 0.9781\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 0.061038605868816376\n",
      "Test Accuracy: 0.9781249761581421\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:22:01.361316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 115ms/step\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:22:02.919422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0353 - accuracy: 0.9896\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.3027 - accuracy: 0.9403\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1649 - accuracy: 0.9368\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0281 - accuracy: 0.9944\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0085 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0149 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0307 - accuracy: 0.9944\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 8.0199e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 4.9600e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 1.4927e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 4.3600e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 2.6198e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 6.3803e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 8.1258e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 3.9232e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 5.0111e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 5.3393e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 2.3572e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 2.0068e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 9.8306e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0146 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0163 - accuracy: 0.9937\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0368 - accuracy: 0.9896\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0116 - accuracy: 0.9937\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0134 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 5.9367e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 4.6707e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0382 - accuracy: 0.9951\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0187 - accuracy: 0.9958\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0073 - accuracy: 0.9965\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0023 - accuracy: 0.9979\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 7.2993e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0128 - accuracy: 0.9979\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0107 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0122 - accuracy: 0.9972\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 3.3441e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 4.6497e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 3.5894e-04 - accuracy: 1.0000\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 2.0646e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:40:54.190096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 141ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 0.003148590447381139\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:40:55.778690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 124ms/step\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:40:57.391458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0264 - accuracy: 0.9924\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0335 - accuracy: 0.9875\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0102 - accuracy: 0.9937\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0180 - accuracy: 0.9937\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0138 - accuracy: 0.9951\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0026 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0058 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 9.3397e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0047 - accuracy: 0.9979\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 7.2504e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 7.7743e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.0018 - accuracy: 0.9986\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 3.2065e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 7.0101e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 1.2304e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 2.4796e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 2.1781e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 7.9360e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 1.7029e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 4.1952e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 5.8845e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 1.6234e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 5.4804e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0331 - accuracy: 0.9944\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1294 - accuracy: 0.9778\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0585 - accuracy: 0.9875\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.3939 - accuracy: 0.9347\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0413 - accuracy: 0.9882\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 8.3846e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 8.9568e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 9.4294e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 8.7158e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 8.8293e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 4.8074e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 7.0518e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 4.5353e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 8.3115e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 5.7137e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 5.7241e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 7.9548e-04 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 9.4508e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 2.5954e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 3.4323e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 9.2194e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 21:00:22.732102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 144ms/step - loss: 1.3031e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 0.00013030803529545665\n",
      "Test Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 21:00:24.370446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 99ms/step\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 21:00:25.770075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 413ms/step - loss: 4.8823e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 2.2007e-04 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 5.3677e-04 - accuracy: 1.0000\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0078 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 9.2144e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0086 - accuracy: 0.9965\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0010 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 3.0374e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 4.8322e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 6.6081e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 2.1385e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0019 - accuracy: 0.9986\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 6.9939e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 1.8394e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 4.0125e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 3.9008e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 9.1891e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 1.1590e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.1558e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 1.3596e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 3.5540e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.5055e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0018 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 2.2460e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 5.8812e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 3.9782e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 5.5619e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 7.9247e-04 - accuracy: 0.9993\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 9.6503e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 6.0291e-05 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 4.4972e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 7.0687e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 5.4266e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0349 - accuracy: 0.9924\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0115 - accuracy: 0.9965\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0020 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 21:19:16.153170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 121ms/step - loss: 1.9930e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 0.00019929904374293983\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 21:19:17.608352: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 101ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 146\u001b[0m\n\u001b[1;32m    143\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Summary table\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m df_summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_accuracies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecall_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1 Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_list\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Display the summary table\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary of Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# JUST TRY THIS ON ONE FOLD FIRST\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Load the saved model for testing\n",
    "    loaded_model = load_model(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "     # Save classification results to a file\n",
    "    results_filename = f'10fold_classification_results_fold_{fold_number}.txt'\n",
    "    with open(results_filename, 'w') as results_file:\n",
    "        results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "        for i in range(len(test_generator.filenames)):\n",
    "            image_name = os.path.basename(test_generator.filenames[i])\n",
    "            true_label = true_labels[i]\n",
    "            predicted_label = predicted_labels[i]\n",
    "            results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 10),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 11), 3),\n",
    "    'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 5-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-16-23\n",
    "10 fold based on 5 fold model (dependent training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:09:27.259848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 09:09:31.611620: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:09:38.517371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 34s 695ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 30s 656ms/step - loss: 0.0445 - accuracy: 0.9882\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0132 - accuracy: 0.9931\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 25s 542ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0058 - accuracy: 0.9972\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0060 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 7.5810e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 9.6498e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 4.5571e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0185 - accuracy: 0.9931\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0211 - accuracy: 0.9944\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0089 - accuracy: 0.9979\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 7.0906e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0113 - accuracy: 0.9972\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 5.1452e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0207 - accuracy: 0.9944\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0095 - accuracy: 0.9958\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0486 - accuracy: 0.9931\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0097 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 7.9461e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 4.8679e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 2.7489e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 2.5079e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 8.0206e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 5.7104e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0064 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 3.2526e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 4.3058e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 1.8389e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0019 - accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:29:57.879616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 0.0030971230007708073\n",
      "Test Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:29:59.463214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 112ms/step\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:30:00.998726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 9.9189e-04 - accuracy: 0.9993\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 2.3236e-04 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0021 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0411 - accuracy: 0.9882\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0133 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0339 - accuracy: 0.9910\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0052 - accuracy: 0.9972\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 5.6761e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0083 - accuracy: 0.9986\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0190 - accuracy: 0.9972\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 8.7054e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0337 - accuracy: 0.9924\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0107 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 3.6202e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 9.9068e-04 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 6.6535e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 6.6972e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 3.4242e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0531 - accuracy: 0.9854\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0268 - accuracy: 0.9896\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0080 - accuracy: 0.9993\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 6.6520e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 7.4171e-04 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 6.2113e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 8.6104e-04 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 5.0649e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 8.9375e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 3.9338e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 4.1209e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0018 - accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:49:01.019161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 131ms/step - loss: 9.0481e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 0.0009048145147971809\n",
      "Test Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:49:02.533114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 99ms/step\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 09:49:04.026164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0144 - accuracy: 0.9924\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0027 - accuracy: 0.9979\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0476 - accuracy: 0.9847\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0197 - accuracy: 0.9951\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0160 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 9.0674e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 4.4132e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 6.7689e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0041 - accuracy: 0.9972\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 6.0394e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0046 - accuracy: 0.9979\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0027 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 2.0500e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 5.9412e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 2.9245e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 3.0956e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0079 - accuracy: 0.9993\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0098 - accuracy: 0.9958\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0117 - accuracy: 0.9972\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0143 - accuracy: 0.9958\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0114 - accuracy: 0.9944\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0247 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 6.4987e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0161 - accuracy: 0.9958\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0073 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 8.8083e-04 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 7.8740e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 2.7789e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 5.0995e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 8.1088e-05 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.6715e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 9.5594e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 5.8490e-04 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 2.2153e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 6.5966e-05 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 2.7376e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 2.9093e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 5.4306e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:07:48.896775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 112ms/step - loss: 2.9920e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 2.9920463930466212e-05\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:07:50.236540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 118ms/step\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:07:51.825874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0338 - accuracy: 0.9917\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0240 - accuracy: 0.9951\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0248 - accuracy: 0.9951\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0156 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0233 - accuracy: 0.9958\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0050 - accuracy: 0.9972\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0184 - accuracy: 0.9965\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0165 - accuracy: 0.9965\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 7.9146e-04 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 6.1165e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 5.0041e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 3.9496e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 4.2216e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0020 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 5.4060e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 6.6293e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 3.3027e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 1.9525e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 1.4942e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.0043e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 5.5098e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 3.3178e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 1.1009e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 6.8580e-05 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 1.4024e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.0059e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 5.6805e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0593 - accuracy: 0.9896\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.2411 - accuracy: 0.9569\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.0311 - accuracy: 0.9903\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0611 - accuracy: 0.9854\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0489 - accuracy: 0.9917\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0186 - accuracy: 0.9951\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0069 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0061 - accuracy: 0.9965\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0010 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:26:46.093097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 129ms/step - loss: 4.4924e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 4.4924072426510975e-05\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:26:47.658016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 132ms/step\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:26:50.435852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 412ms/step - loss: 6.0836e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 4.4894e-04 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 3.2706e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 2.1021e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 1.0039e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 6.6640e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 2.8587e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 3.6838e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 1.4922e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 2.1423e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 1.5410e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 1.4341e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0010 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 2.9055e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 7.4598e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 2.9015e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 1.7022e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 4.2633e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 1.8631e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 5.0181e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0071 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 3.6539e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 1.7978e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 8.7543e-04 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 3.2452e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 3.2440e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0067 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0137 - accuracy: 0.9951\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0029 - accuracy: 0.9979\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 7.3040e-04 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 6.9741e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0089 - accuracy: 0.9958\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0109 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0051 - accuracy: 0.9972\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 3.9610e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 2.2554e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 7.7060e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0038 - accuracy: 0.9972\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0308 - accuracy: 0.9931\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0217 - accuracy: 0.9944\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:45:53.431123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 0.001363915391266346\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:45:54.846072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 95ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Summary table\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m df_summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_accuracies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecall_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1 Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_list\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Display the summary table\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary of Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split'\n",
    "\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Load the entire model from the file\n",
    "model = load_model('/home/wangg/REU-Hearing-Loss-Project-1/machine learning/checkpoint results/10 folds 80_20 split/dependentModel/model/10fold_model_fold_5.h5')\n",
    "\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# JUST TRY THIS ON ONE FOLD FIRST\n",
    "for fold_number in range(6, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Load the saved model for testing\n",
    "    loaded_model = load_model(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "     # Save classification results to a file\n",
    "    results_filename = f'10fold_classification_results_fold_{fold_number}.txt'\n",
    "    with open(results_filename, 'w') as results_file:\n",
    "        results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "        for i in range(len(test_generator.filenames)):\n",
    "            image_name = os.path.basename(test_generator.filenames[i])\n",
    "            true_label = true_labels[i]\n",
    "            predicted_label = predicted_labels[i]\n",
    "            results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 11),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(6, 11), 3),\n",
    "    'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 5-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print the current working directory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Working Directory:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults File Location:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[43mresults_filename\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_filename' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "print(\"Results File Location:\", os.path.abspath(results_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 10 Folds, 90% training, 10% testing split. (2 HI, 2 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:48:43.961558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:48:48.538831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 15:48:48.544169: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold1/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold1/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 686ms/step - loss: 0.9527 - accuracy: 0.5738\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.6354 - accuracy: 0.6350\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 43s 849ms/step - loss: 0.5676 - accuracy: 0.7050\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.5615 - accuracy: 0.7163\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 0.5057 - accuracy: 0.7563\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 0.4770 - accuracy: 0.7713\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 0.4707 - accuracy: 0.7688\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 32s 625ms/step - loss: 0.4360 - accuracy: 0.7775\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.3784 - accuracy: 0.8219\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 0.3640 - accuracy: 0.8294\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.3390 - accuracy: 0.8462\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.3053 - accuracy: 0.8500\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.2876 - accuracy: 0.8619\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 30s 588ms/step - loss: 0.2810 - accuracy: 0.8750\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 30s 588ms/step - loss: 0.2418 - accuracy: 0.8988\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.2086 - accuracy: 0.9069\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.1849 - accuracy: 0.9200\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.1835 - accuracy: 0.9237\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.1739 - accuracy: 0.9287\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.1300 - accuracy: 0.9538\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.1258 - accuracy: 0.9525\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.1000 - accuracy: 0.9644\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 0.1002 - accuracy: 0.9619\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 0.1088 - accuracy: 0.9556\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.1623 - accuracy: 0.9294\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.0649 - accuracy: 0.9744\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 0.0471 - accuracy: 0.9837\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 38s 748ms/step - loss: 0.0465 - accuracy: 0.9831\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 723ms/step - loss: 0.0390 - accuracy: 0.9894\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0323 - accuracy: 0.9875\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 32s 647ms/step - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0448 - accuracy: 0.9894\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0333 - accuracy: 0.9912\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0287 - accuracy: 0.9887\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.0342 - accuracy: 0.9894\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0367 - accuracy: 0.9881\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 30s 585ms/step - loss: 0.0152 - accuracy: 0.9931\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0044 - accuracy: 0.9981\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.1036 - accuracy: 0.9669\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0552 - accuracy: 0.9812\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0095 - accuracy: 0.9956\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0093 - accuracy: 0.9956\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0112 - accuracy: 0.9975\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0330 - accuracy: 0.9887\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0388 - accuracy: 0.9869\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 1.3622 - accuracy: 0.7312\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 1.362206220626831\n",
      "Test Accuracy: 0.731249988079071\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold2/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold2/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.1176 - accuracy: 0.9619\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0402 - accuracy: 0.9875\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0293 - accuracy: 0.9887\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0166 - accuracy: 0.9919\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0100 - accuracy: 0.9975\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 34s 669ms/step - loss: 0.0076 - accuracy: 0.9969\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0129 - accuracy: 0.9981\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 0.0263 - accuracy: 0.9900\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0085 - accuracy: 0.9981\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 35s 698ms/step - loss: 0.0054 - accuracy: 0.9994\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 8.6778e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0282 - accuracy: 0.9931\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 0.0187 - accuracy: 0.9925\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 0.0908 - accuracy: 0.9744\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 0.0328 - accuracy: 0.9881\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0172 - accuracy: 0.9950\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.0045 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0064 - accuracy: 0.9969\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 8.9350e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.3440e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 8.5047e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 5.6985e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 6.6165e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 564ms/step - loss: 4.8942e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 4.8522e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.3348e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.3997e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 3.8558e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 28s 568ms/step - loss: 0.0132 - accuracy: 0.9944\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0246 - accuracy: 0.9906\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0261 - accuracy: 0.9869\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 35s 691ms/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 0.0052 - accuracy: 0.9975\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2636 - accuracy: 0.9312\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.2636183202266693\n",
      "Test Accuracy: 0.9312499761581421\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold3/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold3/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0512 - accuracy: 0.9875\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0140 - accuracy: 0.9937\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 34s 676ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0097 - accuracy: 0.9981\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0162 - accuracy: 0.9944\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0097 - accuracy: 0.9956\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0201 - accuracy: 0.9912\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0098 - accuracy: 0.9981\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.0040 - accuracy: 0.9975\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0792 - accuracy: 0.9806\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0268 - accuracy: 0.9900\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0124 - accuracy: 0.9950\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 3.2297e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 9.2533e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 1.7515e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 3.3557e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 1.8291e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 5.0826e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 3.7885e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 1.8491e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.7358e-04 - accuracy: 0.9994\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0109 - accuracy: 0.9944\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0027 - accuracy: 0.9981\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0113 - accuracy: 0.9944\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 6.3260e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 3.7574e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0280 - accuracy: 0.9937\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.028017695993185043\n",
      "Test Accuracy: 0.9937499761581421\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold4/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold4/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0152 - accuracy: 0.9931\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0309 - accuracy: 0.9925\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 0.0060 - accuracy: 0.9969\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0217 - accuracy: 0.9956\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 35s 703ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0199 - accuracy: 0.9956\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 0.0044 - accuracy: 0.9969\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 566ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 2.5381e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 2.4105e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 5.9215e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 7.1794e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 3.9550e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 4.8054e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 1.9478e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 3.7180e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 2.5073e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 7.6613e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 9.2451e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 8.0212e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 1.2583e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 6.1018e-04 - accuracy: 0.9994\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 5.3141e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 5.2383e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 5.8874e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 2.6281e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 4.0437e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 8.5527e-04 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 2.4924e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 3.9824e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 7.7014e-04 - accuracy: 0.9994\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0046 - accuracy: 0.9981\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 0.0233 - accuracy: 0.9937\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 0.0141 - accuracy: 0.9956\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 0.0216 - accuracy: 0.9962\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0188 - accuracy: 0.9950\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 2.8576e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 4.6061e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 8.0059e-04 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 3.0390e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 1.0499e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 7.9683e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 2.5992e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 2.5991565053118393e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold5/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold5/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 5.4678e-04 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 5.1531e-05 - accuracy: 1.0000\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 2.4568e-04 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 6.8271e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 9.6474e-05 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 0.0091 - accuracy: 0.9987\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 7.5011e-04 - accuracy: 0.9994\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 0.0261 - accuracy: 0.9937\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 5.5301e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 1.6152e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 1.9142e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 1.2072e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 2.7737e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 3.8964e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.1044e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 1.2003e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0268 - accuracy: 0.9919\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0527 - accuracy: 0.9900\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 9.3953e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 7.5270e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.0036 - accuracy: 0.9981\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 4.5073e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 0.0129 - accuracy: 0.9975\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 35s 694ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 9.5915e-05 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 31s 619ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 36s 708ms/step - loss: 1.2711e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 7.1713e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 265ms/step - loss: 1.9932e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 1.993163095903583e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold6/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold6/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 0.0411 - accuracy: 0.9925\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 7.6048e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0054 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 7.9276e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 6.1653e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 6.4111e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.0447e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.2074e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 7.3788e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 2.0906e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 8.5449e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 6.8344e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 4.0619e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 5.1611e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 1.0618e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 5.3677e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 708ms/step - loss: 2.9994e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 3.9470e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 4.3739e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 1.6496e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 1.6341e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 8.2184e-04 - accuracy: 0.9994\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 2.7951e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 3.8546e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0120 - accuracy: 0.9975\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 2.3732e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 2.0393e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 4.6259e-05 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.7966e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 2.9781e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.6920e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 2.0768e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 1.2769e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 3.9592e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 8.4676e-05 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 1.1616e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 2.8765e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 2.3561e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.6957e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 1.3119e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 1.1711e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0250 - accuracy: 0.9956\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0039 - accuracy: 0.9981\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 6.7985e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 6.798455433454365e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold7/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold7/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.1062 - accuracy: 0.9756\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 33s 660ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 38s 745ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 8.2020e-04 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 1.6679e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 3.6984e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 5.2740e-05 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 2.6340e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 9.9302e-05 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 4.5787e-05 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 1.4849e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 3.4806e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 1.5977e-05 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 1.1239e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 1.9109e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 5.9920e-06 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.3723e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 4.8151e-06 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 1.2271e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 7.7432e-04 - accuracy: 0.9994\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 2.4979e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 1.0888e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 38s 749ms/step - loss: 2.7615e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 6.8246e-04 - accuracy: 0.9994\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 38s 746ms/step - loss: 4.9539e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 3.0397e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 1.1164e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 31s 607ms/step - loss: 3.6123e-05 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 1.4324e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 2.8352e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 1.1848e-05 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 3.2976e-06 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 5.8213e-06 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 1.4712e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.4605e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 1.8275e-06 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 3.1083e-06 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 5.0375e-06 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.9206e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 3.3417e-06 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.2057e-06 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 6.5537e-06 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 1.2876e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 4.9297e-07 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 6.2840e-05 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 1.5631e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 7.7627e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 4.8329e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 2.4720e-06 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 1.8577e-06 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 34s 676ms/step - loss: 2.6007e-06 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 5.2154e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 5.2154007335047936e-08\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold8/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold8/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.8146e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.3815e-04 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0148 - accuracy: 0.9962\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0201 - accuracy: 0.9969\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0528 - accuracy: 0.9937\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.1302 - accuracy: 0.9737\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 6.4786e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0043 - accuracy: 0.9981\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 38s 745ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 9.6421e-04 - accuracy: 0.9994\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 1.6085e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 1.1088e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 8.9105e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 2.3028e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 1.1271e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 3.2857e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 5.7814e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.3845e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.1551e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 28s 569ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0308 - accuracy: 0.9919\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 4.8328e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0049 - accuracy: 0.9975\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 8.2530e-04 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.8693e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 4.1950e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 2.2839e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 1.4807e-05 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.2305e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 3.1674e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 5.2586e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.5535e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.6415e-06 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 1.6795e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 3.9011e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 2.4892e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.6052e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 6.6296e-05 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 2.3227e-06 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 6.8916e-07 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 6.891584121149208e-07\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold9/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold9/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 1.2388e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 2.5787e-04 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 7.9892e-05 - accuracy: 1.0000\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 6.6395e-04 - accuracy: 0.9994\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.0089e-05 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 3.5276e-05 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.0037 - accuracy: 0.9975\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 9.9881e-04 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.9607e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 1.7363e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.7721e-04 - accuracy: 0.9994\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 1.5343e-05 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 5.2234e-05 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.3996e-05 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 1.5819e-05 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 5.7938e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 35s 697ms/step - loss: 8.3949e-06 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 2.4736e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 4.6256e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 5.2750e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 3.7050e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 37s 747ms/step - loss: 3.5168e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 1.4989e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 2.4062e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 2.6229e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 1.9517e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 8.6018e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0268 - accuracy: 0.9962\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0103 - accuracy: 0.9981\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 0.0041 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 5.1011e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 34s 667ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 6.9046e-06 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 1.4727e-05 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 8.2477e-06 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 5.5595e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 8.5760e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 564ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 1.0918e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 1.4051e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 6.8570e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0216 - accuracy: 0.9950\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 6.4820e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 6.481987213646789e-08\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold10/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold10/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 0.0015 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 38s 748ms/step - loss: 3.1859e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 1.7270e-05 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 9.1561e-05 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 38s 747ms/step - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 6.1992e-04 - accuracy: 0.9994\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 7.2511e-05 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0028 - accuracy: 0.9981\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 3.2768e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.5351e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 2.9279e-05 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 1.8252e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 5.4271e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 1.5062e-05 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 1.8042e-06 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.1120e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 9.1967e-07 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 3.2109e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 1.8848e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 6.5175e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 2.9259e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 7.2755e-07 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 1.7977e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 36s 705ms/step - loss: 6.4824e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 2.9863e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 6.7671e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.5643e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 2.1166e-06 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0107 - accuracy: 0.9981\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.2394 - accuracy: 0.9787\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0217 - accuracy: 0.9950\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0077 - accuracy: 0.9981\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 9.2193e-04 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 30s 585ms/step - loss: 1.0413e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 6.8035e-04 - accuracy: 0.9994\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 8.0534e-04 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 3.2815e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 4.4275e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 1.3813e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 1.9725e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 2.7357e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 3.3116e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 314ms/step - loss: 9.6857e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 9.685724222663339e-08\n",
      "Test Accuracy: 1.0\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.731249988079071\n",
      "Fold 2: 0.9312499761581421\n",
      "Fold 3: 0.9937499761581421\n",
      "Fold 4: 1.0\n",
      "Fold 5: 1.0\n",
      "Fold 6: 1.0\n",
      "Fold 7: 1.0\n",
      "Fold 8: 1.0\n",
      "Fold 9: 1.0\n",
      "Fold 10: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.9656249940395355\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.08073152242833005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 90-10 train test split'  # Change this to the root folder containing your k-fold data\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-5: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-5: {std_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each fold:\n",
      "Fold 1: 0.731249988079071\n",
      "Fold 2: 0.9312499761581421\n",
      "Fold 3: 0.9937499761581421\n",
      "Fold 4: 1.0\n",
      "Fold 5: 1.0\n",
      "Fold 6: 1.0\n",
      "Fold 7: 1.0\n",
      "Fold 8: 1.0\n",
      "Fold 9: 1.0\n",
      "Fold 10: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-10: 0.9656249940395355\n",
      "Standard Deviation of Accuracy across Folds 1-10: 0.08073152242833005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-10: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-10: {std_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 08:50:20.221559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 08:50:21.424675: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 08:50:21.970898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 22s 455ms/step - loss: 1.1955 - accuracy: 0.5861\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.5882 - accuracy: 0.6917\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.5616 - accuracy: 0.7097\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.5132 - accuracy: 0.7368\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.5000 - accuracy: 0.7451\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.4574 - accuracy: 0.7674\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.4044 - accuracy: 0.8056\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.3851 - accuracy: 0.8194\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.3388 - accuracy: 0.8500\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.3252 - accuracy: 0.8486\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.2766 - accuracy: 0.8750\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.2445 - accuracy: 0.8889\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.2271 - accuracy: 0.8965\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.2294 - accuracy: 0.8938\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.1876 - accuracy: 0.9215\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.1553 - accuracy: 0.9333\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.1589 - accuracy: 0.9389\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.1678 - accuracy: 0.9375\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.1263 - accuracy: 0.9528\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.1385 - accuracy: 0.9424\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.1051 - accuracy: 0.9597\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.1159 - accuracy: 0.9542\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0666 - accuracy: 0.9729\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0848 - accuracy: 0.9694\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.1248 - accuracy: 0.9542\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0631 - accuracy: 0.9757\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0495 - accuracy: 0.9833\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0628 - accuracy: 0.9806\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0491 - accuracy: 0.9826\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0668 - accuracy: 0.9785\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0869 - accuracy: 0.9674\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.1134 - accuracy: 0.9514\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.1543 - accuracy: 0.9424\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0623 - accuracy: 0.9771\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0548 - accuracy: 0.9764\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0326 - accuracy: 0.9889\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0408 - accuracy: 0.9854\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0370 - accuracy: 0.9868\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0517 - accuracy: 0.9792\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0390 - accuracy: 0.9868\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0586 - accuracy: 0.9812\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0410 - accuracy: 0.9889\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0395 - accuracy: 0.9868\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0663 - accuracy: 0.9729\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0434 - accuracy: 0.9847\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0318 - accuracy: 0.9861\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0286 - accuracy: 0.9937\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0254 - accuracy: 0.9889\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0274 - accuracy: 0.9882\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0429 - accuracy: 0.9875\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0725 - accuracy: 0.9792\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.1367 - accuracy: 0.9479\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0503 - accuracy: 0.9840\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0174 - accuracy: 0.9958\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0294 - accuracy: 0.9882\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0933 - accuracy: 0.9681\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1048 - accuracy: 0.9618\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 20s 429ms/step - loss: 0.0487 - accuracy: 0.9833\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0150 - accuracy: 0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:10:41.042728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 122ms/step - loss: 2.9407 - accuracy: 0.6531\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 2.940749406814575\n",
      "Test Accuracy: 0.653124988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:10:42.659712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 100ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:10:44.184680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 429ms/step - loss: 0.2519 - accuracy: 0.9215\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.1326 - accuracy: 0.9563\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1075 - accuracy: 0.9597\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0569 - accuracy: 0.9826\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0513 - accuracy: 0.9847\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0494 - accuracy: 0.9792\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0402 - accuracy: 0.9896\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0834 - accuracy: 0.9715\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0345 - accuracy: 0.9868\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0384 - accuracy: 0.9868\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0777 - accuracy: 0.9778\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0377 - accuracy: 0.9882\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0202 - accuracy: 0.9951\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0174 - accuracy: 0.9951\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0137 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0854 - accuracy: 0.9708\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0294 - accuracy: 0.9847\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0501 - accuracy: 0.9833\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0239 - accuracy: 0.9910\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0126 - accuracy: 0.9972\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0118 - accuracy: 0.9944\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0111 - accuracy: 0.9944\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0376 - accuracy: 0.9868\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.1939 - accuracy: 0.9368\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.1013 - accuracy: 0.9590\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0299 - accuracy: 0.9931\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0135 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0219 - accuracy: 0.9924\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0911 - accuracy: 0.9785\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0992 - accuracy: 0.9660\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0365 - accuracy: 0.9847\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0200 - accuracy: 0.9951\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0503 - accuracy: 0.9861\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0115 - accuracy: 0.9972\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0157 - accuracy: 0.9917\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0148 - accuracy: 0.9958\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0170 - accuracy: 0.9937\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0090 - accuracy: 0.9958\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0104 - accuracy: 0.9958\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0101 - accuracy: 0.9958\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0114 - accuracy: 0.9951\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0116 - accuracy: 0.9951\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0130 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0102 - accuracy: 0.9951\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0129 - accuracy: 0.9965\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0251 - accuracy: 0.9903\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1267 - accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:30:25.066791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 118ms/step - loss: 0.3828 - accuracy: 0.8750\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.3828320801258087\n",
      "Test Accuracy: 0.875\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:30:26.468603: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 111ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:30:27.924474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 20s 450ms/step - loss: 0.2297 - accuracy: 0.9264\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0648 - accuracy: 0.9743\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0367 - accuracy: 0.9903\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0393 - accuracy: 0.9868\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0332 - accuracy: 0.9903\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0299 - accuracy: 0.9910\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0166 - accuracy: 0.9965\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0280 - accuracy: 0.9889\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0290 - accuracy: 0.9910\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0129 - accuracy: 0.9965\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0101 - accuracy: 0.9979\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0178 - accuracy: 0.9931\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0140 - accuracy: 0.9944\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0487 - accuracy: 0.9847\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0736 - accuracy: 0.9778\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0456 - accuracy: 0.9840\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0173 - accuracy: 0.9931\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0142 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0281 - accuracy: 0.9882\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0132 - accuracy: 0.9958\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0092 - accuracy: 0.9951\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0140 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0321 - accuracy: 0.9903\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0156 - accuracy: 0.9944\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0126 - accuracy: 0.9944\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0289 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0324 - accuracy: 0.9903\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0257 - accuracy: 0.9875\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0758 - accuracy: 0.9785\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0807 - accuracy: 0.9757\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0180 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0066 - accuracy: 0.9965\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0189 - accuracy: 0.9924\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0370 - accuracy: 0.9882\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0518 - accuracy: 0.9882\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0502 - accuracy: 0.9854\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0539 - accuracy: 0.9868\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0373 - accuracy: 0.9861\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0088 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0055 - accuracy: 0.9972\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0096 - accuracy: 0.9958\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0047 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:50:32.904283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 143ms/step - loss: 0.1507 - accuracy: 0.9594\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.1507255733013153\n",
      "Test Accuracy: 0.9593750238418579\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:50:34.541187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 158ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold4/Training\n",
      "Found 1480 images belonging to 2 classes.\n",
      "Number of Training Samples: 1480\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold4/Testing\n",
      "Found 280 images belonging to 2 classes.\n",
      "Number of Test Samples: 280\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 09:50:37.298041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 20s 423ms/step - loss: 0.0842 - accuracy: 0.9751\n",
      "Epoch 2/60\n",
      "46/46 [==============================] - 20s 423ms/step - loss: 0.0317 - accuracy: 0.9890\n",
      "Epoch 3/60\n",
      "46/46 [==============================] - 19s 417ms/step - loss: 0.0443 - accuracy: 0.9890\n",
      "Epoch 4/60\n",
      "46/46 [==============================] - 20s 421ms/step - loss: 0.0158 - accuracy: 0.9938\n",
      "Epoch 5/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 6/60\n",
      "46/46 [==============================] - 20s 435ms/step - loss: 0.0232 - accuracy: 0.9938\n",
      "Epoch 7/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 0.0104 - accuracy: 0.9959\n",
      "Epoch 8/60\n",
      "46/46 [==============================] - 20s 435ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "46/46 [==============================] - 20s 427ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "46/46 [==============================] - 20s 426ms/step - loss: 0.0134 - accuracy: 0.9965\n",
      "Epoch 11/60\n",
      "46/46 [==============================] - 20s 433ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "46/46 [==============================] - 20s 433ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "46/46 [==============================] - 20s 427ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 7.6345e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0130 - accuracy: 0.9945\n",
      "Epoch 17/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0814 - accuracy: 0.9779\n",
      "Epoch 18/60\n",
      "46/46 [==============================] - 20s 430ms/step - loss: 0.2123 - accuracy: 0.9392\n",
      "Epoch 19/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 0.0282 - accuracy: 0.9903\n",
      "Epoch 20/60\n",
      "46/46 [==============================] - 20s 428ms/step - loss: 0.0170 - accuracy: 0.9931\n",
      "Epoch 21/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 0.0155 - accuracy: 0.9945\n",
      "Epoch 22/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 0.0195 - accuracy: 0.9924\n",
      "Epoch 23/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 0.0133 - accuracy: 0.9952\n",
      "Epoch 24/60\n",
      "46/46 [==============================] - 20s 433ms/step - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 25/60\n",
      "46/46 [==============================] - 20s 421ms/step - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 26/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0108 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "46/46 [==============================] - 20s 430ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 28/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0096 - accuracy: 0.9965\n",
      "Epoch 29/60\n",
      "46/46 [==============================] - 20s 425ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "46/46 [==============================] - 20s 442ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "46/46 [==============================] - 20s 423ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "46/46 [==============================] - 20s 428ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "46/46 [==============================] - 20s 422ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "46/46 [==============================] - 20s 426ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "46/46 [==============================] - 20s 431ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 36/60\n",
      "46/46 [==============================] - 20s 437ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 8.1374e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "46/46 [==============================] - 20s 437ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "46/46 [==============================] - 20s 439ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "46/46 [==============================] - 20s 423ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "46/46 [==============================] - 20s 431ms/step - loss: 8.4407e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "46/46 [==============================] - 19s 419ms/step - loss: 8.5900e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "46/46 [==============================] - 20s 436ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "46/46 [==============================] - 20s 430ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 0.0330 - accuracy: 0.9903\n",
      "Epoch 46/60\n",
      "46/46 [==============================] - 20s 427ms/step - loss: 0.0948 - accuracy: 0.9793\n",
      "Epoch 47/60\n",
      "46/46 [==============================] - 20s 425ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 48/60\n",
      "46/46 [==============================] - 19s 420ms/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 49/60\n",
      "46/46 [==============================] - 21s 444ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 50/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 51/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0086 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 0.0143 - accuracy: 0.9945\n",
      "Epoch 53/60\n",
      "46/46 [==============================] - 20s 429ms/step - loss: 0.0156 - accuracy: 0.9952\n",
      "Epoch 54/60\n",
      "46/46 [==============================] - 20s 422ms/step - loss: 0.0135 - accuracy: 0.9945\n",
      "Epoch 55/60\n",
      "46/46 [==============================] - 20s 427ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 56/60\n",
      "46/46 [==============================] - 20s 430ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "46/46 [==============================] - 20s 433ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "46/46 [==============================] - 20s 434ms/step - loss: 0.0069 - accuracy: 0.9965\n",
      "Epoch 59/60\n",
      "46/46 [==============================] - 20s 430ms/step - loss: 0.0148 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "46/46 [==============================] - 20s 432ms/step - loss: 0.0424 - accuracy: 0.9869\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 0.0092 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:11:01.320889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 130ms/step - loss: 0.1311 - accuracy: 0.9453\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.13105818629264832\n",
      "Test Accuracy: 0.9453125\n",
      "1/8 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:11:02.599039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 110ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [280, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_generator\u001b[38;5;241m.\u001b[39mlabels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_generator\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m test_generator\u001b[38;5;241m.\u001b[39mlabels\n\u001b[1;32m    105\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m precision, recall, f1, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Store the results for this fold\u001b[39;00m\n\u001b[1;32m    109\u001b[0m precision_list\u001b[38;5;241m.\u001b[39mappend(precision)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [280, 256]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# JUST TRY THIS ON ONE FOLD FIRST\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Load the saved model for testing\n",
    "    loaded_model = load_model(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "     # Save classification results to a file\n",
    "    results_filename = f'10fold_classification_results_fold_{fold_number}.txt'\n",
    "    with open(results_filename, 'w') as results_file:\n",
    "        results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "        for i in range(len(test_generator.filenames)):\n",
    "            image_name = os.path.basename(test_generator.filenames[i])\n",
    "            true_label = true_labels[i]\n",
    "            predicted_label = predicted_labels[i]\n",
    "            results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 10),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 11), 3),\n",
    "    'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 5-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:30:09.669338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 406ms/step - loss: 0.0506 - accuracy: 0.9847\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0577 - accuracy: 0.9826\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0727 - accuracy: 0.9799\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0275 - accuracy: 0.9910\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0217 - accuracy: 0.9917\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0139 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0064 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0339 - accuracy: 0.9861\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0604 - accuracy: 0.9889\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0372 - accuracy: 0.9882\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0050 - accuracy: 0.9979\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0098 - accuracy: 0.9965\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0458 - accuracy: 0.9868\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0711 - accuracy: 0.9785\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0809 - accuracy: 0.9764\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0560 - accuracy: 0.9833\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0057 - accuracy: 0.9972\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0027 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0074 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0259 - accuracy: 0.9917\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.2349 - accuracy: 0.9500\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0320 - accuracy: 0.9882\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0218 - accuracy: 0.9931\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0334 - accuracy: 0.9889\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0411 - accuracy: 0.9847\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 5.5936e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 7.2149e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0022 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:49:12.607036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 121ms/step - loss: 0.0114 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.011414186097681522\n",
      "Test Accuracy: 0.996874988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:49:14.137110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 126ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:49:15.831570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0420 - accuracy: 0.9889\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0981 - accuracy: 0.9674\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0445 - accuracy: 0.9854\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0109 - accuracy: 0.9951\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0236 - accuracy: 0.9944\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0096 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0117 - accuracy: 0.9944\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0024 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 6.1510e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0144 - accuracy: 0.9951\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0118 - accuracy: 0.9958\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0408 - accuracy: 0.9889\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0299 - accuracy: 0.9903\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0236 - accuracy: 0.9944\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.1267 - accuracy: 0.9674\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0669 - accuracy: 0.9819\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0136 - accuracy: 0.9944\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0050 - accuracy: 0.9979\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 3.8464e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 9.6713e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 3.9250e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 5.2763e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 1.3841e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0378 - accuracy: 0.9861\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0111 - accuracy: 0.9944\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0224 - accuracy: 0.9951\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0505 - accuracy: 0.9882\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0895 - accuracy: 0.9785\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0317 - accuracy: 0.9882\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0382 - accuracy: 0.9896\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0154 - accuracy: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:08:29.506927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0365 - accuracy: 0.9875\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.03649797663092613\n",
      "Test Accuracy: 0.987500011920929\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:08:31.099967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 99ms/step\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold6/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold6/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:08:32.575950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0182 - accuracy: 0.9931\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0108 - accuracy: 0.9944\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0115 - accuracy: 0.9972\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0045 - accuracy: 0.9972\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0330 - accuracy: 0.9868\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0747 - accuracy: 0.9792\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0064 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0175 - accuracy: 0.9965\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0100 - accuracy: 0.9944\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0313 - accuracy: 0.9903\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0428 - accuracy: 0.9896\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0150 - accuracy: 0.9958\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2952 - accuracy: 0.9382\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1334 - accuracy: 0.9576\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0201 - accuracy: 0.9903\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0110 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 9.3093e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 7.7654e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 6.2168e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 8.7439e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 3.4476e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 8.3730e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 6.8858e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 5.8391e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 2.9296e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0024 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0079 - accuracy: 0.9951\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0051 - accuracy: 0.9972\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 8.3139e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 2.7841e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 4.6354e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0012 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:27:47.366121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 134ms/step - loss: 0.0090 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 0.0090372608974576\n",
      "Test Accuracy: 0.996874988079071\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:27:48.930219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 102ms/step\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold7/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold7/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:27:50.401201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0090 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0193 - accuracy: 0.9910\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0404 - accuracy: 0.9854\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0149 - accuracy: 0.9931\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0135 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0056 - accuracy: 0.9972\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0174 - accuracy: 0.9931\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.1488 - accuracy: 0.9618\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.1440 - accuracy: 0.9569\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.1048 - accuracy: 0.9701\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0217 - accuracy: 0.9937\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 7.2641e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 9.1203e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 4.2189e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 8.8183e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 7.1775e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 7.5415e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0125 - accuracy: 0.9965\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0486 - accuracy: 0.9910\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0672 - accuracy: 0.9812\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0354 - accuracy: 0.9889\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0303 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0216 - accuracy: 0.9944\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0060 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 9.8927e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 4.7631e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0015 - accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:46:48.898468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 137ms/step - loss: 0.0270 - accuracy: 0.9937\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 0.0269752349704504\n",
      "Test Accuracy: 0.9937499761581421\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:46:50.473017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 110ms/step\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold8/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold8/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 11:46:51.995802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0083 - accuracy: 0.9986\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.1306 - accuracy: 0.9799\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0594 - accuracy: 0.9840\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0064 - accuracy: 0.9972\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 7.8728e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 6.4272e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 6.6645e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0029 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 6.8917e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 5.6025e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 5.5090e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 6.8532e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 5.7232e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 8.3543e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 2.5031e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 2.0734e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 9.5512e-04 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 4.0469e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0750 - accuracy: 0.9819\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0577 - accuracy: 0.9826\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0259 - accuracy: 0.9910\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0584 - accuracy: 0.9792\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0134 - accuracy: 0.9965\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0054 - accuracy: 0.9972\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 7.7291e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0046 - accuracy: 0.9979\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 8.1825e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 1.7586e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 9.9889e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 1.3990e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.1059 - accuracy: 0.9722\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0297 - accuracy: 0.9889\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 7.2587e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0067 - accuracy: 0.9972\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0140 - accuracy: 0.9972\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 3.7606e-04 - accuracy: 1.0000\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 0.0015 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:05:58.749324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 0.0028834848199039698\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:06:00.113396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 97ms/step\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold9/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold9/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:06:01.510857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0109 - accuracy: 0.9958\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0039 - accuracy: 0.9979\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0116 - accuracy: 0.9972\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0091 - accuracy: 0.9965\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0119 - accuracy: 0.9944\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0048 - accuracy: 0.9979\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0017 - accuracy: 0.9986\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 7.3902e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0109 - accuracy: 0.9958\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0144 - accuracy: 0.9951\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0050 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 7.0647e-04 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0099 - accuracy: 0.9965\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0742 - accuracy: 0.9819\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0973 - accuracy: 0.9826\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0109 - accuracy: 0.9951\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0197 - accuracy: 0.9965\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 6.0930e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 6.4337e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 8.3743e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 6.1244e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 3.7805e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 3.8305e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 5.0928e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 1.1341e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 5.2276e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 8.6457e-04 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 8.9558e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 6.4348e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0067 - accuracy: 0.9965\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0169 - accuracy: 0.9937\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0224 - accuracy: 0.9937\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0138 - accuracy: 0.9965\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0032 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 2.9955e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 7.6863e-05 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 4.3248e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 4.2727e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:25:16.617734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 127ms/step - loss: 8.6986e-06 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 8.69862469699001e-06\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:25:18.082151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 115ms/step\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold10/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)/fold10/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:25:19.613966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0176 - accuracy: 0.9965\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.2193 - accuracy: 0.9681\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.5523 - accuracy: 0.8764\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0988 - accuracy: 0.9660\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0226 - accuracy: 0.9917\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0106 - accuracy: 0.9979\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0049 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 5.0988e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 8.9913e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 2.8269e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 5.9118e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 4.3206e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 4.0737e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 1.4671e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 9.2528e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 2.8419e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0582 - accuracy: 0.9819\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0092 - accuracy: 0.9958\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0098 - accuracy: 0.9958\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 2.9330e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 8.0356e-04 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0026 - accuracy: 0.9979\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0024 - accuracy: 0.9979\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 7.8539e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 7.9024e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 5.1139e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 9.2973e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 2.9291e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 8.2894e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0033 - accuracy: 0.9972\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 4.1496e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 2.3684e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 8.0456e-04 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 4.5981e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 2.8811e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 1.2994e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 2.4331e-04 - accuracy: 1.0000\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 7.5623e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:44:23.223034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 137ms/step - loss: 1.4350e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 0.0001434986770618707\n",
      "Test Accuracy: 1.0\n",
      " 1/10 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:44:24.842138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 119ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Fold  Accuracy  Precision   Recall  F1 Score\n",
      "0     4  0.996875   0.993789  1.00000  0.996885\n",
      "1     5  0.987500   0.981481  0.99375  0.987578\n",
      "2     6  0.996875   1.000000  0.99375  0.996865\n",
      "3     7  0.993750   1.000000  0.98750  0.993711\n",
      "4     8  1.000000   1.000000  1.00000  1.000000\n",
      "5     9  1.000000   1.000000  1.00000  1.000000\n",
      "6    10  1.000000   1.000000  1.00000  1.000000\n",
      "Precision List: [0.9937888198757764, 0.9814814814814815, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Recall List: [1.0, 0.99375, 0.99375, 0.9875, 1.0, 1.0, 1.0]\n",
      "F1 List: [0.9968847352024921, 0.9875776397515528, 0.9968652037617556, 0.9937106918238994, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 175\u001b[0m\n\u001b[1;32m    172\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for easy summary and visualization\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m df_results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF1 Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecall_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf1_list\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Visualize the results with a single boxplot\u001b[39;00m\n\u001b[1;32m    182\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/REU-Hearing-Loss-Project/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project-1/machine learning/allFolds/10folds - 80-20 train test split (includes all subjects)'\n",
    "\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Load the entire model from the file\n",
    "model = load_model('/home/wangg/REU-Hearing-Loss-Project-1/machine learning/checkpoint results/10folds - 80-20 train test split (includes all subjects)/model/10fold_model_fold_3.h5')\n",
    "\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# JUST TRY THIS ON ONE FOLD FIRST\n",
    "for fold_number in range(4, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Load the saved model for testing\n",
    "    loaded_model = load_model(f'10fold_model_fold_{fold_number}.h5')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "     # Save classification results to a file\n",
    "    results_filename = f'10fold_classification_results_fold_{fold_number}.txt'\n",
    "    with open(results_filename, 'w') as results_file:\n",
    "        results_file.write(\"Image Name\\tTrue Label\\tPredicted Label\\n\")\n",
    "        for i in range(len(test_generator.filenames)):\n",
    "            image_name = os.path.basename(test_generator.filenames[i])\n",
    "            true_label = true_labels[i]\n",
    "            predicted_label = predicted_labels[i]\n",
    "            results_file.write(f\"{image_name}\\t{true_label}\\t{predicted_label}\\n\")\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(4, 11),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(4, 11), 3),\n",
    "    'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Visualize the results with a single boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Metric', y='Score', data=df_results)\n",
    "plt.title('Performance Across 5-Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('REU-Hearing-Loss-Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9362165e0877ffe35a450e3f6d34df4731e71258943496d98bc14a880fb264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
