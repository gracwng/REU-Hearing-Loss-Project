{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Specify the root directory containing the subfolders\n",
    "root_directory = '/Users/GraceWang/Desktop/UNLV2023/hearingLossOriginalCodebase/REU-Hearing-Loss-Project/machine learning/data split by subject'\n",
    "\n",
    "# Create a list of paths to the subfolders (classes)\n",
    "subfolder_paths = [os.path.join(root_directory, \"Healthy\"), os.path.join(root_directory, \"Hearing Impaired\")]\n",
    "\n",
    "# Combine the data paths and corresponding labels (0 for Healthy, 1 for Hearing Impaired)\n",
    "data_paths = []\n",
    "labels = []\n",
    "\n",
    "# Enumerate over subfolder_paths (0 for Healthy, 1 for Hearing Impaired)\n",
    "for label, subfolder_path in enumerate(subfolder_paths):\n",
    "    # Iterate over subject folders within each class\n",
    "    for subject_folder in os.listdir(subfolder_path):\n",
    "        # Construct the full path to the subject folder\n",
    "        subject_path = os.path.join(subfolder_path, subject_folder)\n",
    "        # Append the subject path to data_paths\n",
    "        data_paths.append(subject_path)\n",
    "        # Append the corresponding label to labels\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "data_paths = np.array(data_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Iterate over K folds\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(data_paths, labels)):\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Extract paths for training and testing\n",
    "    train_paths, test_paths = data_paths[train_indices], data_paths[test_indices]\n",
    "\n",
    "    # Define the number of healthy and unhealthy subjects for test\n",
    "    num_test_healthy = 2\n",
    "    num_test_unhealthy = 2\n",
    "\n",
    "    # Lists to store results for each fold\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Hold out different healthy and unhealthy subjects for each training and average the results\n",
    "    test_healthy_indices = np.random.choice(np.where(labels[test_indices] == 0)[0], num_test_healthy, replace=False)\n",
    "    test_unhealthy_indices = np.random.choice(np.where(labels[test_indices] == 1)[0], num_test_unhealthy, replace=False)\n",
    "    \n",
    "    test_subjects_indices = np.concatenate([test_healthy_indices, test_unhealthy_indices])\n",
    "    test_subjects_paths = test_paths[test_subjects_indices]\n",
    "\n",
    "    for test_subject_path in test_subjects_paths:\n",
    "        # Exclude the current test subject\n",
    "        train_paths_for_iteration = train_paths.copy()\n",
    "        train_paths_for_iteration = np.append(train_paths_for_iteration, test_subject_path)\n",
    "\n",
    "        # Create data generator for the current iteration\n",
    "        train_generator = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n",
    "            train_paths_for_iteration,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        # Clone the model to ensure a new instance is used for each training iteration\n",
    "        model = build_model((224, 224, 3))\n",
    "\n",
    "        # Train the model for the current iteration\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "            epochs=60)\n",
    "\n",
    "        # Evaluate the model on the test subjects for the current iteration\n",
    "        test_generator = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n",
    "            test_subject_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "        fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Average the accuracy results for the test subjects\n",
    "    fold_accuracy = np.mean(fold_accuracies)\n",
    "    print(f\"Average Accuracy for Fold {fold + 1}: {fold_accuracy}\")\n",
    "\n",
    "# Note: You may need to adjust the paths and other parameters based on your specific dataset structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 2\n",
      "List of subjects:\n",
      "['Healthy', 'Hearing Impaired']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mk_folds, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over K folds\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_indices, test_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(subjects, subjects)):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Create directories for train, validate, and test splits\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:370\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    368\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         (\n\u001b[1;32m    372\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    375\u001b[0m     )\n\u001b[1;32m    377\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    378\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=2."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Assuming data is organized as follows:\n",
    "# - Data split by subject folder\n",
    "#   - Healthy folder\n",
    "#     - Subject_001 folder\n",
    "#     - Subject_002 folder\n",
    "#     ...\n",
    "#   - Hearing Impaired folder\n",
    "#     - Subject_003 folder\n",
    "#     - Subject_004 folder\n",
    "#     ...\n",
    "\n",
    "# Specify the root directory containing the subfolders\n",
    "root_directory = '/Users/GraceWang/Desktop/UNLV2023/hearingLossOriginalCodebase/REU-Hearing-Loss-Project/machine learning/data split by subject'\n",
    "\n",
    "# Create a list of paths to the subfolders (classes)\n",
    "subfolder_paths = [os.path.join(root_directory, \"Healthy\"), os.path.join(root_directory, \"Hearing Impaired\")]\n",
    "\n",
    "# Combine the data paths and corresponding labels (0 for Healthy, 1 for Hearing Impaired)\n",
    "data_paths = []\n",
    "labels = []\n",
    "\n",
    "# Enumerate over subfolder_paths (0 for Healthy, 1 for Hearing Impaired)\n",
    "for label, subfolder_path in enumerate(subfolder_paths):\n",
    "    # Iterate over subject folders within each class\n",
    "    for subject_folder in os.listdir(subfolder_path):\n",
    "        # Construct the full path to the subject folder\n",
    "        subject_path = os.path.join(subfolder_path, subject_folder)\n",
    "        # Append the subject path to data_paths\n",
    "        data_paths.append(subject_path)        \n",
    "        # Append the corresponding label to labels\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert lists to arrays\n",
    "data_paths = np.array(data_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "# Iterate over K folds\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(data_paths, labels)):\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Extract paths for training and testing\n",
    "    train_paths, test_paths = data_paths[train_indices], data_paths[test_indices]\n",
    "\n",
    "    # Split the training set into training and validation sets\n",
    "    # train_paths, val_paths = train_test_split(train_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Dimensions of the images (224x224 with 3 channels)\n",
    "    img_width, img_height = 224, 224\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = build_model(input_shape)\n",
    "    model.summary()\n",
    "\n",
    "    # Data generators for training, validation, and testing\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_paths,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        test_paths,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // val_generator.batch_size)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Plotting the training and validation accuracy\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    y_true = val_generator.classes\n",
    "    y_pred = np.argmax(model.predict(val_generator), axis=-1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(val_generator.class_indices))\n",
    "    plt.xticks(tick_marks, val_generator.class_indices.keys(), rotation=45)\n",
    "    plt.yticks(tick_marks, val_generator.class_indices.keys())\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "    print(cm)\n",
    "\n",
    "    # Classification Report\n",
    "    class_names = list(val_generator.class_indices.keys())\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement the strategy of holding out different test subjects for each training and averaging the results, \n",
    "# you can modify the code within your k-fold cross-validation loop. Here's a modified version of your code to incorporate \n",
    "# this approach:\n",
    "\n",
    "\n",
    "# ... (Your previous code remains unchanged up to this point)\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the number of test subjects to hold out for evaluation\n",
    "num_test_subjects = 3\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "# Iterate over K folds\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(data_paths, labels)):\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Extract paths for training and testing\n",
    "    train_paths, test_paths = data_paths[train_indices], data_paths[test_indices]\n",
    "\n",
    "    # Hold out different test subjects for each training and average the results\n",
    "    test_subjects_indices = np.random.choice(len(test_paths), num_test_subjects, replace=False)\n",
    "    test_subjects_paths = test_paths[test_subjects_indices]\n",
    "\n",
    "    fold_accuracies_for_test_subjects = []\n",
    "\n",
    "    for test_subject_path in test_subjects_paths:\n",
    "        # Exclude the current test subject\n",
    "        train_paths_for_iteration = train_paths.copy()\n",
    "        train_paths_for_iteration = np.append(train_paths_for_iteration, test_subject_path)\n",
    "        \n",
    "        # Create data generators for the current iteration\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_paths_for_iteration,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        # Clone the model to ensure a new instance is used for each training iteration\n",
    "        model = build_model(input_shape)\n",
    "\n",
    "        # Train the model for the current iteration\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "            epochs=60)\n",
    "\n",
    "        # Evaluate the model on the test subjects for the current iteration\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            test_subject_path,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        test_loss, test_accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "        fold_accuracies_for_test_subjects.append(test_accuracy)\n",
    "\n",
    "    # Average the accuracy results for the test subjects\n",
    "    fold_accuracy = np.mean(fold_accuracies_for_test_subjects)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\nAverage Accuracy Across All Folds: {average_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
