{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 10 Folds, 80% training, 20% testing split. (4 HI, 4 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 05:08:13.379489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 05:08:15.379476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 05:08:15.386183: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 29s 610ms/step - loss: 1.3232 - accuracy: 0.5472\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.6130 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.5448 - accuracy: 0.7139\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.5083 - accuracy: 0.7382\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.4601 - accuracy: 0.7688\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.3982 - accuracy: 0.8090\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.3966 - accuracy: 0.7965\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.3511 - accuracy: 0.8285\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.3238 - accuracy: 0.8597\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.2771 - accuracy: 0.8743\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.2366 - accuracy: 0.8931\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.2636 - accuracy: 0.8813\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.2123 - accuracy: 0.9139\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.2019 - accuracy: 0.9153\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.1519 - accuracy: 0.9375\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.2108 - accuracy: 0.9118\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.1535 - accuracy: 0.9375\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.1204 - accuracy: 0.9535\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.1098 - accuracy: 0.9604\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.1282 - accuracy: 0.9486\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.2098 - accuracy: 0.9187\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.1243 - accuracy: 0.9556\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.1126 - accuracy: 0.9576\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.1199 - accuracy: 0.9563\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0820 - accuracy: 0.9653\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0903 - accuracy: 0.9667\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0902 - accuracy: 0.9625\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0748 - accuracy: 0.9715\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.1098 - accuracy: 0.9528\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0559 - accuracy: 0.9799\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0868 - accuracy: 0.9618\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0794 - accuracy: 0.9757\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0381 - accuracy: 0.9875\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0595 - accuracy: 0.9792\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0796 - accuracy: 0.9757\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0752 - accuracy: 0.9715\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0541 - accuracy: 0.9799\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0263 - accuracy: 0.9944\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0299 - accuracy: 0.9896\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0254 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0172 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0236 - accuracy: 0.9917\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.1393 - accuracy: 0.9597\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0408 - accuracy: 0.9868\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0394 - accuracy: 0.9882\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0453 - accuracy: 0.9833\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0251 - accuracy: 0.9931\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0169 - accuracy: 0.9931\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0295 - accuracy: 0.9924\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0703 - accuracy: 0.9736\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0213 - accuracy: 0.9931\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0306 - accuracy: 0.9910\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0377 - accuracy: 0.9917\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0580 - accuracy: 0.9806\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 3.1274 - accuracy: 0.6062\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 3.1273767948150635\n",
      "Test Accuracy: 0.606249988079071\n",
      "10/10 [==============================] - 2s 192ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.2718 - accuracy: 0.9229\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0944 - accuracy: 0.9646\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0802 - accuracy: 0.9722\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0724 - accuracy: 0.9729\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0544 - accuracy: 0.9819\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0417 - accuracy: 0.9854\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0253 - accuracy: 0.9910\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0163 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0453 - accuracy: 0.9840\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0398 - accuracy: 0.9875\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0598 - accuracy: 0.9792\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0482 - accuracy: 0.9812\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.0735 - accuracy: 0.9729\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0442 - accuracy: 0.9854\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0261 - accuracy: 0.9896\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0306 - accuracy: 0.9882\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0121 - accuracy: 0.9972\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0165 - accuracy: 0.9937\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0577 - accuracy: 0.9778\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0327 - accuracy: 0.9910\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0555 - accuracy: 0.9812\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0778 - accuracy: 0.9708\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0379 - accuracy: 0.9889\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0159 - accuracy: 0.9944\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0114 - accuracy: 0.9958\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.2201 - accuracy: 0.9410\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0985 - accuracy: 0.9639\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0245 - accuracy: 0.9931\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0258 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0068 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0051 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0300 - accuracy: 0.9931\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0090 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0257 - accuracy: 0.9937\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0227 - accuracy: 0.9937\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0313 - accuracy: 0.9896\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.0798 - accuracy: 0.9785\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0662 - accuracy: 0.9764\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0156 - accuracy: 0.9944\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.9624 - accuracy: 0.8562\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.9624485969543457\n",
      "Test Accuracy: 0.856249988079071\n",
      "10/10 [==============================] - 2s 205ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.1442 - accuracy: 0.9597\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0941 - accuracy: 0.9632\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0343 - accuracy: 0.9854\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0316 - accuracy: 0.9889\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0216 - accuracy: 0.9944\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0217 - accuracy: 0.9937\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0107 - accuracy: 0.9958\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0086 - accuracy: 0.9958\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0095 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.1623 - accuracy: 0.9674\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0422 - accuracy: 0.9861\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 6.4943e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0339 - accuracy: 0.9882\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.1940 - accuracy: 0.9535\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0504 - accuracy: 0.9799\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0237 - accuracy: 0.9910\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0114 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0202 - accuracy: 0.9965\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 24s 540ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0156 - accuracy: 0.9965\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0071 - accuracy: 0.9958\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.3520 - accuracy: 0.9031\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.35199588537216187\n",
      "Test Accuracy: 0.903124988079071\n",
      "10/10 [==============================] - 2s 189ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0425 - accuracy: 0.9882\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0131 - accuracy: 0.9944\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0223 - accuracy: 0.9896\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0085 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.1615 - accuracy: 0.9590\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0552 - accuracy: 0.9806\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0096 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0141 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0330 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0320 - accuracy: 0.9882\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0048 - accuracy: 0.9972\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0048 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0140 - accuracy: 0.9965\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0664 - accuracy: 0.9771\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0171 - accuracy: 0.9924\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0103 - accuracy: 0.9958\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 7.5669e-04 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 9.9703e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0309 - accuracy: 0.9931\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0367 - accuracy: 0.9882\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0436 - accuracy: 0.9861\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.3962 - accuracy: 0.9062\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.3961780071258545\n",
      "Test Accuracy: 0.90625\n",
      "10/10 [==============================] - 2s 217ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0120 - accuracy: 0.9944\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 9.4777e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 5.8247e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0056 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0062 - accuracy: 0.9972\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0060 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0149 - accuracy: 0.9965\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0131 - accuracy: 0.9965\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0111 - accuracy: 0.9972\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 7.8063e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 9.6342e-04 - accuracy: 0.9993\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 5.4044e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0075 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 1.4928e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0239 - accuracy: 0.9931\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0751 - accuracy: 0.9882\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0088 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0135 - accuracy: 0.9979\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 6.5079e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0073 - accuracy: 0.9958\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0028 - accuracy: 0.9979\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 7.7715e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 1.3331e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 3.1308e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 2.0198e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 1.8366e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.0010273780208081007\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 205ms/step\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold6/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0231 - accuracy: 0.9931\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0088 - accuracy: 0.9958\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0035 - accuracy: 0.9972\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 2.7494e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 4.1995e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 6.2680e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 3.1434e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 2.2479e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 4.2832e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 1.1173e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 2.8771e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 7.6939e-04 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 2.6788e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 1.0084e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 1.9828e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.6232e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 6.8759e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 5.8210e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 3.9211e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 4.5795e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 5.0184e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 2.3218e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 4.3941e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0045 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 4.9085e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 1.2422e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 2.1889e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 5.4873e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.0213e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0080 - accuracy: 0.9965\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0081 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0197 - accuracy: 0.9944\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0923 - accuracy: 0.9826\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0599 - accuracy: 0.9861\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0304 - accuracy: 0.9910\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0159 - accuracy: 0.9958\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0114 - accuracy: 0.9986\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.0067 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 0.006706621497869492\n",
      "Test Accuracy: 0.996874988079071\n",
      "10/10 [==============================] - 2s 196ms/step\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold7/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0073 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0020 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 4.4569e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0106 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0144 - accuracy: 0.9944\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0407 - accuracy: 0.9903\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0220 - accuracy: 0.9951\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 1.6605e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 1.4799e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 6.0322e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 1.2865e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 1.3863e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 5.3926e-04 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 2.3381e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 2.1904e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 2.0916e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 9.5250e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 2.0064e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 6.5376e-04 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0326 - accuracy: 0.9917\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0084 - accuracy: 0.9958\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 24s 524ms/step - loss: 5.3064e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0075 - accuracy: 0.9986\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.6979e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 1.6688e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 1.2531e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 1.1139e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.4943e-05 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 4.5171e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 7.1910e-05 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 2.3225e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 3.0088e-06 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 4.2227e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 28s 608ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0050 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 2.0741e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 8.4699e-05 - accuracy: 1.0000\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.1012 - accuracy: 0.9812\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 0.10119403898715973\n",
      "Test Accuracy: 0.981249988079071\n",
      "10/10 [==============================] - 2s 197ms/step\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold8/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.1388 - accuracy: 0.9736\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0325 - accuracy: 0.9937\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0137 - accuracy: 0.9951\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0120 - accuracy: 0.9972\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0260 - accuracy: 0.9944\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0596 - accuracy: 0.9917\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0201 - accuracy: 0.9958\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0044 - accuracy: 0.9972\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 9.8768e-04 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 1.7901e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 3.5677e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 2.3128e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 3.9119e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 3.0239e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 1.3321e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 1.2127e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 1.6311e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.2333e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 1.7216e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 5.1129e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 3.2349e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.7747e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 2.3690e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 9.6357e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 1.9944e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 8.3442e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 1.7125e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 2.9409e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 2.2505e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 5.4631e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 8.6580e-04 - accuracy: 0.9993\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 7.4036e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0380 - accuracy: 0.9944\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0389 - accuracy: 0.9903\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 8.2708e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 1.1664e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 7.7421e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 1.7008e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 5.8091e-04 - accuracy: 0.9993\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 2.5983e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 2.2866e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 24s 522ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 2.1087e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 0.00021087145432829857\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 142ms/step\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold9/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0153 - accuracy: 0.9965\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0518 - accuracy: 0.9896\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0057 - accuracy: 0.9958\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 2.9521e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 2.5368e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 4.2463e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 2.6318e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 3.5783e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 2.0730e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 9.4721e-04 - accuracy: 0.9993\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 7.2150e-05 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 3.3196e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 8.9548e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 6.6356e-04 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 2.7164e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 2.7678e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 5.3318e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 2.7578e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 7.2174e-06 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 3.1351e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 3.5377e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 2.8481e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 4.0806e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0103 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 9.0380e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 4.6870e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0404 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 9.9459e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 9.4020e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 2.2542e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 1.2009e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 1.0381e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.1366e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 6.6753e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 2.9600e-05 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 1.1252e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 1.6214e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 1.2019e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 6.1278e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 5.5392e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 3.3294e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0273 - accuracy: 0.9931\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0345 - accuracy: 0.9924\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 0.0040 - accuracy: 0.9969\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 0.003990915138274431\n",
      "Test Accuracy: 0.996874988079071\n",
      "10/10 [==============================] - 1s 136ms/step\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split/fold10/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0201 - accuracy: 0.9951\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0028 - accuracy: 0.9986\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0071 - accuracy: 0.9958\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 6.8516e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0061 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 8.5290e-05 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 5.0972e-04 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 6.7155e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 3.3346e-05 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 7.7327e-05 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.7410e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.1468e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 1.1135e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 7.6700e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 3.3628e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 4.6956e-06 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 1.2704e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 1.0487e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 2.4462e-04 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 1.6358e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 4.6326e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 9.7512e-06 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 6.6123e-06 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 9.9532e-06 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 5.2735e-06 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 2.5057e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 9.3295e-06 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 4.0107e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 7.5162e-06 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 1.2695e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 1.7537e-05 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 2.2147e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 1.4227e-05 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 6.2128e-06 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 28s 609ms/step - loss: 1.2353e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 5.9674e-05 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 2.6209e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 1.8943e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 8.0607e-06 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 6.4433e-06 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 3.9324e-06 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 3.0997e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 3.5876e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 6.9703e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 1.1384e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 8.3694e-07 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 2.5646e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 1.4737e-05 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 1.2173e-05 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0389 - accuracy: 0.9903\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0686 - accuracy: 0.9875\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 7.1481e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 0.0007148078875616193\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 144ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Fold  Accuracy  Precision   Recall  F1 Score\n",
      "0     1  0.606250   0.584158  0.73750  0.651934\n",
      "1     2  0.856250   0.959677  0.74375  0.838028\n",
      "2     3  0.903125   0.938776  0.86250  0.899023\n",
      "3     4  0.906250   0.911392  0.90000  0.905660\n",
      "4     5  1.000000   1.000000  1.00000  1.000000\n",
      "5     6  0.996875   1.000000  0.99375  0.996865\n",
      "6     7  0.981250   1.000000  0.96250  0.980892\n",
      "7     8  1.000000   1.000000  1.00000  1.000000\n",
      "8     9  0.996875   1.000000  0.99375  0.996865\n",
      "9    10  1.000000   1.000000  1.00000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 80-20 train test split'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 11),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision List: [0.5841584158415841, 0.9596774193548387, 0.9387755102040817, 0.9113924050632911, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Recall List: [0.7375, 0.74375, 0.8625, 0.9, 1.0, 0.99375, 0.9625, 1.0, 0.99375, 1.0]\n",
      "F1 List: [0.6519337016574586, 0.8380281690140845, 0.8990228013029318, 0.9056603773584907, 1.0, 0.9968652037617556, 0.980891719745223, 1.0, 0.9968652037617556, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "           Worst Fold  Avg. Fold  Best Fold\n",
      "Metric                                     \n",
      "F1 Score     0.651934   0.926927        1.0\n",
      "Precision    0.584158   0.939400        1.0\n",
      "Recall       0.737500   0.919375        1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easy summary and visualization\n",
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.repeat(range(1, 11), 3),\n",
    "    'Metric': ['Precision'] * 10 + ['Recall'] * 10 + ['F1 Score'] * 10,\n",
    "    'Score': precision_list + recall_list + f1_list\n",
    "})\n",
    "\n",
    "# Summary table\n",
    "summary_table = df_results.groupby('Metric')['Score'].describe()[['min', 'mean', 'max']]\n",
    "summary_table.columns = ['Worst Fold', 'Avg. Fold', 'Best Fold']\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(summary_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 5 Folds, 80% training, 20% testing split. (4 HI, 4 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 06:42:30.869819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 06:42:32.256520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 06:42:32.264014: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 444ms/step - loss: 0.8751 - accuracy: 0.5458\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.6165 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.5873 - accuracy: 0.6875\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.5554 - accuracy: 0.7139\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.5281 - accuracy: 0.7333\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.4543 - accuracy: 0.7785\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.4291 - accuracy: 0.7840\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.5549 - accuracy: 0.7035\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.4563 - accuracy: 0.7701\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.3812 - accuracy: 0.8139\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.3230 - accuracy: 0.8396\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3139 - accuracy: 0.8604\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3086 - accuracy: 0.8618\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.2662 - accuracy: 0.8792\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.2653 - accuracy: 0.8854\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.2436 - accuracy: 0.8944\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2320 - accuracy: 0.8924\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.1933 - accuracy: 0.9181\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2012 - accuracy: 0.9104\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1843 - accuracy: 0.9333\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.1646 - accuracy: 0.9340\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.1567 - accuracy: 0.9340\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1466 - accuracy: 0.9410\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.1476 - accuracy: 0.9354\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1469 - accuracy: 0.9389\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.1324 - accuracy: 0.9431\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.1222 - accuracy: 0.9514\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.1019 - accuracy: 0.9611\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.1123 - accuracy: 0.9556\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 20s 432ms/step - loss: 0.0887 - accuracy: 0.9660\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0963 - accuracy: 0.9625\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1615 - accuracy: 0.9396\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.1103 - accuracy: 0.9563\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.1116 - accuracy: 0.9597\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0974 - accuracy: 0.9653\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0879 - accuracy: 0.9715\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.1117 - accuracy: 0.9576\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0727 - accuracy: 0.9743\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0651 - accuracy: 0.9736\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0892 - accuracy: 0.9604\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0692 - accuracy: 0.9743\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0882 - accuracy: 0.9694\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0669 - accuracy: 0.9757\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0606 - accuracy: 0.9792\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0613 - accuracy: 0.9833\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0791 - accuracy: 0.9708\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0517 - accuracy: 0.9826\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0371 - accuracy: 0.9917\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0311 - accuracy: 0.9882\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0429 - accuracy: 0.9861\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0291 - accuracy: 0.9903\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0497 - accuracy: 0.9819\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0386 - accuracy: 0.9889\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0402 - accuracy: 0.9847\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0213 - accuracy: 0.9951\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0325 - accuracy: 0.9882\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.1109 - accuracy: 0.9549\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0681 - accuracy: 0.9715\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0325 - accuracy: 0.9868\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 2.6364 - accuracy: 0.6562\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 2.636406898498535\n",
      "Test Accuracy: 0.65625\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.3207 - accuracy: 0.8903\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.1837 - accuracy: 0.9333\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.1134 - accuracy: 0.9583\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0824 - accuracy: 0.9743\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0877 - accuracy: 0.9694\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.1012 - accuracy: 0.9688\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0566 - accuracy: 0.9833\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0330 - accuracy: 0.9917\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0460 - accuracy: 0.9840\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0489 - accuracy: 0.9819\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0273 - accuracy: 0.9889\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0359 - accuracy: 0.9910\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0371 - accuracy: 0.9931\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0162 - accuracy: 0.9917\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0618 - accuracy: 0.9819\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0719 - accuracy: 0.9861\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0351 - accuracy: 0.9854\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0221 - accuracy: 0.9896\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0374 - accuracy: 0.9896\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0417 - accuracy: 0.9861\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0240 - accuracy: 0.9937\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0449 - accuracy: 0.9854\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0153 - accuracy: 0.9931\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0305 - accuracy: 0.9903\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0213 - accuracy: 0.9917\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0099 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0314 - accuracy: 0.9868\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0402 - accuracy: 0.9840\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0151 - accuracy: 0.9937\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0103 - accuracy: 0.9972\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0154 - accuracy: 0.9937\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0174 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0151 - accuracy: 0.9958\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0396 - accuracy: 0.9833\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0284 - accuracy: 0.9889\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0307 - accuracy: 0.9889\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0096 - accuracy: 0.9958\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0138 - accuracy: 0.9944\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0164 - accuracy: 0.9924\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0161 - accuracy: 0.9937\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0141 - accuracy: 0.9924\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0095 - accuracy: 0.9951\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0148 - accuracy: 0.9972\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.4543 - accuracy: 0.8844\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.4542678892612457\n",
      "Test Accuracy: 0.8843749761581421\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.1744 - accuracy: 0.9479\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0520 - accuracy: 0.9806\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0276 - accuracy: 0.9917\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0169 - accuracy: 0.9937\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0197 - accuracy: 0.9924\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0163 - accuracy: 0.9924\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0258 - accuracy: 0.9937\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0114 - accuracy: 0.9951\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0139 - accuracy: 0.9944\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0060 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0243 - accuracy: 0.9903\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0230 - accuracy: 0.9924\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0051 - accuracy: 0.9972\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0473 - accuracy: 0.9882\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0567 - accuracy: 0.9875\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0104 - accuracy: 0.9951\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0180 - accuracy: 0.9958\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0102 - accuracy: 0.9979\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 8.6504e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 5.9666e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0208 - accuracy: 0.9910\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0128 - accuracy: 0.9951\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0162 - accuracy: 0.9965\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0117 - accuracy: 0.9986\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0186 - accuracy: 0.9937\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0166 - accuracy: 0.9965\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0315 - accuracy: 0.9861\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0246 - accuracy: 0.9937\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0424 - accuracy: 0.9847\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3166 - accuracy: 0.8875\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.31663310527801514\n",
      "Test Accuracy: 0.887499988079071\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0571 - accuracy: 0.9812\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0203 - accuracy: 0.9924\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0197 - accuracy: 0.9931\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0376 - accuracy: 0.9868\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0305 - accuracy: 0.9931\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0143 - accuracy: 0.9958\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0096 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0161 - accuracy: 0.9931\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0095 - accuracy: 0.9965\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0166 - accuracy: 0.9958\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0102 - accuracy: 0.9979\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0154 - accuracy: 0.9937\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0149 - accuracy: 0.9979\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0047 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0162 - accuracy: 0.9937\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0093 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0417 - accuracy: 0.9882\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0170 - accuracy: 0.9965\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0335 - accuracy: 0.9924\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0142 - accuracy: 0.9972\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0073 - accuracy: 0.9965\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0098 - accuracy: 0.9965\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0090 - accuracy: 0.9951\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 6.9084e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0011 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 6.7861e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0390 - accuracy: 0.9812\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.03903304785490036\n",
      "Test Accuracy: 0.981249988079071\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0463 - accuracy: 0.9868\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0180 - accuracy: 0.9924\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0188 - accuracy: 0.9958\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0143 - accuracy: 0.9944\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0024 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 8.8664e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 9.0243e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 7.2921e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 6.3062e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0556 - accuracy: 0.9896\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0632 - accuracy: 0.9806\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0087 - accuracy: 0.9958\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0151 - accuracy: 0.9937\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0169 - accuracy: 0.9931\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0029 - accuracy: 0.9979\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0153 - accuracy: 0.9958\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0599 - accuracy: 0.9812\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0516 - accuracy: 0.9861\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0195 - accuracy: 0.9944\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0316 - accuracy: 0.9910\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0059 - accuracy: 0.9972\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 5.7248e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 5.3881e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 5.7841e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 6.9475e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 1.1409e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0025 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 7.1108e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 5.9546e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.0005954562220722437\n",
      "Test Accuracy: 1.0\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.65625\n",
      "Fold 2: 0.8843749761581421\n",
      "Fold 3: 0.887499988079071\n",
      "Fold 4: 0.981249988079071\n",
      "Fold 5: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.8818749904632568\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.12228935757243639\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.65625\n",
      "Fold 2: 0.8843749761581421\n",
      "Fold 3: 0.887499988079071\n",
      "Fold 4: 0.981249988079071\n",
      "Fold 5: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.8818749904632568\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.12228935757243639\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'  # Change this to the root folder containing your k-fold data\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 6):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-5: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-5: {std_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below is for K fold: 5 folds, 80%-20% train/test split, but it includes evluation metrics, boxplot and summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 16:42:35.995061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 16:42:37.173100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 16:42:37.180220: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold1/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 24s 500ms/step - loss: 1.0862 - accuracy: 0.5931\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.6127 - accuracy: 0.6729\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.5982 - accuracy: 0.6722\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.5538 - accuracy: 0.7083\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.5230 - accuracy: 0.7271\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.4921 - accuracy: 0.7667\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.4280 - accuracy: 0.7951\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.4330 - accuracy: 0.7771\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.3521 - accuracy: 0.8271\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.3236 - accuracy: 0.8444\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.3199 - accuracy: 0.8542\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.3214 - accuracy: 0.8507\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.2625 - accuracy: 0.8743\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.2756 - accuracy: 0.8764\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.2186 - accuracy: 0.9062\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.2032 - accuracy: 0.9090\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.2148 - accuracy: 0.9118\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.1672 - accuracy: 0.9299\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.1889 - accuracy: 0.9236\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.1932 - accuracy: 0.9187\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.1866 - accuracy: 0.9146\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.1469 - accuracy: 0.9451\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.1200 - accuracy: 0.9535\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.1117 - accuracy: 0.9507\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.1137 - accuracy: 0.9597\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.2020 - accuracy: 0.9208\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.1197 - accuracy: 0.9549\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0725 - accuracy: 0.9743\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.1153 - accuracy: 0.9597\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.1316 - accuracy: 0.9549\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.2601 - accuracy: 0.9118\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.1255 - accuracy: 0.9514\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.1494 - accuracy: 0.9403\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.1037 - accuracy: 0.9590\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0791 - accuracy: 0.9722\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0735 - accuracy: 0.9708\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0929 - accuracy: 0.9625\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0565 - accuracy: 0.9806\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0552 - accuracy: 0.9812\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0969 - accuracy: 0.9618\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0701 - accuracy: 0.9785\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0975 - accuracy: 0.9646\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.1244 - accuracy: 0.9500\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0732 - accuracy: 0.9729\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0973 - accuracy: 0.9722\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0531 - accuracy: 0.9806\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0665 - accuracy: 0.9764\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0460 - accuracy: 0.9812\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0338 - accuracy: 0.9910\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0188 - accuracy: 0.9924\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0272 - accuracy: 0.9931\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0190 - accuracy: 0.9951\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0222 - accuracy: 0.9910\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0478 - accuracy: 0.9847\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0803 - accuracy: 0.9681\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0749 - accuracy: 0.9771\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0729 - accuracy: 0.9764\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0391 - accuracy: 0.9861\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 2.6055 - accuracy: 0.6094\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 2.6055362224578857\n",
      "Test Accuracy: 0.609375\n",
      "10/10 [==============================] - 2s 153ms/step\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold2/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.3521 - accuracy: 0.8806\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.1796 - accuracy: 0.9257\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.1170 - accuracy: 0.9563\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.1045 - accuracy: 0.9542\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0630 - accuracy: 0.9799\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0729 - accuracy: 0.9750\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0544 - accuracy: 0.9792\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0493 - accuracy: 0.9854\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0800 - accuracy: 0.9757\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 26s 563ms/step - loss: 0.0494 - accuracy: 0.9861\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0276 - accuracy: 0.9903\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0413 - accuracy: 0.9854\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0388 - accuracy: 0.9854\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0463 - accuracy: 0.9868\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0517 - accuracy: 0.9799\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0429 - accuracy: 0.9833\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0378 - accuracy: 0.9854\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0242 - accuracy: 0.9937\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0266 - accuracy: 0.9910\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0470 - accuracy: 0.9819\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 27s 582ms/step - loss: 0.0241 - accuracy: 0.9910\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0376 - accuracy: 0.9882\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0415 - accuracy: 0.9854\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0182 - accuracy: 0.9951\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0134 - accuracy: 0.9944\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0151 - accuracy: 0.9944\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0272 - accuracy: 0.9896\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0274 - accuracy: 0.9889\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0193 - accuracy: 0.9931\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.0679 - accuracy: 0.9757\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0287 - accuracy: 0.9882\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0231 - accuracy: 0.9910\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0728 - accuracy: 0.9819\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0848 - accuracy: 0.9750\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0524 - accuracy: 0.9826\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0348 - accuracy: 0.9868\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0223 - accuracy: 0.9937\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0169 - accuracy: 0.9951\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0164 - accuracy: 0.9924\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0103 - accuracy: 0.9965\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0133 - accuracy: 0.9944\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0203 - accuracy: 0.9944\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 27s 585ms/step - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0512 - accuracy: 0.9812\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0526 - accuracy: 0.9826\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.0214 - accuracy: 0.9951\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0166 - accuracy: 0.9958\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.4368 - accuracy: 0.8781\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.4367833137512207\n",
      "Test Accuracy: 0.878125011920929\n",
      "10/10 [==============================] - 2s 153ms/step\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold3/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.1075 - accuracy: 0.9660\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0676 - accuracy: 0.9757\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0447 - accuracy: 0.9833\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0267 - accuracy: 0.9910\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0140 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0189 - accuracy: 0.9924\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0329 - accuracy: 0.9910\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.1166 - accuracy: 0.9694\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.2111 - accuracy: 0.9333\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0652 - accuracy: 0.9799\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0777 - accuracy: 0.9778\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0309 - accuracy: 0.9903\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0137 - accuracy: 0.9958\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0050 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0056 - accuracy: 0.9972\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0089 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0273 - accuracy: 0.9896\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0101 - accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.0080 - accuracy: 0.9965\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0065 - accuracy: 0.9965\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0232 - accuracy: 0.9917\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0145 - accuracy: 0.9944\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0196 - accuracy: 0.9944\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0324 - accuracy: 0.9910\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0129 - accuracy: 0.9931\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0505 - accuracy: 0.9847\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0399 - accuracy: 0.9861\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 26s 565ms/step - loss: 0.0313 - accuracy: 0.9937\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0104 - accuracy: 0.9979\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.0287 - accuracy: 0.9910\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0089 - accuracy: 0.9965\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0367 - accuracy: 0.9868\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0874 - accuracy: 0.9750\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0811 - accuracy: 0.9771\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0355 - accuracy: 0.9854\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 23s 495ms/step - loss: 0.0103 - accuracy: 0.9958\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0066 - accuracy: 0.9979\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 0.1077 - accuracy: 0.9563\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.10766126215457916\n",
      "Test Accuracy: 0.956250011920929\n",
      "10/10 [==============================] - 2s 162ms/step\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold4/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0494 - accuracy: 0.9875\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0721 - accuracy: 0.9806\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0663 - accuracy: 0.9750\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.1369 - accuracy: 0.9625\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0439 - accuracy: 0.9847\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.0219 - accuracy: 0.9944\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0070 - accuracy: 0.9986\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0117 - accuracy: 0.9951\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0039 - accuracy: 0.9979\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0067 - accuracy: 0.9972\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0128 - accuracy: 0.9944\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0306 - accuracy: 0.9917\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0552 - accuracy: 0.9826\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0106 - accuracy: 0.9944\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0201 - accuracy: 0.9924\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0133 - accuracy: 0.9965\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0144 - accuracy: 0.9979\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0084 - accuracy: 0.9965\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0090 - accuracy: 0.9958\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0074 - accuracy: 0.9965\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0052 - accuracy: 0.9979\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0104 - accuracy: 0.9958\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0015 - accuracy: 0.9993\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0218 - accuracy: 0.9917\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0235 - accuracy: 0.9958\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0370 - accuracy: 0.9875\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0501 - accuracy: 0.9847\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0712 - accuracy: 0.9792\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0640 - accuracy: 0.9799\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0172 - accuracy: 0.9931\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0073 - accuracy: 0.9958\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0070 - accuracy: 0.9965\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0383 - accuracy: 0.9903\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.0115 - accuracy: 0.9958\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0133 - accuracy: 0.9944\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 22s 474ms/step - loss: 0.0101 - accuracy: 0.9965\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 0.009356117807328701\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 2s 157ms/step\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Training\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Number of Training Samples: 1440\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split/fold5/Testing\n",
      "Found 320 images belonging to 2 classes.\n",
      "Number of Test Samples: 320\n",
      "Epoch 1/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0275 - accuracy: 0.9924\n",
      "Epoch 2/60\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0190 - accuracy: 0.9924\n",
      "Epoch 3/60\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0374 - accuracy: 0.9847\n",
      "Epoch 4/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 5/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 6/60\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 7/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 8/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 9/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 9.2922e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 11/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 12/60\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 13/60\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0262 - accuracy: 0.9958\n",
      "Epoch 14/60\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0419 - accuracy: 0.9861\n",
      "Epoch 15/60\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0740 - accuracy: 0.9750\n",
      "Epoch 16/60\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0153 - accuracy: 0.9958\n",
      "Epoch 17/60\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0064 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 19/60\n",
      "45/45 [==============================] - 26s 566ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 20/60\n",
      "45/45 [==============================] - 27s 585ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "Epoch 21/60\n",
      "45/45 [==============================] - 22s 471ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 22/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 6.1406e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 25/60\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 26/60\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 5.1265e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 29/60\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 30/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 8.0443e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 5.4739e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0018 - accuracy: 0.9986\n",
      "Epoch 33/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 34/60\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0077 - accuracy: 0.9965\n",
      "Epoch 35/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0925 - accuracy: 0.9806\n",
      "Epoch 36/60\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.1131 - accuracy: 0.9681\n",
      "Epoch 37/60\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0251 - accuracy: 0.9917\n",
      "Epoch 38/60\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0072 - accuracy: 0.9986\n",
      "Epoch 39/60\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 40/60\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 41/60\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 42/60\n",
      "45/45 [==============================] - 27s 586ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0072 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 45/60\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0026 - accuracy: 0.9986\n",
      "Epoch 47/60\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 49/60\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 51/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 5.2579e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0053 - accuracy: 0.9993\n",
      "Epoch 54/60\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 7.0909e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 56/60\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0058 - accuracy: 0.9972\n",
      "Epoch 57/60\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0139 - accuracy: 0.9972\n",
      "Epoch 58/60\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 59/60\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0151 - accuracy: 0.9965\n",
      "Epoch 60/60\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 7.0558e-04 - accuracy: 1.0000\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 2.1364e-04 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 0.00021363883570302278\n",
      "Test Accuracy: 1.0\n",
      "10/10 [==============================] - 1s 132ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Fold  Accuracy  Precision  Recall  F1 Score\n",
      "0     1  0.609375   0.627737  0.5375  0.579125\n",
      "1     2  0.878125   0.853801  0.9125  0.882175\n",
      "2     3  0.956250   0.939759  0.9750  0.957055\n",
      "3     4  1.000000   1.000000  1.0000  1.000000\n",
      "4     5  1.000000   1.000000  1.0000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/5folds- 80-20 train test split'\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_number in range(1, 6):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Evaluate precision, recall, and F1 score\n",
    "    predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    true_labels = np.argmax(test_generator.labels, axis=1) if len(test_generator.labels.shape) > 1 else test_generator.labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "    # Store the results for this fold\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "\n",
    "# Save precision, recall, and f1_list to a file\n",
    "results = {\n",
    "    'precision_list': precision_list,\n",
    "    'recall_list': recall_list,\n",
    "    'f1_list': f1_list\n",
    "}\n",
    "\n",
    "with open('evaluation_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Boxplot for precision, recall, and F1 score\n",
    "df_boxplot = pd.DataFrame({\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_boxplot)\n",
    "plt.title('Precision, Recall, and F1 Score Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "df_summary = pd.DataFrame({\n",
    "    'Fold': range(1, 6),\n",
    "    'Accuracy': fold_accuracies,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1 Score': f1_list\n",
    "})\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision List: [0.6277372262773723, 0.8538011695906432, 0.9397590361445783, 1.0, 1.0]\n",
      "Recall List: [0.5375, 0.9125, 0.975, 1.0, 1.0]\n",
      "F1 List: [0.5791245791245792, 0.8821752265861027, 0.9570552147239264, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the results from the file\n",
    "with open('evaluation_results.pkl', 'rb') as file:\n",
    "    loaded_results = pickle.load(file)\n",
    "\n",
    "# Access individual lists\n",
    "precision_list_loaded = loaded_results['precision_list']\n",
    "recall_list_loaded = loaded_results['recall_list']\n",
    "f1_list_loaded = loaded_results['f1_list']\n",
    "\n",
    "# Print the loaded results\n",
    "print(\"Precision List:\", precision_list_loaded)\n",
    "print(\"Recall List:\", recall_list_loaded)\n",
    "print(\"F1 List:\", f1_list_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIOCAYAAACPj11ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFoElEQVR4nO3deVzU1f7H8fewowgqJmAioKhgUq65EFdRc80iM+lqLqmVtt1cWqxrLpm0qFk3NTOXtPJqZmTm3qKYpmVZmZYbhCa4leC+wPn94Y+5jqBfQHBQXs/HYx4P58z5nvl8v8N85c35zhmbMcYIAAAAAHBJLs4uAAAAAABKOoITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITgCI3a9Ys2Ww2h9sNN9ygli1bavHixc4uzy40NFR9+vQp8HYnTpzQyJEj9fXXXxd5TSkpKerUqZMqVqwom82mJ5988pJ9Q0NDHY6xj4+PmjRpotmzZxd5XVZSUlJks9k0a9asAm3Xp08fhYaGFktNhdGnTx+HY+rh4aEaNWpo6NChyszMdHZ5eR7nnPdbSkqK0+rKj/zWOXLkyFznj5zbW2+9Ze83e/Zs3Xfffapdu7ZcXFwK/HO0Z88ePfLII6pVq5a8vb1VsWJFRUVF6cEHH9SePXsKsYcArnduzi4AwPVr5syZioiIkDFG6enpeuutt9S5c2ctWrRInTt3dnZ5hXbixAmNGjVKktSyZcsiHXvQoEHasGGDZsyYocDAQAUFBV22f3R0tMaNGydJ2rt3r8aNG6fevXvr+PHjGjhwYJHWdjlBQUFav369atSoUaDthg8frn/961/FVFXheHt768svv5QkHTlyRAsWLND48eP1888/a8WKFU6urvRYtmyZ/Pz8HNrCwsLs/54zZ47S09N16623Kjs7W2fPns332Hv37lWDBg1Uvnx5DRkyRLVr11ZGRoa2bt2q+fPna/fu3QoODi6yfQFwfSA4ASg2devWVaNGjez327dvrwoVKmju3LnXdHAqTlu2bNGtt96quLi4fPUvX768mjZtar/fpk0bhYSEaMKECZcMTllZWTp37pw8PT2LomRJkqenp0Md+VXQoHU1uLi4OOxL+/bttXv3bq1cuVLJyckOv7yj+DRs2FCVKlW65OPLly+Xi8v5C2fuuOMObdmyJd9jT5s2TYcOHdLGjRsdXs+4uDg999xzys7OLnzhBXTy5El5eXnJZrNdtecEUDhcqgfgqvHy8pKHh4fc3d0d2v/66y898sgjuvHGG+Xh4aHq1avr+eef1+nTpyVJp06dUv369RUeHq6MjAz7dunp6QoMDFTLli2VlZUl6fylVj4+Pvr111/VunVrlS1bVjfccIMee+wxnThxwrLG1NRU3X///apcubI8PT0VGRmp8ePH23+RSklJ0Q033CBJGjVqlP0SIqtL/qzG/frrr2Wz2bRz504tXbrUPm5BL78qX768ateurT/++MNer81m06uvvqoxY8YoLCxMnp6e+uqrryRJ33//ve68805VrFhRXl5eql+/vubPn59r3D///FMPPfSQgoOD5eHhoSpVqqhr167av3+/w/NceAnZwYMH7dt4enrqhhtuUHR0tFatWmXvk9eleqdOndKwYcMUFhYmDw8P3XjjjXr00Ud15MgRh36hoaG64447tGzZMjVo0EDe3t6KiIjQjBkzCnTM8iPnDwA5+5tj3rx5atasmcqWLSsfHx+1a9dOP/74Y67tN2zYoM6dO8vf319eXl6qUaOGw2WYO3fu1AMPPKCaNWuqTJkyuvHGG9W5c2f98ssvRb4vFxs1apSaNGmiihUrytfXVw0aNND06dNljHHoV5Dj/e233yo6OlpeXl6qUqWKhg0bVqAZofzICU2FcfjwYbm4uKhy5cr5Gtvq9ZOktWvXqnXr1ipXrpzKlCmj5s2b6/PPP3fok3O54ooVK9S3b1/dcMMNKlOmjP1cl9+fJwDOQXACUGxyZjbOnj2rvXv36sknn9Tx48fVvXt3e59Tp04pNjZWs2fP1uDBg/X555/r/vvv16uvvqouXbpIOh+45s+frwMHDqhv376SpOzsbPXo0UPGGM2dO1eurq72Mc+ePauOHTuqdevWSkxM1GOPPaapU6cqPj7+svUePHhQzZs314oVK/Tiiy9q0aJFatOmjYYOHarHHntM0vlL0pYtWyZJ6tevn9avX6/169dr+PDhVzRugwYNtH79egUGBio6Oto+rtWlehc7e/as/vjjD3u4y/Hmm2/qyy+/1Lhx47R06VJFREToq6++UnR0tI4cOaK3335bn376qerVq6f4+HiHAPTnn3+qcePG+uSTTzR48GAtXbpUEydOlJ+fn/7+++9L1tKzZ08lJibqhRde0IoVK/Tuu++qTZs2Onz48CW3McYoLi5O48aNU8+ePfX5559r8ODBeu+999SqVSv7L5g5fvrpJw0ZMkSDBg3Sp59+qptvvln9+vXTmjVrCnTcrCQnJ8vNzU3Vq1e3t40dO1b//Oc/VadOHc2fP19z5szR0aNHFRMTo61bt9r7LV++XDExMUpNTdWECRO0dOlS/fvf/3YIYfv27ZO/v79efvllLVu2TJMmTZKbm5uaNGmi33//vUj35WIpKSl6+OGHNX/+fC1cuFBdunTR448/rhdffDFX3/wc761bt6p169Y6cuSIZs2apbfffls//vijxowZU6C6cs4fObecP44UhWbNmik7O1tdunTR8uXLL/v5tfy8fqtXr1arVq2UkZGh6dOna+7cuSpXrpw6d+6sefPm5Rqzb9++cnd315w5c7RgwQK5u7vn++cJgBMZAChiM2fONJJy3Tw9Pc3kyZMd+r799ttGkpk/f75D+yuvvGIkmRUrVtjb5s2bZySZiRMnmhdeeMG4uLg4PG6MMb179zaSzBtvvOHQ/tJLLxlJZu3atfa2kJAQ07t3b/v9Z5991kgyGzZscNh24MCBxmazmd9//90YY8zBgweNJDNixIh8HY/8jptTU6dOnfI1bkhIiOnYsaM5e/asOXv2rElOTrbv/1NPPWWMMSY5OdlIMjVq1DBnzpxx2D4iIsLUr1/fnD171qH9jjvuMEFBQSYrK8sYY0zfvn2Nu7u72bp16yVryXmemTNn2tt8fHzMk08+edl96N27twkJCbHfX7ZsmZFkXn31VYd+Oa/9O++847D/Xl5e5o8//rC3nTx50lSsWNE8/PDDl33ey9VTtmxZ+zE9dOiQmTJlinFxcTHPPfecvV9qaqpxc3Mzjz/+uMP2R48eNYGBgaZbt272tho1apgaNWqYkydP5ruOc+fOmTNnzpiaNWuaQYMG2dvzOs4577fk5OSC7/BFsrKyzNmzZ83o0aONv7+/yc7Otj+W3+MdHx9vvL29TXp6usP+RERE5KvOESNG5Hn+uPHGGy+5TadOnRx+jqxkZ2ebhx9+2Li4uBhJxmazmcjISDNo0KBc9eXn9WvatKmpXLmyOXr0qL3t3Llzpm7duqZq1ar245jzWvXq1cth+4L8PAFwHmacABSb2bNn67vvvtN3332npUuXqnfv3nr00UcdVsb68ssvVbZsWXXt2tVh25xL37744gt7W7du3TRw4EA99dRTGjNmjJ577jndfvvteT53jx49HO7nzHLlXKKWly+//FJ16tTRrbfemqsWY4x9wYCCKq5xJWnJkiVyd3eXu7u7wsLCNH/+fD3++OO5/rp/5513OlwiuXPnTv3222/243ThX/Y7duyotLQ0+0zH0qVLFRsbq8jIyALVduutt2rWrFkaM2aMvv3223xdqpVzLC6+9PHee+9V2bJlHX4eJKlevXqqVq2a/b6Xl5dq1aplv1SxMI4fP24/ppUqVdLAgQMVHx+vl156yd5n+fLlOnfunHr16uVw7Ly8vNSiRQv7iovbt2/Xrl271K9fP3l5eV3yOc+dO6exY8eqTp068vDwkJubmzw8PLRjxw5t27at0PuSH19++aXatGkjPz8/ubq6yt3dXS+88IIOHz6sAwcOOPTNz/H+6quv1Lp1awUEBNjbXF1dLWd8L7Zq1Sr7+eO7777TkiVLCrmHudlsNr399tvavXu3Jk+erAceeEBnz57V66+/rptuukmrV6+WlL/X7/jx49qwYYO6du0qHx8fe7urq6t69uypvXv35po1vOeeexzu5/fnCYBzsTgEgGITGRmZa3GIP/74Q08//bTuv/9+lS9fXocPH1ZgYGCuD0ZXrlxZbm5uuS7r6tu3r6ZMmSIPDw898cQTeT6vm5ub/P39HdoCAwMl6bKXiR0+fDjPJY2rVKliue3lFNe4knTbbbfp9ddfl81mU5kyZVSjRg15eHjk6nfxJX85lxkNHTpUQ4cOzXPsQ4cOSTp/qWHVqlULXNu8efM0ZswYvfvuuxo+fLh8fHx0991369VXX7W/Hhc7fPiw3Nzccl1qaLPZFBgYmOtYXfw6S+cXqjh58mSB683h7e1tv/QsPT1d48eP19y5c3XzzTfr2WeflfS/49e4ceM8x8j5jMzBgwclyfL4DR48WJMmTdIzzzyjFi1aqEKFCnJxcVH//v2vaF+sbNy4UW3btlXLli01bdo0Va1aVR4eHkpMTNRLL72U67nzc7xz3tMXu9Rrfim33HLLZReHKAohISEOi6jMnz9f//znP/XUU09p48aN+Xr9/v77bxlj8rys9lLv8Uu9H61+ngA4F8EJwFV18803a/ny5dq+fbtuvfVW+fv7a8OGDTLGOISnAwcO6Ny5cw6/OB0/flw9e/ZUrVq1tH//fvXv31+ffvppruc4d+6cDh8+7PBLXnp6uqS8f/HL4e/vr7S0tFzt+/btk6RC/xJXXONKkp+fn0M4vZSLg2nOcw4bNsz+WbKL1a5dW5J0ww03aO/evQWurVKlSpo4caImTpyo1NRULVq0SM8++6wOHDhg/5zYxfz9/XXu3DkdPHjQITyZ/1/S/lK/WBYlFxcXh2N6++23q2HDhho1apR69Oih4OBg+/FbsGCBQkJCLjlWzj5YHb/3339fvXr10tixYx3aDx06pPLlyxdyT6z997//lbu7uxYvXuwwo5KYmFjoMf39/e3vtwvl1VbSdOvWTQkJCfYV+vLz+uWE3IK8xy/1frT6eQLgXPwJA8BVtXnzZkn/+4WkdevWOnbsWK5f1HK+xLV169b2tgEDBig1NVULFy7U9OnTtWjRIr3++ut5Ps8HH3zgcP/DDz+UdPnvXWrdurW2bt2qH374IVctNptNsbGxkmRfxju/MwH5Hfdqql27tmrWrKmffvpJjRo1yvNWrlw5SVKHDh301VdfXdEiBdWqVdNjjz2m22+/PddxuFDO6/3+++87tH/88cc6fvy4w8/D1eLp6alJkybp1KlT9ksg27VrJzc3N+3ateuSx0+SatWqpRo1amjGjBm5Fra4kM1my7U8/Oeff64///yz+Hbs/5/Xzc3NYXGVkydPas6cOYUeMzY2Vl988YXD4glZWVl5LpLgLHmFHEk6duyY9uzZY58pys/rV7ZsWTVp0kQLFy50OCdkZ2fr/fffV9WqVVWrVq3L1pPfnycAzsWME4Bis2XLFp07d07S+UtVFi5cqJUrV+ruu++2f3dKr169NGnSJPXu3VspKSmKiorS2rVrNXbsWHXs2FFt2rSRJL377rt6//33NXPmTN1000266aab9Nhjj+mZZ55RdHS0w+eHPDw8NH78eB07dkyNGzfWunXrNGbMGHXo0EG33XbbJesdNGiQZs+erU6dOmn06NEKCQnR559/rsmTJ2vgwIH2X37KlSunkJAQffrpp2rdurUqVqyoSpUq5Xk5XkHGvdqmTp2qDh06qF27durTp49uvPFG/fXXX9q2bZt++OEHffTRR5Kk0aNHa+nSpfrHP/6h5557TlFRUTpy5IiWLVumwYMHKyIiItfYGRkZio2NVffu3RUREaFy5crpu+++07Jlyy45wyWdn91p166dnnnmGWVmZio6Olo///yzRowYofr166tnz56F2tec16agy7vnaNGihTp27KiZM2fq2WefVVhYmEaPHq3nn39eu3fvtn9H2f79+7Vx40aVLVvW/iXJkyZNUufOndW0aVMNGjRI1apVU2pqqpYvX24P+HfccYdmzZqliIgI3Xzzzdq0aZNee+21Ql0iKZ1f3j42NlYjRozQyJEjL9mvU6dOmjBhgrp3766HHnpIhw8f1rhx467oO77+/e9/a9GiRWrVqpVeeOEFlSlTRpMmTdLx48cLPWZetm7dal9tLj09XSdOnNCCBQskSXXq1FGdOnUuue1LL72kb775RvHx8apXr568vb2VnJyst956S4cPH9Zrr71m75uf1y8hIUG33367YmNjNXToUHl4eGjy5MnasmWL5s6da/kdTaGhofn+eQLgRE5dmgLAdSmvVfX8/PxMvXr1zIQJE8ypU6cc+h8+fNgMGDDABAUFGTc3NxMSEmKGDRtm7/fzzz8bb29vhxXwjDHm1KlTpmHDhiY0NNT8/fffxpj/rYr2888/m5YtWxpvb29TsWJFM3DgQHPs2DGH7S9eVc8YY/744w/TvXt34+/vb9zd3U3t2rXNa6+9Zl9hLseqVatM/fr1jaenp5GUa5yL5Xfcgq6qZ9U3ZxW21157Lc/Hf/rpJ9OtWzdTuXJl4+7ubgIDA02rVq3M22+/7dBvz549pm/fviYwMNC4u7ubKlWqmG7dupn9+/c7PE/Oam+nTp0yAwYMMDfffLPx9fU13t7epnbt2mbEiBHm+PHj9nEvXlXPmPMrtT3zzDMmJCTEuLu7m6CgIDNw4ED7a2y1/y1atDAtWrRwaKtUqZJp2rTpZY9VTj1ly5bN87FffvnFuLi4mAceeMDelpiYaGJjY42vr6/x9PQ0ISEhpmvXrmbVqlUO265fv9506NDB+Pn5GU9PT1OjRg2H1fL+/vtv069fP1O5cmVTpkwZc9ttt5mkpKRc+5LfVfU+++wzIynX65iXGTNmmNq1axtPT09TvXp1k5CQYKZPn55rzIIc72+++cY0bdrUeHp6msDAQPPUU0+Zd955p0Cr6h08eDBf/fK6Wa14+e2335pHH33U3HLLLaZixYrG1dXV3HDDDaZ9+/ZmyZIlufpbvX7GGJOUlGRatWplypYta7y9vU3Tpk3NZ5995tAn57X67rvv8qwrvz9PAJzDZsxF33AHANewPn36aMGCBTp27JizS0EJsXXrVt10001avHixOnXq5Oxyroqnn35ac+fO1Y4dOy67mh8AIP/4jBMA4Lr21VdfqVmzZqUmNEnn93n48OGEJgAoQsw4AbiuMOMEAACKA8EJAAAAACxwqR4AAAAAWCA4AQAAAIAFghMAAAAAWCh1X4CbnZ2tffv2qVy5cpZfSAcAAADg+mWM0dGjR1WlShW5uFx+TqnUBad9+/YpODjY2WUAAAAAKCH27NmjqlWrXrZPqQtO5cqVk3T+4Pj6+jq5GgAAAADOkpmZqeDgYHtGuJxSF5xyLs/z9fUlOAEAAADI10d4WBwCAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAglOD05o1a9S5c2dVqVJFNptNiYmJltusXr1aDRs2lJeXl6pXr6633367+AsFAAAAUKo5NTgdP35ct9xyi95666189U9OTlbHjh0VExOjH3/8Uc8995yeeOIJffzxx8VcKQAAAIDSzM2ZT96hQwd16NAh3/3ffvttVatWTRMnTpQkRUZG6vvvv9e4ceN0zz33FFOVAAAAAEo7pwanglq/fr3atm3r0NauXTtNnz5dZ8+elbu7e65tTp8+rdOnT9vvZ2ZmFnud+J8dO3bo6NGjVzzOyZMnlZKScuUFFaPQ0FB5e3tf8TjlypVTzZo1i6AioGQoqvOAVPLPBUV1HpA4F+D6UprOAxK/E1yvrqnglJ6eroCAAIe2gIAAnTt3TocOHVJQUFCubRISEjRq1KirVSIusGPHDtWqVcvZZVyTtm/fzokS1wXOA1eGcwGuB5wHrgzngZLjmgpOkmSz2RzuG2PybM8xbNgwDR482H4/MzNTwcHBxVcg7HL+svT+++8rMjLyisYqLX9d2rZtm+6///4i+6sc4GxFeR6QSv65oKj+ysy5ANeT0nYekPid4Hp1TQWnwMBApaenO7QdOHBAbm5u8vf3z3MbT09PeXp6Xo3ycAmRkZFq0KDBFY8THR1dBNUAcIaiOg9InAuAaxXnAVzrrqnvcWrWrJlWrlzp0LZixQo1atQoz883AQAAAEBRcGpwOnbsmDZv3qzNmzdLOr/c+ObNm5Wamirp/GV2vXr1svcfMGCA/vjjDw0ePFjbtm3TjBkzNH36dA0dOtQZ5QMAAAAoJZx6qd7333+v2NhY+/2czyL17t1bs2bNUlpamj1ESVJYWJiWLFmiQYMGadKkSapSpYrefPNNliIHAAAAUKycGpxatmxpX9whL7NmzcrV1qJFC/3www/FWBUAAAAAOLqmPuMEAAAAAM5AcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALDg5uwCAADXt0Afm7yPbJf28be6/PI+sl2BPjZnlwEAuADBCQBQrB5u6KHINQ9La5xdybUjUuePGwCg5CA4AQCK1dRNZxT/wixFRkQ4u5RrxrbfftPU8d11p7MLAQDYEZwAAMUq/ZjRyfK1pCr1nF3KNeNkerbSjxlnlwEAuAAXnAMAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFhwc3YBAAAAuL4F+tjkfWS7tI+/2eeX95HtCvSxObsMXIDgBAAAgGL1cEMPRa55WFrj7EquHZE6f9xQchCcAAAAUKymbjqj+BdmKTIiwtmlXDO2/fabpo7vrjudXQjsCE4AAAAoVunHjE6WryVVqefsUq4ZJ9OzlX7MOLsMXIALTQEAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACy4ObsAXN8CfWzyPrJd2kdGzw/vI9sV6GNzdhkAAAC4CMEJxerhhh6KXPOwtMbZlVwbInX+mAEAAKBkITihWE3ddEbxL8xSZESEs0u5Jmz77TdNHd9ddzq7EAAAADggOKFYpR8zOlm+llSlnrNLuSacTM9W+jHj7DIAAABwET54AgAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAW3JxdAADg+nXixAlJ0g8//FAk4508eVIpKSlFMlZxCA0Nlbe39xWPs23btiKoBgBQlAhOAIBi89tvv0mSHnzwQSdXcm0qV66cs0sAAPw/ghMAoNjExcVJkiIiIlSmTJkrHq+0zDhJ50NTzZo1i2QsAMCVIzgBAIpNpUqV1L9//yIdMzo6ukjHAwAgP1gcAgAAAAAsEJwAAAAAwALBCQAAAAAsEJwAAAAAwILTg9PkyZMVFhYmLy8vNWzYUElJSZftP2nSJEVGRsrb21u1a9fW7Nmzr1KlAAAAAEorp66qN2/ePD355JOaPHmyoqOjNXXqVHXo0EFbt25VtWrVcvWfMmWKhg0bpmnTpqlx48bauHGjHnzwQVWoUEGdO3d2wh4AAAAAKA2cOuM0YcIE9evXT/3791dkZKQmTpyo4OBgTZkyJc/+c+bM0cMPP6z4+HhVr15d9913n/r166dXXnnlKlcOAAAAoDRxWnA6c+aMNm3apLZt2zq0t23bVuvWrctzm9OnT8vLy8uhzdvbWxs3btTZs2cvuU1mZqbDDQAAAAAKwmnB6dChQ8rKylJAQIBDe0BAgNLT0/Pcpl27dnr33Xe1adMmGWP0/fffa8aMGTp79qwOHTqU5zYJCQny8/Oz34KDg4t8XwAAAABc35y+OITNZnO4b4zJ1ZZj+PDh6tChg5o2bSp3d3fddddd6tOnjyTJ1dU1z22GDRumjIwM+23Pnj1FWj8AAACA65/TglOlSpXk6uqaa3bpwIEDuWahcnh7e2vGjBk6ceKEUlJSlJqaqtDQUJUrV06VKlXKcxtPT0/5+vo63AAAAACgIJwWnDw8PNSwYUOtXLnSoX3lypVq3rz5Zbd1d3dX1apV5erqqv/+97+644475OLi9MkzAAAAANcppy5HPnjwYPXs2VONGjVSs2bN9M477yg1NVUDBgyQdP4yuz///NP+XU3bt2/Xxo0b1aRJE/3999+aMGGCtmzZovfee8+ZuwEAAADgOufU4BQfH6/Dhw9r9OjRSktLU926dbVkyRKFhIRIktLS0pSammrvn5WVpfHjx+v333+Xu7u7YmNjtW7dOoWGhjppDwAAAACUBk4NTpL0yCOP6JFHHsnzsVmzZjncj4yM1I8//ngVqgIAAACA/+GDQQAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABac/gW4AAAAuH6dOHFCkvTDDz8UyXgnT55USkpKkYxVXEJDQ+Xt7X1FY2zbtq2IqkFRITgBAACg2Pz222+SpAcffNDJlVybypUr5+wS8P8ITgAAACg2cXFxkqSIiAiVKVPmiscrLTNO0vnQVLNmzSKoCEWB4AQAAIBiU6lSJfXv379Ix4yOji7S8YD8YHEIAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAAC27OLgDXrxMnTkiSfvjhhyse6+TJk0pJSbnicYpTaGiovL29r2iMbdu2FVE1AAAAKEoEJxSb3377TZL04IMPOrmSa0+5cuWcXQIAAAAuQHBCsYmLi5MkRUREqEyZMlc0VmmZcZLOh6aaNWsWQUUAAAAoKjZjjHF2EVdTZmam/Pz8lJGRIV9fX2eXAwAAAMBJCpINWBwCAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACw4PThNnjxZYWFh8vLyUsOGDZWUlHTZ/h988IFuueUWlSlTRkFBQXrggQd0+PDhq1QtAAAAgNLIqcFp3rx5evLJJ/X888/rxx9/VExMjDp06KDU1NQ8+69du1a9evVSv3799Ouvv+qjjz7Sd999p/79+1/lygEAAACUJk4NThMmTFC/fv3Uv39/RUZGauLEiQoODtaUKVPy7P/tt98qNDRUTzzxhMLCwnTbbbfp4Ycf1vfff3+VKwcAAABQmjgtOJ05c0abNm1S27ZtHdrbtm2rdevW5blN8+bNtXfvXi1ZskTGGO3fv18LFixQp06drkbJAAAAAEoppwWnQ4cOKSsrSwEBAQ7tAQEBSk9Pz3Ob5s2b64MPPlB8fLw8PDwUGBio8uXL6z//+c8ln+f06dPKzMx0uAEAAABAQTh9cQibzeZw3xiTqy3H1q1b9cQTT+iFF17Qpk2btGzZMiUnJ2vAgAGXHD8hIUF+fn72W3BwcJHWDwAAAOD6ZzPGGGc88ZkzZ1SmTBl99NFHuvvuu+3t//rXv7R582atXr061zY9e/bUqVOn9NFHH9nb1q5dq5iYGO3bt09BQUG5tjl9+rROnz5tv5+Zmang4GBlZGTI19e3iPcKAAAAwLUiMzNTfn5++coGTptx8vDwUMOGDbVy5UqH9pUrV6p58+Z5bnPixAm5uDiW7OrqKun8TFVePD095evr63ADAAAAgIJw6qV6gwcP1rvvvqsZM2Zo27ZtGjRokFJTU+2X3g0bNky9evWy9+/cubMWLlyoKVOmaPfu3frmm2/0xBNP6NZbb1WVKlWctRsAAAAArnNuznzy+Ph4HT58WKNHj1ZaWprq1q2rJUuWKCQkRJKUlpbm8J1Offr00dGjR/XWW29pyJAhKl++vFq1aqVXXnnFWbsAAAAAoBRw2mecnKUg1zECAAAAuH5dE59xAgAAAIBrBcEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAwhUFpzNnzuj333/XuXPniqoeAAAAAChxChWcTpw4oX79+qlMmTK66aab7N+19MQTT+jll18u0gIBAAAAwNkKFZyGDRumn376SV9//bW8vLzs7W3atNG8efOKrDgAAAAAKAncCrNRYmKi5s2bp6ZNm8pms9nb69Spo127dhVZcQAAAABQEhRqxungwYOqXLlyrvbjx487BCkAAAAAuB4UKjg1btxYn3/+uf1+TliaNm2amjVrVjSVAQAAAEAJUahL9RISEtS+fXtt3bpV586d0xtvvKFff/1V69ev1+rVq4u6RgAAAABwqkLNODVv3lzr1q3TiRMnVKNGDa1YsUIBAQFav369GjZsWNQ1AgAAAIBTFXjG6ezZs3rooYc0fPhwvffee8VREwAAAACUKAWecXJ3d9cnn3xSHLUAAAAAQIlUqEv17r77biUmJhZxKQAAAABQMhVqcYjw8HC9+OKLWrdunRo2bKiyZcs6PP7EE08USXEAAAAAUBLYjDGmoBuFhYVdekCbTbt3776ioopTZmam/Pz8lJGRIV9fX2eXAwAAAMBJCpINCjXjlJycXKjCAAAAAOBaVKjPOF3IGKNCTFoBAAAAwDWj0MFp9uzZioqKkre3t7y9vXXzzTdrzpw5RVkbAAAAAJQIhbpUb8KECRo+fLgee+wxRUdHyxijb775RgMGDNChQ4c0aNCgoq4TAAAAAJym0ItDjBo1Sr169XJof++99zRy5MgS/RkoFocAAAAAIBUsGxTqUr20tDQ1b948V3vz5s2VlpZWmCEBAAAAoMQqVHAKDw/X/Pnzc7XPmzdPNWvWvOKiAAAAAKAkKdRnnEaNGqX4+HitWbNG0dHRstlsWrt2rb744os8AxUAAAAAXMsKNeN0zz33aMOGDapUqZISExO1cOFCVapUSRs3btTdd99d1DUCAAAAgFMVanGIaxmLQwAAAACQrsLiEEuWLNHy5ctztS9fvlxLly4tzJAAAAAAUGIVKjg9++yzysrKytVujNGzzz57xUUBAAAAQElSqOC0Y8cO1alTJ1d7RESEdu7cecVFAQAAAEBJUqjg5Ofnp927d+dq37lzp8qWLXvFRQEAAABASVKo4HTnnXfqySef1K5du+xtO3fu1JAhQ3TnnXcWWXEAAAAAUBIUKji99tprKlu2rCIiIhQWFqawsDBFRETI399f48aNK+oaAQAAAMCpCvUFuH5+flq3bp1Wrlypn376Sd7e3rrlllsUExNT1PUBAAAAgNMVaMZpw4YN9uXGbTab2rZtq8qVK2vcuHG655579NBDD+n06dPFUigAAAAAOEuBgtPIkSP1888/2+//8ssvevDBB3X77bfr2Wef1WeffaaEhIQiLxIAAAAAnKlAwWnz5s1q3bq1/f5///tf3XrrrZo2bZoGDx6sN998U/Pnzy/yIgEAAADAmQoUnP7++28FBATY769evVrt27e332/cuLH27NlTdNUBAAAAQAlQoOAUEBCg5ORkSdKZM2f0ww8/qFmzZvbHjx49Knd396KtEAAAAACcrEDBqX379nr22WeVlJSkYcOGqUyZMg4r6f3888+qUaNGkRcJAAAAAM5UoOXIx4wZoy5duqhFixby8fHRe++9Jw8PD/vjM2bMUNu2bYu8SAAAAABwJpsxxhR0o4yMDPn4+MjV1dWh/a+//pKPj49DmCppMjMz5efnp4yMDPn6+jq7HAAAAABOUpBsUOgvwM1LxYoVCzMcAAAAAJRoBfqMEwAAAACURgQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALDg9OA0efJkhYWFycvLSw0bNlRSUtIl+/bp00c2my3X7aabbrqKFQMAAAAobZwanObNm6cnn3xSzz//vH788UfFxMSoQ4cOSk1NzbP/G2+8obS0NPttz549qlixou69996rXDkAAACA0sRmjDHOevImTZqoQYMGmjJlir0tMjJScXFxSkhIsNw+MTFRXbp0UXJyskJCQvL1nJmZmfLz81NGRoZ8fX0LXTsAAACAa1tBsoHTZpzOnDmjTZs2qW3btg7tbdu21bp16/I1xvTp09WmTZt8hyYAAAAAKAw3Zz3xoUOHlJWVpYCAAIf2gIAApaenW26flpampUuX6sMPP7xsv9OnT+v06dP2+5mZmYUrGAAAAECp5fTFIWw2m8N9Y0yutrzMmjVL5cuXV1xc3GX7JSQkyM/Pz34LDg6+knIBAAAAlEJOC06VKlWSq6trrtmlAwcO5JqFupgxRjNmzFDPnj3l4eFx2b7Dhg1TRkaG/bZnz54rrh0AAABA6eK04OTh4aGGDRtq5cqVDu0rV65U8+bNL7vt6tWrtXPnTvXr18/yeTw9PeXr6+twAwAAAICCcNpnnCRp8ODB6tmzpxo1aqRmzZrpnXfeUWpqqgYMGCDp/GzRn3/+qdmzZztsN336dDVp0kR169Z1RtkAAAAAShmnBqf4+HgdPnxYo0ePVlpamurWraslS5bYV8lLS0vL9Z1OGRkZ+vjjj/XGG284o2QAAAAApZBTv8fJGfgeJwAAAADSNfI9TgAAAABwrSA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFN2cXAFxtWVlZSkpKUlpamoKCghQTEyNXV1dnlwUAAIASjBknlCoLFy5UeHi4YmNj1b17d8XGxio8PFwLFy50dmkAAAAowQhOKDUWLlyorl27KioqSuvXr9fRo0e1fv16RUVFqWvXroQnAAAAXJLNGGOcXcTVlJmZKT8/P2VkZMjX19fZ5eAqycrKUnh4uKKiopSYmCgXl//9zSA7O1txcXHasmWLduzYwWV7AAAApURBsgEzTigVkpKSlJKSoueee84hNEmSi4uLhg0bpuTkZCUlJTmpQgAAAJRkBCeUCmlpaZKkunXr5vl4TntOPwAAAOBCBCeUCkFBQZKkLVu25Pl4TntOPwAAAOBCBCeUCjExMQoNDdXYsWOVnZ3t8Fh2drYSEhIUFhammJgYJ1UIAACAkozghFLB1dVV48eP1+LFixUXF+ewql5cXJwWL16scePGsTAEAAAA8sQX4KLU6NKlixYsWKAhQ4aoefPm9vawsDAtWLBAXbp0cWJ1AAAAKMlYjhylTlZWlpKSkpSWlqagoCDFxMQw0wQAAFAKFSQbMOOEUsfV1VUtW7Z0dhkAAAC4hvAZJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAtOD06TJ09WWFiYvLy81LBhQyUlJV22/+nTp/X8888rJCREnp6eqlGjhmbMmHGVqgUAAABQGrk588nnzZunJ598UpMnT1Z0dLSmTp2qDh06aOvWrapWrVqe23Tr1k379+/X9OnTFR4ergMHDujcuXNXuXIAAAAApYnNGGOc9eRNmjRRgwYNNGXKFHtbZGSk4uLilJCQkKv/smXLdN9992n37t2qWLFioZ4zMzNTfn5+ysjIkK+vb6FrBwAAAHBtK0g2cNqlemfOnNGmTZvUtm1bh/a2bdtq3bp1eW6zaNEiNWrUSK+++qpuvPFG1apVS0OHDtXJkyevRskAAAAASimnXap36NAhZWVlKSAgwKE9ICBA6enpeW6ze/durV27Vl5eXvrkk0906NAhPfLII/rrr78u+Tmn06dP6/Tp0/b7mZmZRbcTAAAAAEoFpy8OYbPZHO4bY3K15cjOzpbNZtMHH3ygW2+9VR07dtSECRM0a9asS846JSQkyM/Pz34LDg4u8n0AAAAAcH1zWnCqVKmSXF1dc80uHThwINcsVI6goCDdeOON8vPzs7dFRkbKGKO9e/fmuc2wYcOUkZFhv+3Zs6fodgIAAABAqeC04OTh4aGGDRtq5cqVDu0rV65U8+bN89wmOjpa+/bt07Fjx+xt27dvl4uLi6pWrZrnNp6envL19XW4AQAAAEBBOPVSvcGDB+vdd9/VjBkztG3bNg0aNEipqakaMGCApPOzRb169bL37969u/z9/fXAAw9o69atWrNmjZ566in17dtX3t7eztoNAAAAANc5p36PU3x8vA4fPqzRo0crLS1NdevW1ZIlSxQSEiJJSktLU2pqqr2/j4+PVq5cqccff1yNGjWSv7+/unXrpjFjxjhrFwAAAACUAk79Hidn4HucAAAAAEjXyPc4AQAAAMC1guAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABgwalfgAsAAAA4Q1ZWlpKSkpSWlqagoCDFxMTI1dXV2WWhBGPGCQAAAKXKwoULFR4ertjYWHXv3l2xsbEKDw/XwoULnV0aSjCCEwAAAEqNhQsXqmvXroqKitL69et19OhRrV+/XlFRUeratSvhCZdkM8YYZxdxNWVmZsrPz08ZGRny9fV1djkAAAC4SrKyshQeHq6oqCglJibKxeV/cwjZ2dmKi4vTli1btGPHDi7bKyUKkg2YcQIAAECpkJSUpJSUFD333HMOoUmSXFxcNGzYMCUnJyspKclJFaIkIzgBAACgVEhLS5Mk1a1bN8/Hc9pz+gEXIjgBAACgVAgKCpIkbdmyJc/Hc9pz+gEXIjgBAACgVIiJiVFoaKjGjh2r7Oxsh8eys7OVkJCgsLAwxcTEOKlClGQEJwAAAJQKrq6uGj9+vBYvXqy4uDiHVfXi4uK0ePFijRs3joUhkCe+ABcAAAClRpcuXbRgwQINGTJEzZs3t7eHhYVpwYIF6tKlixOrQ0nGcuQAAAAodbKyspSUlKS0tDQFBQUpJiaGmaZSqCDZgBknAAAAlDqurq5q2bKls8vANYTPOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFhwc3YBAABcbVlZWUpKSlJaWpqCgoIUExMjV1dXZ5cFACjBmHECAJQqCxcuVHh4uGJjY9W9e3fFxsYqPDxcCxcudHZpAIASjOAEACg1Fi5cqK5duyoqKkrr16/X0aNHtX79ekVFRalr166EJwDAJdmMMcbZRVxNmZmZ8vPzU0ZGhnx9fZ1dDgDgKsnKylJ4eLiioqKUmJgoF5f//e0wOztbcXFx2rJli3bs2MFlewBQShQkGzDjBAAoFZKSkpSSkqLnnnvOITRJkouLi4YNG6bk5GQlJSU5qUIAQElGcAIAlAppaWmSpLp16+b5eE57Tj8AAC5EcAIAlApBQUGSpC1btuT5eE57Tj8AAC5EcAIAlAoxMTEKDQ3V2LFjlZ2d7fBYdna2EhISFBYWppiYGCdVCAAoyQhOAIBSwdXVVePHj9fixYsVFxfnsKpeXFycFi9erHHjxrEwBAAgT3wBLgCg1OjSpYsWLFigIUOGqHnz5vb2sLAwLViwQF26dHFidQCAkozlyAEApU5WVpaSkpKUlpamoKAgxcTEMNMEAKVQQbIBM04AgFLH1dVVLVu2dHYZAIBrCJ9xAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALbs4u4GozxkiSMjMznVwJAAAAAGfKyQQ5GeFySl1wOnr0qCQpODjYyZUAAAAAKAmOHj0qPz+/y/axmfzEq+tIdna29u3bp3Llyslmszm7HDhJZmamgoODtWfPHvn6+jq7HABOwHkAAOcBGGN09OhRValSRS4ul/8UU6mbcXJxcVHVqlWdXQZKCF9fX06UQCnHeQAA54HSzWqmKQeLQwAAAACABYITAAAAAFggOKFU8vT01IgRI+Tp6ensUgA4CecBAJwHUBClbnEIAAAAACgoZpwAAAAAwALBCQAAAAAsEJwAAAAAwALBCaVSaGioJk6cWOR9AVz/Lj4n2Gw2JSYmOq0eAMDVQXCC0/Xp00c2m002m03u7u6qXr26hg4dquPHjxfbc3733Xd66KGHirwvgOJ14fnCzc1N1apV08CBA/X33387uzQAReDC9/iFt507d0qS1qxZo86dO6tKlSr5/qNFVlaWEhISFBERIW9vb1WsWFFNmzbVzJkzi3lvcL1xc3YBgCS1b99eM2fO1NmzZ5WUlKT+/fvr+PHjmjJlikO/s2fPyt3d/Yqf74YbbiiWvgCKX8754ty5c9q6dav69u2rI0eOaO7cuc4uDUARyHmPXyjn/+Ljx4/rlltu0QMPPKB77rknX+ONHDlS77zzjt566y01atRImZmZ+v7774v1Dy5nzpyRh4dHsY0P52DGCSWCp6enAgMDFRwcrO7du6tHjx5KTEzUyJEjVa9ePc2YMUPVq1eXp6enjDHKyMjQQw89pMqVK8vX11etWrXSTz/95DDmokWL1KhRI3l5ealSpUrq0qWL/bGLL7UZOXKkqlWrJk9PT1WpUkVPPPHEJfumpqbqrrvuko+Pj3x9fdWtWzft37/fYax69eppzpw5Cg0NlZ+fn+677z4dPXq06A8cUArlnC+qVq2qtm3bKj4+XitWrLA/PnPmTEVGRsrLy0sRERGaPHmyw/Z79+7Vfffdp4oVK6ps2bJq1KiRNmzYIEnatWuX7rrrLgUEBMjHx0eNGzfWqlWrrur+AaVdznv8wpurq6skqUOHDhozZozD/+lWPvvsMz3yyCO69957FRYWpltuuUX9+vXT4MGD7X2ys7P1yiuvKDw8XJ6enqpWrZpeeukl++O//PKLWrVqJW9vb/n7++uhhx7SsWPH7I/36dNHcXFxSkhIUJUqVVSrVi1J0p9//qn4+HhVqFBB/v7+uuuuu5SSknKFRwjOQnBCieTt7a2zZ89Kknbu3Kn58+fr448/1ubNmyVJnTp1Unp6upYsWaJNmzapQYMGat26tf766y9J0ueff64uXbqoU6dO+vHHH/XFF1+oUaNGeT7XggUL9Prrr2vq1KnasWOHEhMTFRUVlWdfY4zi4uL0119/afXq1Vq5cqV27dql+Ph4h367du1SYmKiFi9erMWLF2v16tV6+eWXi+joAMixe/duLVu2zD4TPW3aND3//PN66aWXtG3bNo0dO1bDhw/Xe++9J0k6duyYWrRooX379mnRokX66aef9PTTTys7O9v+eMeOHbVq1Sr9+OOPateunTp37qzU1FSn7SOAKxMYGKgvv/xSBw8evGSfYcOG6ZVXXtHw4cO1detWffjhhwoICJAknThxQu3bt1eFChX03Xff6aOPPtKqVav02GOPOYzxxRdfaNu2bVq5cqUWL16sEydOKDY2Vj4+PlqzZo3Wrl0rHx8ftW/fXmfOnCnWfUYxMYCT9e7d29x11132+xs2bDD+/v6mW7duZsSIEcbd3d0cOHDA/vgXX3xhfH19zalTpxzGqVGjhpk6daoxxphmzZqZHj16XPI5Q0JCzOuvv26MMWb8+PGmVq1a5syZM5Z9V6xYYVxdXU1qaqr98V9//dVIMhs3bjTGGDNixAhTpkwZk5mZae/z1FNPmSZNmlgfDACX1bt3b+Pq6mrKli1rvLy8jCQjyUyYMMEYY0xwcLD58MMPHbZ58cUXTbNmzYwxxkydOtWUK1fOHD58ON/PWadOHfOf//zHfv/Cc4Ixxkgyn3zySeF3CoDdhe/xnFvXrl3z7Jvf996vv/5qIiMjjYuLi4mKijIPP/ywWbJkif3xzMxM4+npaaZNm5bn9u+8846pUKGCOXbsmL3t888/Ny4uLiY9Pd1ed0BAgDl9+rS9z/Tp003t2rVNdna2ve306dPG29vbLF++3LJulDzMOKFEWLx4sXx8fOTl5aVmzZrpH//4h/7zn/9IkkJCQhw+Z7Rp0yYdO3ZM/v7+8vHxsd+Sk5O1a9cuSdLmzZvVunXrfD33vffeq5MnT6p69ep68MEH9cknn+jcuXN59t22bZuCg4MVHBxsb6tTp47Kly+vbdu22dtCQ0NVrlw5+/2goCAdOHAg/wcEwCXFxsZq8+bN2rBhgx5//HG1a9dOjz/+uA4ePKg9e/aoX79+DueGMWPGOJwb6tevr4oVK+Y59vHjx/X000/b39c+Pj767bffmHECrqKc93jO7c0337yi8erUqaMtW7bo22+/1QMPPKD9+/erc+fO6t+/v6Tz/7efPn36kr83bNu2TbfccovKli1rb4uOjlZ2drZ+//13e1tUVJTD55o2bdqknTt3qly5cvbzUcWKFXXq1Cn7OQnXFhaHQIkQGxurKVOmyN3dXVWqVHFYAOLCE5V0/jrkoKAgff3117nGKV++vKTzl/rlV3BwsH7//XetXLlSq1at0iOPPKLXXntNq1evzrUQhTFGNpst1xgXt1+8nc1ms18KBODKlC1bVuHh4ZKkN998U7GxsRo1apT9splp06apSZMmDtvkfD7C6tzw1FNPafny5Ro3bpzCw8Pl7e2trl27clkNcBVd+B4vKi4uLmrcuLEaN26sQYMG6f3331fPnj31/PPPW54XLvV/vySH9rx+X2nYsKE++OCDXNux8NS1iRknlAg5J8mQkBDLVfMaNGig9PR0ubm5KTw83OFWqVIlSdLNN9+sL774It/P7+3trTvvvFNvvvmmvv76a61fv16//PJLrn516tRRamqq9uzZY2/bunWrMjIyFBkZme/nA1B0RowYoXHjxikrK0s33nijdu/enevcEBYWJun8uWHz5s32z0NeLCkpSX369NHdd9+tqKgoBQYG8kFu4DpUp04dSednmWvWrClvb+9L/t5Qp04dbd682eFrUr755hu5uLjYF4HIS4MGDbRjxw5Vrlw51znJz8+vaHcIVwXBCdecNm3aqFmzZoqLi9Py5cuVkpKidevW6d///re+//57Sed/kZo7d65GjBihbdu26ZdfftGrr76a53izZs3S9OnTtWXLFu3evVtz5syRt7e3QkJC8nzum2++WT169NAPP/ygjRs3qlevXmrRosUlF58AULxatmypm266SWPHjtXIkSOVkJCgN954Q9u3b9cvv/yimTNnasKECZKkf/7znwoMDFRcXJy++eYb7d69Wx9//LHWr18vSQoPD9fChQu1efNm/fTTT+revTuzxUAJcuzYMfslfJKUnJyszZs3X/Zy2q5du+r111/Xhg0b9Mcff+jrr7/Wo48+qlq1aikiIkJeXl565pln9PTTT2v27NnatWuXvv32W02fPl2S1KNHD3l5eal3797asmWLvvrqKz3++OPq2bOnfQGJvPTo0UOVKlXSXXfdpaSkJCUnJ2v16tX617/+pb179xbpccHVQXDCNcdms2nJkiX6xz/+ob59+6pWrVq67777lJKSYj+BtWzZUh999JEWLVqkevXqqVWrVvblhi9Wvnx5TZs2TdHR0faZqs8++0z+/v55PndiYqIqVKigf/zjH2rTpo2qV6+uefPmFes+A7i8wYMHa9q0aWrXrp3effddzZo1S1FRUWrRooVmzZpln3Hy8PDQihUrVLlyZXXs2FFRUVF6+eWX7Zfyvf7666pQoYKaN2+uzp07q127dmrQoIEzdw3ABb7//nvVr19f9evXl3T+vV+/fn298MILl9ymXbt2+uyzz9S5c2fVqlVLvXv3VkREhFasWCE3t/OfWhk+fLiGDBmiF154QZGRkYqPj7d/NrlMmTJavny5/vrrLzVu3Fhdu3ZV69at9dZbb1221jJlymjNmjWqVq2aunTposjISPXt21cnT56Ur69vER0RXE02Y4xxdhEAAAAAUJIx4wQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGDh/wC3Khr0dR0akAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "precision_list = [0.6277372262773723, 0.8538011695906432, 0.9397590361445783, 1.0, 1.0]\n",
    "recall_list = [0.5375, 0.9125, 0.975, 1.0, 1.0]\n",
    "f1_list = [0.5791245791245792, 0.8821752265861027, 0.9570552147239264, 1.0, 1.0]\n",
    "\n",
    "# Combine the lists into a single list of lists\n",
    "data = [precision_list, recall_list, f1_list]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create boxplot\n",
    "bp = ax.boxplot(data, labels=['Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Boxplot of Precision, Recall, and F1 Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold: 10 Folds, 90% training, 10% testing split. (2 HI, 2 NH for testing, and rest for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:48:43.961558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 15:48:48.538831: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 15:48:48.544169: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,397,122\n",
      "Trainable params: 44,397,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Fold 1 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold1/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 1 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold1/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 686ms/step - loss: 0.9527 - accuracy: 0.5738\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.6354 - accuracy: 0.6350\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 43s 849ms/step - loss: 0.5676 - accuracy: 0.7050\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.5615 - accuracy: 0.7163\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 0.5057 - accuracy: 0.7563\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 0.4770 - accuracy: 0.7713\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 0.4707 - accuracy: 0.7688\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 32s 625ms/step - loss: 0.4360 - accuracy: 0.7775\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.3784 - accuracy: 0.8219\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 0.3640 - accuracy: 0.8294\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.3390 - accuracy: 0.8462\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.3053 - accuracy: 0.8500\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.2876 - accuracy: 0.8619\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 30s 588ms/step - loss: 0.2810 - accuracy: 0.8750\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 30s 588ms/step - loss: 0.2418 - accuracy: 0.8988\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.2086 - accuracy: 0.9069\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.1849 - accuracy: 0.9200\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.1835 - accuracy: 0.9237\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.1739 - accuracy: 0.9287\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.1300 - accuracy: 0.9538\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.1258 - accuracy: 0.9525\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.1000 - accuracy: 0.9644\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 0.1002 - accuracy: 0.9619\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 0.1088 - accuracy: 0.9556\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.1623 - accuracy: 0.9294\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.0649 - accuracy: 0.9744\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 0.0471 - accuracy: 0.9837\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 38s 748ms/step - loss: 0.0465 - accuracy: 0.9831\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 723ms/step - loss: 0.0390 - accuracy: 0.9894\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0323 - accuracy: 0.9875\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 32s 647ms/step - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0448 - accuracy: 0.9894\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0333 - accuracy: 0.9912\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0287 - accuracy: 0.9887\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.0342 - accuracy: 0.9894\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0367 - accuracy: 0.9881\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 30s 585ms/step - loss: 0.0152 - accuracy: 0.9931\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0044 - accuracy: 0.9981\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.1036 - accuracy: 0.9669\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0552 - accuracy: 0.9812\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0095 - accuracy: 0.9956\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0093 - accuracy: 0.9956\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0112 - accuracy: 0.9975\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0330 - accuracy: 0.9887\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0388 - accuracy: 0.9869\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 1.3622 - accuracy: 0.7312\n",
      "\n",
      "Evaluation for Fold 1:\n",
      "Test Loss: 1.362206220626831\n",
      "Test Accuracy: 0.731249988079071\n",
      "\n",
      "Fold 2 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold2/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 2 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold2/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.1176 - accuracy: 0.9619\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0402 - accuracy: 0.9875\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0293 - accuracy: 0.9887\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0166 - accuracy: 0.9919\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0100 - accuracy: 0.9975\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 34s 669ms/step - loss: 0.0076 - accuracy: 0.9969\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0129 - accuracy: 0.9981\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 0.0263 - accuracy: 0.9900\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0085 - accuracy: 0.9981\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 35s 698ms/step - loss: 0.0054 - accuracy: 0.9994\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 8.6778e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0282 - accuracy: 0.9931\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 0.0187 - accuracy: 0.9925\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 0.0908 - accuracy: 0.9744\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 0.0328 - accuracy: 0.9881\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0172 - accuracy: 0.9950\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.0045 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0064 - accuracy: 0.9969\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 8.9350e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.3440e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 8.5047e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 5.6985e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 6.6165e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 564ms/step - loss: 4.8942e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 4.8522e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.3348e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.3997e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 3.8558e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 28s 568ms/step - loss: 0.0132 - accuracy: 0.9944\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0246 - accuracy: 0.9906\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0261 - accuracy: 0.9869\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 35s 691ms/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 0.0052 - accuracy: 0.9975\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2636 - accuracy: 0.9312\n",
      "\n",
      "Evaluation for Fold 2:\n",
      "Test Loss: 0.2636183202266693\n",
      "Test Accuracy: 0.9312499761581421\n",
      "\n",
      "Fold 3 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold3/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 3 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold3/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0512 - accuracy: 0.9875\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0140 - accuracy: 0.9937\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 34s 676ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0097 - accuracy: 0.9981\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0162 - accuracy: 0.9944\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0097 - accuracy: 0.9956\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0201 - accuracy: 0.9912\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0098 - accuracy: 0.9981\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.0040 - accuracy: 0.9975\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0792 - accuracy: 0.9806\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0268 - accuracy: 0.9900\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0124 - accuracy: 0.9950\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 3.2297e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 9.2533e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 1.7515e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 3.3557e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 1.8291e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 5.0826e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 3.7885e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 1.8491e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.7358e-04 - accuracy: 0.9994\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0109 - accuracy: 0.9944\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0027 - accuracy: 0.9981\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0113 - accuracy: 0.9944\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 6.3260e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 3.7574e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "5/5 [==============================] - 1s 213ms/step - loss: 0.0280 - accuracy: 0.9937\n",
      "\n",
      "Evaluation for Fold 3:\n",
      "Test Loss: 0.028017695993185043\n",
      "Test Accuracy: 0.9937499761581421\n",
      "\n",
      "Fold 4 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold4/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 4 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold4/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0152 - accuracy: 0.9931\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0309 - accuracy: 0.9925\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 0.0060 - accuracy: 0.9969\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0217 - accuracy: 0.9956\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 35s 703ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0199 - accuracy: 0.9956\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 0.0044 - accuracy: 0.9969\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 566ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 2.5381e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 2.4105e-04 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 5.9215e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 7.1794e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 3.9550e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 4.8054e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 1.9478e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 3.7180e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 2.5073e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 7.6613e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 9.2451e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 8.0212e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 1.2583e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 6.1018e-04 - accuracy: 0.9994\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 5.3141e-05 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 5.2383e-05 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 5.8874e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 2.6281e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 4.0437e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 8.5527e-04 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 2.4924e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 3.9824e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 7.7014e-04 - accuracy: 0.9994\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0046 - accuracy: 0.9981\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 0.0233 - accuracy: 0.9937\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 0.0141 - accuracy: 0.9956\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 0.0216 - accuracy: 0.9962\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0188 - accuracy: 0.9950\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 2.8576e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 4.6061e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 8.0059e-04 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 3.0390e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 1.0499e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 7.9683e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 2.5992e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 4:\n",
      "Test Loss: 2.5991565053118393e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 5 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold5/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 5 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold5/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 5.4678e-04 - accuracy: 1.0000\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 5.1531e-05 - accuracy: 1.0000\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 2.4568e-04 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 6.8271e-04 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 9.6474e-05 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 0.0091 - accuracy: 0.9987\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 7.5011e-04 - accuracy: 0.9994\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 0.0261 - accuracy: 0.9937\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 5.5301e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 1.6152e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 1.9142e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 1.2072e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 2.7737e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 3.8964e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.1044e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 1.2003e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0268 - accuracy: 0.9919\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.0527 - accuracy: 0.9900\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0303 - accuracy: 0.9912\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 9.3953e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 7.5270e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.0036 - accuracy: 0.9981\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 4.5073e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 0.0129 - accuracy: 0.9975\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 35s 694ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 9.5915e-05 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 31s 619ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 36s 708ms/step - loss: 1.2711e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 7.1713e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 265ms/step - loss: 1.9932e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 5:\n",
      "Test Loss: 1.993163095903583e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 6 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold6/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 6 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold6/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 0.0411 - accuracy: 0.9925\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 7.6048e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0054 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 7.9276e-04 - accuracy: 1.0000\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 6.1653e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 6.4111e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.0447e-04 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.2074e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 7.3788e-04 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 2.0906e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 8.5449e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 6.8344e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 4.0619e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 5.1611e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 1.0618e-04 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 5.3677e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 36s 708ms/step - loss: 2.9994e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 3.9470e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 4.3739e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 1.6496e-05 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 1.6341e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 8.2184e-04 - accuracy: 0.9994\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 2.7951e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 3.8546e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0120 - accuracy: 0.9975\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 2.3732e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 2.0393e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 4.6259e-05 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.7966e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 2.9781e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.6920e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 2.0768e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 1.2769e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 3.9592e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 8.4676e-05 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 1.1616e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 2.8765e-05 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 2.3561e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.6957e-04 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 1.3119e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 1.1711e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0250 - accuracy: 0.9956\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0039 - accuracy: 0.9981\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 6.7985e-05 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 6:\n",
      "Test Loss: 6.798455433454365e-05\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 7 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold7/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 7 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold7/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.1062 - accuracy: 0.9756\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 33s 660ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 38s 745ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 8.2020e-04 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 1.6679e-04 - accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 3.6984e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 5.2740e-05 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 2.6340e-04 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 9.9302e-05 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 4.5787e-05 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 1.4849e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 3.4806e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 1.5977e-05 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 1.1239e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 1.9109e-04 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 5.9920e-06 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.3723e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 4.8151e-06 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 1.2271e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 7.7432e-04 - accuracy: 0.9994\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 2.4979e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 1.0888e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 38s 749ms/step - loss: 2.7615e-04 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 6.8246e-04 - accuracy: 0.9994\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 38s 746ms/step - loss: 4.9539e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 3.0397e-05 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 726ms/step - loss: 1.1164e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 31s 607ms/step - loss: 3.6123e-05 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 1.4324e-05 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 2.8352e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 1.1848e-05 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 3.2976e-06 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 5.8213e-06 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 1.4712e-05 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.4605e-05 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 1.8275e-06 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 3.1083e-06 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 5.0375e-06 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.9206e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 3.3417e-06 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.2057e-06 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 6.5537e-06 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 1.2876e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 4.9297e-07 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 6.2840e-05 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 1.5631e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 7.7627e-06 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 4.8329e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 2.4720e-06 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 1.8577e-06 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 34s 676ms/step - loss: 2.6007e-06 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 5.2154e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 7:\n",
      "Test Loss: 5.2154007335047936e-08\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 8 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold8/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 8 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold8/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.8146e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.3815e-04 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0148 - accuracy: 0.9962\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0201 - accuracy: 0.9969\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0528 - accuracy: 0.9937\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.1302 - accuracy: 0.9737\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 6.4786e-04 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0043 - accuracy: 0.9981\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 38s 745ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 9.6421e-04 - accuracy: 0.9994\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 1.6085e-04 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 36s 711ms/step - loss: 1.1088e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 8.9105e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 2.3028e-05 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 1.1271e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 3.2857e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 5.7814e-04 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.3845e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.1551e-04 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 28s 569ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0308 - accuracy: 0.9919\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 4.8328e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0049 - accuracy: 0.9975\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 8.2530e-04 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.8693e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 4.1950e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 2.2839e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 1.4807e-05 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 2.2305e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 3.1674e-04 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 5.2586e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 3.5535e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 4.6415e-06 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 1.6795e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 3.9011e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 2.4892e-04 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 1.6052e-04 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 6.6296e-05 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 2.3227e-06 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 6.8916e-07 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 8:\n",
      "Test Loss: 6.891584121149208e-07\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 9 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold9/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 9 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold9/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 1.2388e-04 - accuracy: 1.0000\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 2.5787e-04 - accuracy: 1.0000\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 7.9892e-05 - accuracy: 1.0000\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 6.6395e-04 - accuracy: 0.9994\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 7.0089e-05 - accuracy: 1.0000\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 3.5276e-05 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.0037 - accuracy: 0.9975\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 9.9881e-04 - accuracy: 0.9994\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.9607e-04 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 1.7363e-04 - accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 4.7721e-04 - accuracy: 0.9994\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 1.5343e-05 - accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 5.2234e-05 - accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 1.3996e-05 - accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 1.5819e-05 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 5.7938e-05 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 35s 697ms/step - loss: 8.3949e-06 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 2.4736e-05 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 37s 728ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 4.6256e-04 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 5.2750e-04 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 3.7050e-05 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 37s 747ms/step - loss: 3.5168e-05 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 36s 709ms/step - loss: 1.4989e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 2.4062e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 2.6229e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 1.9517e-04 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 8.6018e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 0.0268 - accuracy: 0.9962\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0103 - accuracy: 0.9981\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 0.0041 - accuracy: 0.9994\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 5.1011e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 34s 667ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 6.9046e-06 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 1.4727e-05 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 8.2477e-06 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 5.5595e-05 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 0.0041 - accuracy: 0.9975\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 8.5760e-04 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 29s 564ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 1.0918e-04 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 1.4051e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 6.8570e-06 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0216 - accuracy: 0.9950\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 6.4820e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 9:\n",
      "Test Loss: 6.481987213646789e-08\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Fold 10 - Training Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold10/Training\n",
      "Found 1600 images belonging to 2 classes.\n",
      "Number of Training Samples: 1600\n",
      "\n",
      "Fold 10 - Testing Data Directory: /home/wangg/REU-Hearing-Loss-Project/machine learning/newFolds/fold10/Testing\n",
      "Found 160 images belonging to 2 classes.\n",
      "Number of Test Samples: 160\n",
      "Epoch 1/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 2/60\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0094 - accuracy: 0.9962\n",
      "Epoch 3/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 4/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 5/60\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 6/60\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 0.0015 - accuracy: 0.9987\n",
      "Epoch 7/60\n",
      "50/50 [==============================] - 38s 748ms/step - loss: 3.1859e-04 - accuracy: 1.0000\n",
      "Epoch 8/60\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 1.7270e-05 - accuracy: 1.0000\n",
      "Epoch 9/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 9.1561e-05 - accuracy: 1.0000\n",
      "Epoch 10/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 11/60\n",
      "50/50 [==============================] - 38s 747ms/step - loss: 0.0013 - accuracy: 0.9987\n",
      "Epoch 12/60\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 6.1992e-04 - accuracy: 0.9994\n",
      "Epoch 13/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 7.2511e-05 - accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 15/60\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0028 - accuracy: 0.9981\n",
      "Epoch 17/60\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 18/60\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 19/60\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 3.2768e-04 - accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 4.5351e-04 - accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 2.9279e-05 - accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 1.8252e-04 - accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 5.4271e-05 - accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "50/50 [==============================] - 30s 590ms/step - loss: 1.5062e-05 - accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 1.8042e-06 - accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 2.1120e-05 - accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 9.1967e-07 - accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 3.2109e-06 - accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 1.8848e-04 - accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 6.5175e-05 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 2.9259e-04 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 7.2755e-07 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 1.7977e-05 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "50/50 [==============================] - 36s 705ms/step - loss: 6.4824e-05 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "50/50 [==============================] - 37s 729ms/step - loss: 2.9863e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 6.7671e-05 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 38/60\n",
      "50/50 [==============================] - 29s 568ms/step - loss: 1.5643e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 2.1166e-06 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 0.0107 - accuracy: 0.9981\n",
      "Epoch 41/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.2394 - accuracy: 0.9787\n",
      "Epoch 42/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0217 - accuracy: 0.9950\n",
      "Epoch 43/60\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0077 - accuracy: 0.9981\n",
      "Epoch 44/60\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 45/60\n",
      "50/50 [==============================] - 29s 567ms/step - loss: 9.2193e-04 - accuracy: 0.9994\n",
      "Epoch 46/60\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 47/60\n",
      "50/50 [==============================] - 30s 585ms/step - loss: 1.0413e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0010 - accuracy: 0.9994\n",
      "Epoch 49/60\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 6.8035e-04 - accuracy: 0.9994\n",
      "Epoch 50/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 51/60\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 8.0534e-04 - accuracy: 0.9994\n",
      "Epoch 52/60\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 53/60\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 3.2815e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 4.4275e-04 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 1.3813e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 1.9725e-04 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "50/50 [==============================] - 37s 727ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 59/60\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 2.7357e-04 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 3.3116e-05 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 314ms/step - loss: 9.6857e-08 - accuracy: 1.0000\n",
      "\n",
      "Evaluation for Fold 10:\n",
      "Test Loss: 9.685724222663339e-08\n",
      "Test Accuracy: 1.0\n",
      "Accuracies for each fold:\n",
      "Fold 1: 0.731249988079071\n",
      "Fold 2: 0.9312499761581421\n",
      "Fold 3: 0.9937499761581421\n",
      "Fold 4: 1.0\n",
      "Fold 5: 1.0\n",
      "Fold 6: 1.0\n",
      "Fold 7: 1.0\n",
      "Fold 8: 1.0\n",
      "Fold 9: 1.0\n",
      "Fold 10: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-5: 0.9656249940395355\n",
      "Standard Deviation of Accuracy across Folds 1-5: 0.08073152242833005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Path to the data directories\n",
    "fold_data_dir = '/home/wangg/REU-Hearing-Loss-Project/machine learning/allFolds/10folds- 90-10 train test split'  # Change this to the root folder containing your k-fold data\n",
    "\n",
    "# CNN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Dimensions of the images (224x224 with 3 channels)\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Create the CNN model\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Data generator for training and testing (no validation)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Lists to store results for each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold_number in range(1, 11):\n",
    "    # Update fold path \n",
    "    fold_path = os.path.join(fold_data_dir, f'fold{fold_number}')\n",
    "\n",
    "    # Training data\n",
    "    train_data_dir = os.path.join(fold_path, 'Training')\n",
    "    print(f\"\\nFold {fold_number} - Training Data Directory:\", train_data_dir)\n",
    "    \n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    print(\"Number of Training Samples:\", train_generator.samples)\n",
    "\n",
    "    # Testing data\n",
    "    test_data_dir = os.path.join(fold_path, 'Testing')\n",
    "    print(f\"\\nFold {fold_number} - Testing Data Directory:\", test_data_dir)\n",
    "\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "    print(\"Number of Test Samples:\", test_generator.samples)\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=60)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "    print(f'\\nEvaluation for Fold {fold_number}:')\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # Store the accuracy for this fold\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-5: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-5: {std_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each fold:\n",
      "Fold 1: 0.731249988079071\n",
      "Fold 2: 0.9312499761581421\n",
      "Fold 3: 0.9937499761581421\n",
      "Fold 4: 1.0\n",
      "Fold 5: 1.0\n",
      "Fold 6: 1.0\n",
      "Fold 7: 1.0\n",
      "Fold 8: 1.0\n",
      "Fold 9: 1.0\n",
      "Fold 10: 1.0\n",
      "\n",
      "Average Accuracy across Folds 1-10: 0.9656249940395355\n",
      "Standard Deviation of Accuracy across Folds 1-10: 0.08073152242833005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Traverse through fold_accuracies and print them\n",
    "print(\"Accuracies for each fold:\")\n",
    "for fold_number, accuracy in enumerate(fold_accuracies, start=1):\n",
    "    print(f'Fold {fold_number}: {accuracy}')\n",
    "\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\nAverage Accuracy across Folds 1-10: {average_accuracy}')\n",
    "print(f'Standard Deviation of Accuracy across Folds 1-10: {std_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('REU-Hearing-Loss-Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9362165e0877ffe35a450e3f6d34df4731e71258943496d98bc14a880fb264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
